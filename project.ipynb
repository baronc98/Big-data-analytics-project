{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57kg2SCcxGPs"
      },
      "source": [
        "# Setting Pyspark on Colab (If runned on colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjv4Ak07skbe",
        "outputId": "bb3333e7-2e56-48b0-e776-d63bdd1f50f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=451176eb9b35f04f1a69a4f5ede3e0b3c1d77ee6766aa402d1b9c0a6a6054551\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting horovod[spark]\n",
            "  Downloading horovod-0.28.1.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (2.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (23.2)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (1.23.5)\n",
            "Collecting petastorm>=0.12.0 (from horovod[spark])\n",
            "  Downloading petastorm-0.12.1-py2.py3-none-any.whl (284 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<11.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (9.0.0)\n",
            "Requirement already satisfied: fsspec>=2021.07.0 in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (2023.6.0)\n",
            "Requirement already satisfied: pyspark>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from horovod[spark]) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.0->horovod[spark]) (2.21)\n",
            "Collecting dill>=0.2.1 (from petastorm>=0.12.0->horovod[spark])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=3.0.0 (from petastorm>=0.12.0->horovod[spark])\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from petastorm>=0.12.0->horovod[spark]) (0.18.3)\n",
            "Requirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from petastorm>=0.12.0->horovod[spark]) (1.5.3)\n",
            "Requirement already satisfied: pyzmq>=14.0.0 in /usr/local/lib/python3.10/dist-packages (from petastorm>=0.12.0->horovod[spark]) (23.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from petastorm>=0.12.0->horovod[spark]) (1.16.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark>=3.0.0->horovod[spark]) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->petastorm>=0.12.0->horovod[spark]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->petastorm>=0.12.0->horovod[spark]) (2023.3.post1)\n",
            "Building wheels for collected packages: horovod\n",
            "  Building wheel for horovod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for horovod: filename=horovod-0.28.1-cp310-cp310-linux_x86_64.whl size=38034631 sha256=467200216683715d354577c8d41a2509b3ec8304688e6c0302cc88cf1558c39d\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/48/5f/ebbf9b83e04c68070cf9621e6466c33d698efb747d7920b81f\n",
            "Successfully built horovod\n",
            "Installing collected packages: diskcache, dill, horovod, petastorm\n",
            "Successfully installed dill-0.3.7 diskcache-5.6.3 horovod-0.28.1 petastorm-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install horovod[spark]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a57uWQQ-sB_G"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Jg338wU7sQWG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i05EQdumsTBk",
        "outputId": "5bbf7b5d-36e7-41df-f245-128804ed9544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diabetic_data.csv  sample_data\tspark-3.1.1-bin-hadoop3.2  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0KD3QDUns6_K"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-zOh6AQXB5p",
        "outputId": "566a4bf7-b3af-4ae4-fc03-bf5eb64d094e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.8)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.19.1\n",
            "time: 1.01 ms (started: 2023-10-16 11:13:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfRuJkDXr3Do"
      },
      "source": [
        "# Big Data Project: Diabetes Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tymt7vEsRQGC"
      },
      "source": [
        "Taking some inspiration from:\n",
        "- The paper of the dataset: https://downloads.hindawi.com/journals/bmri/2014/781670.pdf\n",
        "- The data description attached with the dataset\n",
        "- GitHub repo: https://github.com/ranveerkln/Diabetic/blob/main/dibetis_23_12.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btgeV_HKr3Dt"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVyQcHRXdy2",
        "outputId": "680bf94c-e3fd-4d95-9928-55ccab2eb73c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 14 s (started: 2023-10-16 11:13:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from zipfile import ZipFile\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, isnan, max, count, sum, when, expr, lit\n",
        "from pyspark.ml.feature import StringIndexer, StandardScaler, VectorAssembler, PCA\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, MultilayerPerceptronClassifier, LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SQLContext\n",
        "from pandas import Series\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.sql.types import IntegerType\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv1D, Dense, Dropout, Activation, MaxPooling1D, InputLayer, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "import horovod.spark.keras as hvd\n",
        "from horovod.spark.common.store import DBFSLocalStore\n",
        "\n",
        "seed = 42   # set the random seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLwZkUsVr3Dv"
      },
      "source": [
        "## Get Dataset + Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6lx8TBBXdy7",
        "outputId": "fa31cd81-786c-4d12-e05c-d98b14ae7422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.47 s (started: 2023-10-16 11:14:07 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pandas = pd.read_csv('diabetic_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "GAlwPGolXdy8",
        "outputId": "6731744b-4a74-438f-a1b2-fb0dd066798a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   encounter_id  patient_nbr             race  gender       age weight  \\\n",
              "0       2278392      8222157        Caucasian  Female    [0-10)      ?   \n",
              "1        149190     55629189        Caucasian  Female   [10-20)      ?   \n",
              "2         64410     86047875  AfricanAmerican  Female   [20-30)      ?   \n",
              "3        500364     82442376        Caucasian    Male   [30-40)      ?   \n",
              "4         16680     42519267        Caucasian    Male   [40-50)      ?   \n",
              "5         35754     82637451        Caucasian    Male   [50-60)      ?   \n",
              "6         55842     84259809        Caucasian    Male   [60-70)      ?   \n",
              "7         63768    114882984        Caucasian    Male   [70-80)      ?   \n",
              "8         12522     48330783        Caucasian  Female   [80-90)      ?   \n",
              "9         15738     63555939        Caucasian  Female  [90-100)      ?   \n",
              "\n",
              "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
              "0                  6                        25                    1   \n",
              "1                  1                         1                    7   \n",
              "2                  1                         1                    7   \n",
              "3                  1                         1                    7   \n",
              "4                  1                         1                    7   \n",
              "5                  2                         1                    2   \n",
              "6                  3                         1                    2   \n",
              "7                  1                         1                    7   \n",
              "8                  2                         1                    4   \n",
              "9                  3                         3                    4   \n",
              "\n",
              "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
              "0                 1  ...          No      No                   No   \n",
              "1                 3  ...          No      Up                   No   \n",
              "2                 2  ...          No      No                   No   \n",
              "3                 2  ...          No      Up                   No   \n",
              "4                 1  ...          No  Steady                   No   \n",
              "5                 3  ...          No  Steady                   No   \n",
              "6                 4  ...          No  Steady                   No   \n",
              "7                 5  ...          No      No                   No   \n",
              "8                13  ...          No  Steady                   No   \n",
              "9                12  ...          No  Steady                   No   \n",
              "\n",
              "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
              "0                   No                        No                       No   \n",
              "1                   No                        No                       No   \n",
              "2                   No                        No                       No   \n",
              "3                   No                        No                       No   \n",
              "4                   No                        No                       No   \n",
              "5                   No                        No                       No   \n",
              "6                   No                        No                       No   \n",
              "7                   No                        No                       No   \n",
              "8                   No                        No                       No   \n",
              "9                   No                        No                       No   \n",
              "\n",
              "   metformin-pioglitazone  change diabetesMed readmitted  \n",
              "0                      No      No          No         NO  \n",
              "1                      No      Ch         Yes        >30  \n",
              "2                      No      No         Yes         NO  \n",
              "3                      No      Ch         Yes         NO  \n",
              "4                      No      Ch         Yes         NO  \n",
              "5                      No      No         Yes        >30  \n",
              "6                      No      Ch         Yes         NO  \n",
              "7                      No      No         Yes        >30  \n",
              "8                      No      Ch         Yes         NO  \n",
              "9                      No      Ch         Yes         NO  \n",
              "\n",
              "[10 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf7311f2-75bc-4e5e-8e7e-fca006d84976\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_nbr</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>...</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>readmitted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2278392</td>\n",
              "      <td>8222157</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[0-10)</td>\n",
              "      <td>?</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>149190</td>\n",
              "      <td>55629189</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[10-20)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64410</td>\n",
              "      <td>86047875</td>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Female</td>\n",
              "      <td>[20-30)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500364</td>\n",
              "      <td>82442376</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[30-40)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16680</td>\n",
              "      <td>42519267</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[40-50)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>35754</td>\n",
              "      <td>82637451</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[50-60)</td>\n",
              "      <td>?</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>55842</td>\n",
              "      <td>84259809</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[60-70)</td>\n",
              "      <td>?</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>63768</td>\n",
              "      <td>114882984</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[70-80)</td>\n",
              "      <td>?</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>&gt;30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12522</td>\n",
              "      <td>48330783</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[80-90)</td>\n",
              "      <td>?</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15738</td>\n",
              "      <td>63555939</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[90-100)</td>\n",
              "      <td>?</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf7311f2-75bc-4e5e-8e7e-fca006d84976')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf7311f2-75bc-4e5e-8e7e-fca006d84976 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf7311f2-75bc-4e5e-8e7e-fca006d84976');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-295529d0-a9a8-4d1b-ae7e-6600922a5399\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-295529d0-a9a8-4d1b-ae7e-6600922a5399')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-295529d0-a9a8-4d1b-ae7e-6600922a5399 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 61.4 ms (started: 2023-10-16 11:14:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pandas.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "43x6v4nKr3Dw",
        "outputId": "cdfc7224-e147-46d0-a22e-d8b7fd0e64a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x796268196f80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6d55bf8076b6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Project_BDA</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.6 s (started: 2023-10-16 11:14:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# local mode\n",
        "spark = SparkSession.builder.appName('Project_BDA').getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pVc3avMr3Dx",
        "outputId": "c05fae5f-18b2-4170-b067-fdbf1f73726e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py:331: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 49.4 s (started: 2023-10-16 11:14:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame(df_pandas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhxIV6Q0r3Dx"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usGJlwvMPkCr"
      },
      "source": [
        "\n",
        "### Printing schema, shape and some interesting features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92s-kCMftj-M",
        "outputId": "869e19fb-d112-4159-f92a-15abc00947ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---------------+------+--------+------+-----------------+------------------------+-------------------+----------------+----------+--------------------+------------------+--------------+---------------+-----------------+----------------+----------------+------+------+------+----------------+-------------+---------+---------+-----------+-----------+--------------+-----------+-------------+---------+---------+-----------+------------+-------------+--------+--------+------------+----------+-------+-----------+-------+-------------------+-------------------+------------------------+-----------------------+----------------------+------+-----------+----------+\n",
            "|encounter_id|patient_nbr|           race|gender|     age|weight|admission_type_id|discharge_disposition_id|admission_source_id|time_in_hospital|payer_code|   medical_specialty|num_lab_procedures|num_procedures|num_medications|number_outpatient|number_emergency|number_inpatient|diag_1|diag_2|diag_3|number_diagnoses|max_glu_serum|A1Cresult|metformin|repaglinide|nateglinide|chlorpropamide|glimepiride|acetohexamide|glipizide|glyburide|tolbutamide|pioglitazone|rosiglitazone|acarbose|miglitol|troglitazone|tolazamide|examide|citoglipton|insulin|glyburide-metformin|glipizide-metformin|glimepiride-pioglitazone|metformin-rosiglitazone|metformin-pioglitazone|change|diabetesMed|readmitted|\n",
            "+------------+-----------+---------------+------+--------+------+-----------------+------------------------+-------------------+----------------+----------+--------------------+------------------+--------------+---------------+-----------------+----------------+----------------+------+------+------+----------------+-------------+---------+---------+-----------+-----------+--------------+-----------+-------------+---------+---------+-----------+------------+-------------+--------+--------+------------+----------+-------+-----------+-------+-------------------+-------------------+------------------------+-----------------------+----------------------+------+-----------+----------+\n",
            "|     2278392|    8222157|      Caucasian|Female|  [0-10)|     ?|                6|                      25|                  1|               1|         ?|Pediatrics-Endocr...|                41|             0|              1|                0|               0|               0|250.83|     ?|     ?|               1|         None|     None|       No|         No|         No|            No|         No|           No|       No|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No|     No|                 No|                 No|                      No|                     No|                    No|    No|         No|        NO|\n",
            "|      149190|   55629189|      Caucasian|Female| [10-20)|     ?|                1|                       1|                  7|               3|         ?|                   ?|                59|             0|             18|                0|               0|               0|   276|250.01|   255|               9|         None|     None|       No|         No|         No|            No|         No|           No|       No|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No|     Up|                 No|                 No|                      No|                     No|                    No|    Ch|        Yes|       >30|\n",
            "|       64410|   86047875|AfricanAmerican|Female| [20-30)|     ?|                1|                       1|                  7|               2|         ?|                   ?|                11|             5|             13|                2|               0|               1|   648|   250|   V27|               6|         None|     None|       No|         No|         No|            No|         No|           No|   Steady|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No|     No|                 No|                 No|                      No|                     No|                    No|    No|        Yes|        NO|\n",
            "|      500364|   82442376|      Caucasian|  Male| [30-40)|     ?|                1|                       1|                  7|               2|         ?|                   ?|                44|             1|             16|                0|               0|               0|     8|250.43|   403|               7|         None|     None|       No|         No|         No|            No|         No|           No|       No|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No|     Up|                 No|                 No|                      No|                     No|                    No|    Ch|        Yes|        NO|\n",
            "|       16680|   42519267|      Caucasian|  Male| [40-50)|     ?|                1|                       1|                  7|               1|         ?|                   ?|                51|             0|              8|                0|               0|               0|   197|   157|   250|               5|         None|     None|       No|         No|         No|            No|         No|           No|   Steady|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No| Steady|                 No|                 No|                      No|                     No|                    No|    Ch|        Yes|        NO|\n",
            "|       35754|   82637451|      Caucasian|  Male| [50-60)|     ?|                2|                       1|                  2|               3|         ?|                   ?|                31|             6|             16|                0|               0|               0|   414|   411|   250|               9|         None|     None|       No|         No|         No|            No|         No|           No|       No|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No| Steady|                 No|                 No|                      No|                     No|                    No|    No|        Yes|       >30|\n",
            "|       55842|   84259809|      Caucasian|  Male| [60-70)|     ?|                3|                       1|                  2|               4|         ?|                   ?|                70|             1|             21|                0|               0|               0|   414|   411|   V45|               7|         None|     None|   Steady|         No|         No|            No|     Steady|           No|       No|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No| Steady|                 No|                 No|                      No|                     No|                    No|    Ch|        Yes|        NO|\n",
            "|       63768|  114882984|      Caucasian|  Male| [70-80)|     ?|                1|                       1|                  7|               5|         ?|                   ?|                73|             0|             12|                0|               0|               0|   428|   492|   250|               8|         None|     None|       No|         No|         No|            No|         No|           No|       No|   Steady|         No|          No|           No|      No|      No|          No|        No|     No|         No|     No|                 No|                 No|                      No|                     No|                    No|    No|        Yes|       >30|\n",
            "|       12522|   48330783|      Caucasian|Female| [80-90)|     ?|                2|                       1|                  4|              13|         ?|                   ?|                68|             2|             28|                0|               0|               0|   398|   427|    38|               8|         None|     None|       No|         No|         No|            No|         No|           No|   Steady|       No|         No|          No|           No|      No|      No|          No|        No|     No|         No| Steady|                 No|                 No|                      No|                     No|                    No|    Ch|        Yes|        NO|\n",
            "|       15738|   63555939|      Caucasian|Female|[90-100)|     ?|                3|                       3|                  4|              12|         ?|    InternalMedicine|                33|             3|             18|                0|               0|               0|   434|   198|   486|               8|         None|     None|       No|         No|         No|            No|         No|           No|       No|       No|         No|          No|       Steady|      No|      No|          No|        No|     No|         No| Steady|                 No|                 No|                      No|                     No|                    No|    Ch|        Yes|        NO|\n",
            "+------------+-----------+---------------+------+--------+------+-----------------+------------------------+-------------------+----------------+----------+--------------------+------------------+--------------+---------------+-----------------+----------------+----------------+------+------+------+----------------+-------------+---------+---------+-----------+-----------+--------------+-----------+-------------+---------+---------+-----------+------------+-------------+--------+--------+------------+----------+-------+-----------+-------+-------------------+-------------------+------------------------+-----------------------+----------------------+------+-----------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "time: 5.75 s (started: 2023-10-16 11:15:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WIrZNZir3Dy",
        "outputId": "de491517-b039-439f-c79e-5d01ac949534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- encounter_id: long (nullable = true)\n",
            " |-- patient_nbr: long (nullable = true)\n",
            " |-- race: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- weight: string (nullable = true)\n",
            " |-- admission_type_id: long (nullable = true)\n",
            " |-- discharge_disposition_id: long (nullable = true)\n",
            " |-- admission_source_id: long (nullable = true)\n",
            " |-- time_in_hospital: long (nullable = true)\n",
            " |-- payer_code: string (nullable = true)\n",
            " |-- medical_specialty: string (nullable = true)\n",
            " |-- num_lab_procedures: long (nullable = true)\n",
            " |-- num_procedures: long (nullable = true)\n",
            " |-- num_medications: long (nullable = true)\n",
            " |-- number_outpatient: long (nullable = true)\n",
            " |-- number_emergency: long (nullable = true)\n",
            " |-- number_inpatient: long (nullable = true)\n",
            " |-- diag_1: string (nullable = true)\n",
            " |-- diag_2: string (nullable = true)\n",
            " |-- diag_3: string (nullable = true)\n",
            " |-- number_diagnoses: long (nullable = true)\n",
            " |-- max_glu_serum: string (nullable = true)\n",
            " |-- A1Cresult: string (nullable = true)\n",
            " |-- metformin: string (nullable = true)\n",
            " |-- repaglinide: string (nullable = true)\n",
            " |-- nateglinide: string (nullable = true)\n",
            " |-- chlorpropamide: string (nullable = true)\n",
            " |-- glimepiride: string (nullable = true)\n",
            " |-- acetohexamide: string (nullable = true)\n",
            " |-- glipizide: string (nullable = true)\n",
            " |-- glyburide: string (nullable = true)\n",
            " |-- tolbutamide: string (nullable = true)\n",
            " |-- pioglitazone: string (nullable = true)\n",
            " |-- rosiglitazone: string (nullable = true)\n",
            " |-- acarbose: string (nullable = true)\n",
            " |-- miglitol: string (nullable = true)\n",
            " |-- troglitazone: string (nullable = true)\n",
            " |-- tolazamide: string (nullable = true)\n",
            " |-- examide: string (nullable = true)\n",
            " |-- citoglipton: string (nullable = true)\n",
            " |-- insulin: string (nullable = true)\n",
            " |-- glyburide-metformin: string (nullable = true)\n",
            " |-- glipizide-metformin: string (nullable = true)\n",
            " |-- glimepiride-pioglitazone: string (nullable = true)\n",
            " |-- metformin-rosiglitazone: string (nullable = true)\n",
            " |-- metformin-pioglitazone: string (nullable = true)\n",
            " |-- change: string (nullable = true)\n",
            " |-- diabetesMed: string (nullable = true)\n",
            " |-- readmitted: string (nullable = true)\n",
            "\n",
            "time: 76.3 ms (started: 2023-10-16 11:15:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gIyEWTLr3Dy",
        "outputId": "56b923c7-5a3e-41e1-8001-6564134db2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101766, 50)\n",
            "time: 3.36 s (started: 2023-10-16 11:15:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Dataset shape\n",
        "print((df.count(), len(df.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwlqos1kr3Dy"
      },
      "source": [
        "#### Visualization of some important features:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAxfzAMbr3Dy",
        "outputId": "8a2ef461-91e8-4e9c-e7a9-524cf27e8a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|A1Cresult|readmitted|\n",
            "+---------+----------+\n",
            "|     None|        NO|\n",
            "|     None|       >30|\n",
            "|     None|        NO|\n",
            "|     None|        NO|\n",
            "|     None|        NO|\n",
            "|     None|       >30|\n",
            "|     None|        NO|\n",
            "|     None|       >30|\n",
            "|     None|        NO|\n",
            "|     None|        NO|\n",
            "|     None|       >30|\n",
            "|     None|       <30|\n",
            "|     None|       <30|\n",
            "|     None|        NO|\n",
            "|     None|       >30|\n",
            "+---------+----------+\n",
            "only showing top 15 rows\n",
            "\n",
            "time: 386 ms (started: 2023-10-16 11:15:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.select(['A1Cresult', 'readmitted']).show(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting unique values for this two features"
      ],
      "metadata": {
        "id": "-tnCRNz8vFo9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E0ts4wGr3Dz",
        "outputId": "8ef0bf7d-a3f6-413d-8907-05b85b1e4805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|readmitted|\n",
            "+----------+\n",
            "|       >30|\n",
            "|        NO|\n",
            "|       <30|\n",
            "+----------+\n",
            "\n",
            "+---------+\n",
            "|A1Cresult|\n",
            "+---------+\n",
            "|     None|\n",
            "|       >8|\n",
            "|     Norm|\n",
            "|       >7|\n",
            "+---------+\n",
            "\n",
            "time: 7.84 s (started: 2023-10-16 11:15:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "readmitted_unique = df.select(\"readmitted\").distinct()\n",
        "readmitted_unique.show()\n",
        "A1Cresult_unique = df.select(\"A1Cresult\").distinct()\n",
        "A1Cresult_unique.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the none/null values"
      ],
      "metadata": {
        "id": "igO9SlTavOJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tEoIoIxr3Dz",
        "outputId": "ff7c5d12-ead2-45b1-944e-068689f8e32f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+----+------+---+------+-----------------+------------------------+-------------------+----------------+----------+-----------------+------------------+--------------+---------------+-----------------+----------------+----------------+------+------+------+----------------+-------------+---------+---------+-----------+-----------+--------------+-----------+-------------+---------+---------+-----------+------------+-------------+--------+--------+------------+----------+-------+-----------+-------+-------------------+-------------------+------------------------+-----------------------+----------------------+------+-----------+----------+\n",
            "|encounter_id|patient_nbr|race|gender|age|weight|admission_type_id|discharge_disposition_id|admission_source_id|time_in_hospital|payer_code|medical_specialty|num_lab_procedures|num_procedures|num_medications|number_outpatient|number_emergency|number_inpatient|diag_1|diag_2|diag_3|number_diagnoses|max_glu_serum|A1Cresult|metformin|repaglinide|nateglinide|chlorpropamide|glimepiride|acetohexamide|glipizide|glyburide|tolbutamide|pioglitazone|rosiglitazone|acarbose|miglitol|troglitazone|tolazamide|examide|citoglipton|insulin|glyburide-metformin|glipizide-metformin|glimepiride-pioglitazone|metformin-rosiglitazone|metformin-pioglitazone|change|diabetesMed|readmitted|\n",
            "+------------+-----------+----+------+---+------+-----------------+------------------------+-------------------+----------------+----------+-----------------+------------------+--------------+---------------+-----------------+----------------+----------------+------+------+------+----------------+-------------+---------+---------+-----------+-----------+--------------+-----------+-------------+---------+---------+-----------+------------+-------------+--------+--------+------------+----------+-------+-----------+-------+-------------------+-------------------+------------------------+-----------------------+----------------------+------+-----------+----------+\n",
            "|           0|          0|2273|     0|  0| 98569|                0|                       0|                  0|               0|     40256|            49949|                 0|             0|              0|                0|               0|               0|    21|   358|  1423|               0|        96420|    84748|        0|          0|          0|             0|          0|            0|        0|        0|          0|           0|            0|       0|       0|           0|         0|      0|          0|      0|                  0|                  0|                       0|                      0|                     0|     0|          0|         0|\n",
            "+------------+-----------+----+------+---+------+-----------------+------------------------+-------------------+----------------+----------+-----------------+------------------+--------------+---------------+-----------------+----------------+----------------+------+------+------+----------------+-------------+---------+---------+-----------+-----------+--------------+-----------+-------------+---------+---------+-----------+------------+-------------+--------+--------+------------+----------+-------+-----------+-------+-------------------+-------------------+------------------------+-----------------------+----------------------+------+-----------+----------+\n",
            "\n",
            "time: 15.7 s (started: 2023-10-16 11:15:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.select([count(when(col(c).contains('None') | \\\n",
        "                            col(c).contains('NULL') | \\\n",
        "                            (col(c) == '?' ) | \\\n",
        "                            col(c).isNull() | \\\n",
        "                            isnan(c), c\n",
        "                           )).alias(c)\n",
        "                    for c in df.columns]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUW9ZOULr3Dz"
      },
      "source": [
        "There are a lot of 'None' values in A1Cresult, but they are still important 'cause the indicate when the test was not performed. From this information we can gain as insight into whether or not the test is necessary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5i1Xkll_EAh"
      },
      "source": [
        "A lot of distinct in diag_x features, I must reduce values in data pre-processing section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2h8zrrInE4C",
        "outputId": "dc4b1b64-e562-435c-a4ce-73149823032e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.show of +------+-----+\n",
              "|diag_1|count|\n",
              "+------+-----+\n",
              "|   296|  896|\n",
              "|   691|    1|\n",
              "|   451|   40|\n",
              "|   853|   18|\n",
              "|   800|    6|\n",
              "|   944|    2|\n",
              "|   870|    1|\n",
              "|   919|    1|\n",
              "|250.01|   61|\n",
              "|   447|   63|\n",
              "|   591|   19|\n",
              "|     7|    2|\n",
              "|   574|  965|\n",
              "|   475|   14|\n",
              "|   718|   17|\n",
              "|   307|   25|\n",
              "|   577| 1057|\n",
              "|   581|   19|\n",
              "|   205|   27|\n",
              "|   747|    7|\n",
              "+------+-----+\n",
              "only showing top 20 rows\n",
              ">"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.64 s (started: 2023-10-16 11:15:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.groupBy(\"diag_1\").count().show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIXgZxR9n7qQ",
        "outputId": "d55de601-4102-4e1d-ace4-873a2ae8460e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.show of +------+-----+\n",
              "|diag_2|count|\n",
              "+------+-----+\n",
              "|   296|  165|\n",
              "|   691|    3|\n",
              "|   451|   32|\n",
              "|   V72|   13|\n",
              "|   800|    1|\n",
              "|   944|    1|\n",
              "|   853|    2|\n",
              "|   919|    3|\n",
              "|   870|    3|\n",
              "|250.01| 1523|\n",
              "|   447|   26|\n",
              "|   591|  233|\n",
              "|     7|    1|\n",
              "|   574|  346|\n",
              "|   718|   12|\n",
              "|   307|   13|\n",
              "|   475|    1|\n",
              "|   577|  401|\n",
              "|   581|   80|\n",
              "|   205|   58|\n",
              "+------+-----+\n",
              "only showing top 20 rows\n",
              ">"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.21 s (started: 2023-10-16 11:15:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.groupBy(\"diag_2\").count().show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq4QsJ2vn83a",
        "outputId": "08118e92-1bc7-48f0-8cb5-95422f181e8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.show of +------+-----+\n",
              "|diag_3|count|\n",
              "+------+-----+\n",
              "|   296|  214|\n",
              "|   451|    9|\n",
              "|  E876|    1|\n",
              "|   V72|    8|\n",
              "|   944|    1|\n",
              "|   853|    1|\n",
              "|   800|    2|\n",
              "|   919|    3|\n",
              "|   870|    2|\n",
              "|250.01|  915|\n",
              "|   591|  140|\n",
              "|   447|   39|\n",
              "|     7|    2|\n",
              "|  E825|    1|\n",
              "|   574|  136|\n",
              "|   307|   16|\n",
              "|   718|    9|\n",
              "|   475|    1|\n",
              "|   581|   97|\n",
              "|   577|  149|\n",
              "+------+-----+\n",
              "only showing top 20 rows\n",
              ">"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.88 s (started: 2023-10-16 11:15:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.groupBy(\"diag_3\").count().show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c__Y4hlPYD7"
      },
      "source": [
        "### Some plots to see distributions of readmission and presence of the test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "tbFPefd_r3Dz",
        "outputId": "47e01c25-d210-4dc4-fb28-eca5fbae1c30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x350 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "time: 39.4 s (started: 2023-10-16 11:15:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Visualize distribution of unique values\n",
        "values_A1C = []\n",
        "dist_A1C = []\n",
        "values_readmission = []\n",
        "dist_readmission = []\n",
        "\n",
        "var1 = [values_A1C, values_readmission]\n",
        "var2 = [dist_A1C, dist_readmission]\n",
        "var3 = [A1Cresult_unique, readmitted_unique]\n",
        "columns = ['A1Cresult', 'readmitted']\n",
        "\n",
        "for item1, item2, item3, item4 in zip(var1, var2, var3, columns):\n",
        "  #computing dist\n",
        "  for i in range(item3.count()):\n",
        "    tot = 0\n",
        "    value = item3.collect()[i][0]\n",
        "    item1.append(value)\n",
        "    temp_collect = df.select(item4).collect()\n",
        "    for j in range(df.count()):\n",
        "      if (temp_collect[j][0] == value):\n",
        "        tot = tot + 1\n",
        "    item2.append(tot)\n",
        "\n",
        "  # plotting\n",
        "  fig = plt.figure(figsize = (7, 3.5))\n",
        "  plt.bar(item1, item2, color=(0.2, 0.4, 0.6, 0.6))\n",
        "  plt.title(item4 + ' distribution')\n",
        "  plt.legend(['Number of elements in dataset'], loc='upper right')\n",
        "  plt.show()\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNPwj9g8P1QE"
      },
      "source": [
        "As we can see it's a very unbalanced task. This justify the use of F1-score and some pre-processing techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_MppnwjRIp8"
      },
      "source": [
        "Visualization of \"early readmission\" percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "USE-E3Q2PRKw",
        "outputId": "ec74f954-3944-4e42-a284-4e1cfdc32ac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.patches.Wedge at 0x796264c92230>,\n",
              "  <matplotlib.patches.Wedge at 0x796264c90490>],\n",
              " [Text(-1.0330838402192162, 0.3778065365738357, 'No readmission before 30 days --->'),\n",
              "  Text(1.1270005722606713, -0.4121525325945721, '<--- Early_readmission')],\n",
              " [Text(-0.5635002764832088, 0.20607629267663766, '88.8%'),\n",
              "  Text(0.6574170004853914, -0.240422310680167, '11.2%')])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 288 ms (started: 2023-10-16 11:16:31 +00:00)\n"
          ]
        }
      ],
      "source": [
        "plt.title('Early-readmission distribution')\n",
        "plt.pie([dist_readmission[0] + dist_readmission[1], dist_readmission[2]], labels=['No readmission before 30 days --->', '<--- Early_readmission'],\n",
        "        autopct=\"%1.1f%%\", startangle=0, textprops={'fontsize': 10.5, 'color':'#0a0a00'}, colors=['cornflowerblue', 'orange'], explode=[0, 0.1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjXwtfimr3D0"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFD_wrb8oqzW"
      },
      "source": [
        "For diag_1, diag_2, diag_3 I use most common value to fill missing value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf6CiHkqo7cn",
        "outputId": "654c0982-c7c4-4030-b896-69e11b532eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 185 ms (started: 2023-10-16 11:16:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumn(\"diag_1\", when(df.diag_1 == \"?\", \"577\") \\\n",
        "      .otherwise(df.diag_1))\n",
        "\n",
        "df = df.withColumn(\"diag_2\", when(df.diag_2 == \"?\", \"250.01\") \\\n",
        "      .otherwise(df.diag_2))\n",
        "\n",
        "df = df.withColumn(\"diag_3\", when(df.diag_3 == \"?\", \"250.01\") \\\n",
        "      .otherwise(df.diag_3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLfbG7gI_APS"
      },
      "source": [
        "**diag_x** for x in 1,2,3 has too many values. I must create fewer categories to avoid curse of dimensionality.\n",
        "Using domain knowledge:\n",
        "1.Circulatory → 390–459, 785 → Diseases of the circulatory system\n",
        "2.Respiratory → 460–519, 786 → Diseases of the respiratory system\n",
        "3.Digestive → 520–579, 787 → Diseases of the digestive system\n",
        "4.Diabetes → 250.xx → Diabetes mellitus\n",
        "5.Injury → 800–999 → Injury and poisoning\n",
        "6.Musculoskeletal → 710–739 → Diseases of the musculoskeletal system and connective tissue\n",
        "7.Genitourinary → 580–629, 788 → Diseases of the genitourinary system\n",
        "8.Neoplasms → 140–239 → Neoplasms\n",
        "9.Pregnecy → 630–679 → Complications of pregnancy, childbirth, and the puerperium\n",
        "10.Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzGUH2v4-_Yp",
        "outputId": "59d2fab1-9019-4936-c8d8-7517d390a92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "716\n",
            "10\n",
            "time: 6.93 s (started: 2023-10-16 11:16:32 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('diag_1').distinct().count())\n",
        "\n",
        "df = df.withColumn(\"diag_1\", when(((df.diag_1 >= 390) & (df.diag_1 < 460)) | (df.diag_1 == 785), \"circulatory\")\n",
        "                  .when(((df.diag_1 >= 460) & (df.diag_1 < 519)) | (df.diag_1 == 786), \"respiratory\")\n",
        "                  .when(((df.diag_1 >= 520) & (df.diag_1 < 580)) | (df.diag_1 == 787), \"digestive\")\n",
        "                  .when((df.diag_1 == 250), \"diabetes\")\n",
        "                  .when((df.diag_1 >= 800) & (df.diag_1 < 1000), \"injury\")\n",
        "                  .when((df.diag_1 >= 710) & (df.diag_1 < 740), \"musculoskeletal\")\n",
        "                  .when(((df.diag_1 >= 580) & (df.diag_1 < 630)) | (df.diag_1 == 788), \"genitourinary\")\n",
        "                  .when((df.diag_1 >= 140) & (df.diag_1 < 240), \"neoplasms\")\n",
        "                  .when((df.diag_1 >= 630) & (df.diag_1 < 680), \"pregnecy\")\n",
        "                  .otherwise(\"other\"))\n",
        "\n",
        "print(df.select('diag_1').distinct().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgr0wDWOCLVK",
        "outputId": "a30eb189-e64f-474e-a838-a312ccb5b621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "748\n",
            "10\n",
            "time: 5.27 s (started: 2023-10-16 11:16:39 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('diag_2').distinct().count())\n",
        "\n",
        "df = df.withColumn(\"diag_2\", when(((df.diag_2 >= 390) & (df.diag_2 < 460)) | (df.diag_2 == 785), \"circulatory\")\n",
        "                  .when(((df.diag_2 >= 460) & (df.diag_2 < 519)) | (df.diag_2 == 786), \"respiratory\")\n",
        "                  .when(((df.diag_2 >= 520) & (df.diag_2 < 580)) | (df.diag_2 == 787), \"digestive\")\n",
        "                  .when((df.diag_2 == 250), \"diabetes\")\n",
        "                  .when((df.diag_2 >= 800) & (df.diag_2 < 1000), \"injury\")\n",
        "                  .when((df.diag_2 >= 710) & (df.diag_2 < 740), \"musculoskeletal\")\n",
        "                  .when(((df.diag_2 >= 580) & (df.diag_2 < 630)) | (df.diag_2 == 788), \"genitourinary\")\n",
        "                  .when((df.diag_2 >= 140) & (df.diag_2 < 240), \"neoplasms\")\n",
        "                  .when((df.diag_2 >= 630) & (df.diag_2 < 680), \"pregnecy\")\n",
        "                  .otherwise(\"other\"))\n",
        "\n",
        "print(df.select('diag_2').distinct().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOjhIjR8CLkm",
        "outputId": "0ec55f9f-0bd2-44f3-d4cd-8d1467dfc9e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "789\n",
            "10\n",
            "time: 7.88 s (started: 2023-10-16 11:16:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('diag_3').distinct().count())\n",
        "\n",
        "df = df.withColumn(\"diag_3\", when(((df.diag_3 >= 390) & (df.diag_3 < 460)) | (df.diag_3 == 785), \"circulatory\")\n",
        "                  .when(((df.diag_3 >= 460) & (df.diag_3 < 519)) | (df.diag_3 == 786), \"respiratory\")\n",
        "                  .when(((df.diag_3 >= 520) & (df.diag_3 < 580)) | (df.diag_3 == 787), \"digestive\")\n",
        "                  .when((df.diag_3 == 250), \"diabetes\")\n",
        "                  .when((df.diag_3 >= 800) & (df.diag_3 < 1000), \"injury\")\n",
        "                  .when((df.diag_3 >= 710) & (df.diag_3 < 740), \"musculoskeletal\")\n",
        "                  .when(((df.diag_3 >= 580) & (df.diag_3 < 630)) | (df.diag_3 == 788), \"genitourinary\")\n",
        "                  .when((df.diag_3 >= 140) & (df.diag_3 < 240), \"neoplasms\")\n",
        "                  .when((df.diag_3 >= 630) & (df.diag_3 < 680), \"pregnecy\")\n",
        "                  .otherwise(\"other\"))\n",
        "\n",
        "print(df.select('diag_3').distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcxY7-QsMLbN"
      },
      "source": [
        "For discharge_disposition the value 11, 13, 14, 19, 20, 21 indicates patient has expired, so there are no possibility that patient will readmit. I proceed by deleting the corresponding lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb-e9TDMtbl",
        "outputId": "fc8944ca-14d6-4a8a-ea89-4c003f9d0dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "21\n",
            "time: 6.53 s (started: 2023-10-16 11:16:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('discharge_disposition_id').distinct().count())\n",
        "\n",
        "for i in [11, 13, 14, 19, 20, 21]:\n",
        "  df = df.where(df.discharge_disposition_id != i)\n",
        "\n",
        "print(df.select('discharge_disposition_id').distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJhle2u9Rhr1"
      },
      "source": [
        "Still too many values, so I proceed with merging based on the variable's description given with the dataset (example I merge not mapped/unknown/invalid as NULL which is the id = 18.\n",
        "this is the mapping:\n",
        "cat1 = [6, 8, 9, 13],\n",
        "cat2 = [3, 4, 5, 14, 22, 23, 24],\n",
        "cat10 = [12, 15, 16, 17],\n",
        "cat11 = [19, 20, 21],\n",
        "cat18 = [25, 26]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTTrtJACRsFh",
        "outputId": "20a46f77-abc9-474f-e85f-4aa67fa4649a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n",
            "7\n",
            "time: 7.82 s (started: 2023-10-16 11:16:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('discharge_disposition_id').distinct().count())\n",
        "\n",
        "df = df.withColumn(\"discharge_disposition_id\", when((df.discharge_disposition_id == 6) | (df.discharge_disposition_id == 8) | (df.discharge_disposition_id == 9) | (df.discharge_disposition_id == 13), 1)\n",
        "                                              .when((df.discharge_disposition_id == 3) | (df.discharge_disposition_id == 4) | (df.discharge_disposition_id == 5) | (df.discharge_disposition_id == 14) | (df.discharge_disposition_id == 22) | (df.discharge_disposition_id == 23) | (df.discharge_disposition_id == 24), 2)\n",
        "                                              .when((df.discharge_disposition_id == 12) | (df.discharge_disposition_id == 15) | (df.discharge_disposition_id == 16) | (df.discharge_disposition_id == 17), 10)\n",
        "                                              .when((df.discharge_disposition_id == 19) | (df.discharge_disposition_id == 20) | (df.discharge_disposition_id == 21), 11)\n",
        "                                              .when((df.discharge_disposition_id == 25) | (df.discharge_disposition_id == 26), 18)\n",
        "                                              .otherwise(df.discharge_disposition_id))\n",
        "\n",
        "print(df.select('discharge_disposition_id').distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jw4u8zGr3D0"
      },
      "source": [
        "I have to select features wich could be important to predict the readmission rate and the presence or not of the test.\n",
        "I start deleting some useless columns (for predicting readmission) and those which are not well covered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYe1aI8vr3D0",
        "outputId": "1ce615cd-ec69-448d-d31d-4906d4d25367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  30\n",
            "time: 32 ms (started: 2023-10-16 11:17:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df = df.drop('encounter_id', 'patient_nbr', 'payer_code', 'weight', 'medical_specialty', 'glimepiride', 'acetohexamide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'examide', 'citoglipton', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone')\n",
        "# df.printSchema()\n",
        "print('Features: ', len(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7dSln-WsVVU"
      },
      "source": [
        "Converting ordinal feature 'Age' into numerical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUR1aH5PsVnA",
        "outputId": "b6ece186-f16c-44a2-db7a-72ac3093fc61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 272 ms (started: 2023-10-16 11:17:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "replaceDict = {'[0-10)' : 5,\n",
        "               '[10-20)' : 15,\n",
        "               '[20-30)' : 25,\n",
        "               '[30-40)' : 35,\n",
        "               '[40-50)' : 45,\n",
        "               '[50-60)' : 55,\n",
        "               '[60-70)' : 65,\n",
        "               '[70-80)' : 75,\n",
        "               '[80-90)' : 85,\n",
        "               '[90-100)' : 95}\n",
        "\n",
        "for i in range(len(replaceDict)):\n",
        "  item = replaceDict.popitem()\n",
        "  key = item[0]\n",
        "  value = item[1]\n",
        "  df = df.withColumn(\"age\", when(df.age == key, value) \\\n",
        "        .otherwise(df.age))\n",
        "\n",
        "df = df.withColumn(\"age\", df.age.cast(IntegerType()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd4vm-6wwA5_"
      },
      "source": [
        "Check and drop duplicates ---> same shape as before, so no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03n0AhwOv_0B",
        "outputId": "eda81e70-6c11-431d-dd67-207c142c0875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99340\n",
            "time: 22.1 s (started: 2023-10-16 11:17:07 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVS3pAZgLf4N"
      },
      "source": [
        "Admission Type ID :\n",
        "\n",
        "reducing number of categories\n",
        "cat1 = [2, 7],\n",
        "cat5 = [6, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8oJZMCAMbvl",
        "outputId": "beddfb90-8067-4bd4-d30f-2de64593704a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "4\n",
            "time: 7.84 s (started: 2023-10-16 11:17:29 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('admission_type_id').distinct().count())\n",
        "\n",
        "df = df.withColumn(\"admission_type_id\", when((df.admission_type_id == 2) | (df.admission_type_id == 7), 1)\n",
        "                                              .when((df.admission_type_id == 6) | (df.admission_type_id == 8), 5)\n",
        "                                              .otherwise(df.admission_type_id))\n",
        "\n",
        "print(df.select('admission_type_id').distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ruZVzGeNMmR"
      },
      "source": [
        "Admission Source ID :\n",
        "\n",
        "reducing number of categories\n",
        "cat1 = [2, 3],\n",
        "cat4 = [5, 6, 10, 22, 25],\n",
        "cat9 = [15, 17, 20, 21],\n",
        "cat11 = [13, 17]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk6XNqwkNVvD",
        "outputId": "0045fadc-e98d-4d7a-f013-e3ac3a512eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "6\n",
            "time: 6.55 s (started: 2023-10-16 11:17:37 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(df.select('admission_source_id').distinct().count())\n",
        "\n",
        "df = df.withColumn(\"admission_source_id\", when((df.admission_source_id == 2) | (df.admission_source_id == 3), 1)\n",
        "                                              .when((df.admission_source_id == 5) | (df.admission_source_id == 6) | (df.admission_source_id == 10) | (df.admission_source_id == 22) | (df.admission_source_id == 25), 4)\n",
        "                                              .when((df.admission_source_id == 15) | (df.admission_source_id == 17) | (df.admission_source_id == 20) | (df.admission_source_id == 21), 9)\n",
        "                                              .when((df.admission_source_id == 13) | (df.admission_source_id == 14), 11)\n",
        "                                              .otherwise(df.admission_source_id))\n",
        "\n",
        "print(df.select('admission_source_id').distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX1LVoVOyN5K"
      },
      "source": [
        "**Creating new features:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC8DGO7FuxzR"
      },
      "source": [
        "If the frequency of person’s visit to the hospital is high then the person could be less healthier and tends to readmit quickly. Creating a new variable health_index. Higher the health_index lesser the chance that person will readmit (indirectly proportional).\n",
        "\n",
        "**Health_index** = ( 1 / (number_emergency + number_inpatient + number_outpatient) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RprbXpKUuysf",
        "outputId": "3c590270-46a7-4b40-b5c7-e2cc6bb5a556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 513 ms (started: 2023-10-16 11:17:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumn(\"health_index\", expr(\"1 / (number_emergency + number_inpatient + number_outpatient)\"))\n",
        "# handling when all 3 variables in the denominator are 0 ---> (solution) giving a number > 1\n",
        "df = df.withColumn(\"health_index\", when(df.health_index.isNull(), 2) \\\n",
        "      .otherwise(df.health_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maTxdCIy0ZtN"
      },
      "source": [
        "Severity of disease is high if patient is spending lots of time in hospital and going through number of complicated test so. To get probabilistic interpretation lets divide it by total values.\n",
        "\n",
        "**severity_of_disease** = (time_in_hospital + num_procedures + num_medications + num_lab_procedures + number_of_diagnoses) / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Tnr1Rbxiq-",
        "outputId": "5dbb21eb-5eaa-4918-b2f0-531a15186e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.52 s (started: 2023-10-16 11:17:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumn(\"sum\", expr(\"time_in_hospital + num_procedures + num_medications + num_lab_procedures + number_diagnoses\"))\n",
        "total_value = df.select(sum(df.sum)).first()[\"sum(sum)\"]\n",
        "df = df.withColumn(\"total\", lit(total_value)).withColumn(\"sum\", expr(\"sum / total\")).withColumnRenamed(\"sum\", \"severity_of_disease\").drop(\"total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCfibUuG92i_",
        "outputId": "059825df-b1ff-4ab5-f4b0-0cc400b8e0b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------+---+-----------------+------------------------+-------------------+----------------+------------------+--------------+---------------+-----------------+----------------+----------------+---------+---------+-----------+----------------+-------------+---------+---------+-----------+-----------+--------------+---------+---------+----------+-------+------+-----------+----------+------------------+--------------------+\n",
            "|           race|gender|age|admission_type_id|discharge_disposition_id|admission_source_id|time_in_hospital|num_lab_procedures|num_procedures|num_medications|number_outpatient|number_emergency|number_inpatient|   diag_1|   diag_2|     diag_3|number_diagnoses|max_glu_serum|A1Cresult|metformin|repaglinide|nateglinide|chlorpropamide|glipizide|glyburide|tolazamide|insulin|change|diabetesMed|readmitted|      health_index| severity_of_disease|\n",
            "+---------------+------+---+-----------------+------------------------+-------------------+----------------+------------------+--------------+---------------+-----------------+----------------+----------------+---------+---------+-----------+----------------+-------------+---------+---------+-----------+-----------+--------------+---------+---------+----------+-------+------+-----------+----------+------------------+--------------------+\n",
            "|      Caucasian|Female|  5|                5|                      18|                  1|               1|                41|             0|              1|                0|               0|               0| diabetes| diabetes|   diabetes|               1|         None|     None|       No|         No|         No|            No|       No|       No|        No|     No|    No|         No|        NO|               2.0|6.151418279386793E-6|\n",
            "|      Caucasian|Female| 15|                1|                       1|                  7|               3|                59|             0|             18|                0|               0|               0|    other| diabetes|      other|               9|         None|     None|       No|         No|         No|            No|       No|       No|        No|     Up|    Ch|        Yes|       >30|               2.0|1.244264151966874E-5|\n",
            "|AfricanAmerican|Female| 25|                1|                       1|                  7|               2|                11|             5|             13|                2|               0|               1| pregnecy| diabetes|      other|               6|         None|     None|       No|         No|         No|            No|   Steady|       No|        No|     No|    No|        Yes|        NO|0.3333333333333333|5.172783553120712E-6|\n",
            "|      Caucasian|  Male| 35|                1|                       1|                  7|               2|                44|             1|             16|                0|               0|               0|    other| diabetes|circulatory|               7|         None|     None|       No|         No|         No|            No|       No|       No|        No|     Up|    Ch|        Yes|        NO|               2.0|9.786347262660807E-6|\n",
            "|      Caucasian|  Male| 45|                1|                       1|                  7|               1|                51|             0|              8|                0|               0|               0|neoplasms|neoplasms|   diabetes|               5|         None|     None|       No|         No|         No|            No|   Steady|       No|        No| Steady|    Ch|        Yes|        NO|               2.0|9.087322458185035E-6|\n",
            "+---------------+------+---+-----------------+------------------------+-------------------+----------------+------------------+--------------+---------------+-----------------+----------------+----------------+---------+---------+-----------+----------------+-------------+---------+---------+-----------+-----------+--------------+---------+---------+----------+-------+------+-----------+----------+------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "time: 6.27 s (started: 2023-10-16 11:17:45 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh5fdHLqr3D1"
      },
      "source": [
        "Now we need to transform the data into numbers so that we can work on them with ML models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj2U77sbr3D1",
        "outputId": "9ae31cce-ddf4-4d48-a7e7-d78841d674ef",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns:  ['age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'health_index', 'severity_of_disease']\n",
            "\n",
            "\n",
            "Categorical columns:  ['race', 'gender', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glipizide', 'glyburide', 'tolazamide', 'insulin', 'change', 'diabetesMed', 'readmitted']\n",
            "time: 491 ms (started: 2023-10-16 11:17:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# looking for categorical and numeric columns\n",
        "numeric_columns = list()\n",
        "categorical_columns = list()\n",
        "\n",
        "for col in df.columns:\n",
        "    if df.select(col).dtypes[0][1] != \"string\":\n",
        "        numeric_columns.append(col)\n",
        "    else:\n",
        "        categorical_columns.append(col)\n",
        "\n",
        "print(\"Numeric columns: \", numeric_columns)\n",
        "print(\"\\n\")\n",
        "print(\"Categorical columns: \", categorical_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RixFoXB8r3D1"
      },
      "source": [
        "A lot of features are strings, so I define a function wich maps string into numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leBD8ihQr3D1",
        "outputId": "a10c22bb-cbbd-4b12-8bfd-b4b418911481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 708 µs (started: 2023-10-16 11:17:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def categorical_to_numerical(col_name, col_out_name, df):\n",
        "    stringIndexer = StringIndexer(inputCol=col_name, outputCol=col_out_name)\n",
        "    df_new = stringIndexer.fit(df).transform(df)\n",
        "    return df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXwpI8Nwr3D1",
        "outputId": "d323aafe-e108-4ca8-ac3d-e4796e3f830c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 33 s (started: 2023-10-16 11:17:52 +00:00)\n"
          ]
        }
      ],
      "source": [
        "for col in categorical_columns:\n",
        "    new_name = col + \"_indexed\"\n",
        "    df = categorical_to_numerical(col, new_name, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTbv0Kycr3D1"
      },
      "source": [
        "Dropping old columns with strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xgybHuFr3D1",
        "outputId": "740d4fb4-b7e9-4397-c8fc-4c3784c24391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 282 ms (started: 2023-10-16 11:18:25 +00:00)\n"
          ]
        }
      ],
      "source": [
        "for col in categorical_columns:\n",
        "  df = df.drop(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaHFw3rvr3D1",
        "outputId": "86a4da6a-cc3b-403c-dc8f-122d7ccf0fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- admission_type_id: long (nullable = true)\n",
            " |-- discharge_disposition_id: long (nullable = true)\n",
            " |-- admission_source_id: long (nullable = true)\n",
            " |-- time_in_hospital: long (nullable = true)\n",
            " |-- num_lab_procedures: long (nullable = true)\n",
            " |-- num_procedures: long (nullable = true)\n",
            " |-- num_medications: long (nullable = true)\n",
            " |-- number_outpatient: long (nullable = true)\n",
            " |-- number_emergency: long (nullable = true)\n",
            " |-- number_inpatient: long (nullable = true)\n",
            " |-- number_diagnoses: long (nullable = true)\n",
            " |-- health_index: double (nullable = true)\n",
            " |-- severity_of_disease: double (nullable = true)\n",
            " |-- race_indexed: double (nullable = false)\n",
            " |-- gender_indexed: double (nullable = false)\n",
            " |-- diag_1_indexed: double (nullable = false)\n",
            " |-- diag_2_indexed: double (nullable = false)\n",
            " |-- diag_3_indexed: double (nullable = false)\n",
            " |-- max_glu_serum_indexed: double (nullable = false)\n",
            " |-- A1Cresult_indexed: double (nullable = false)\n",
            " |-- metformin_indexed: double (nullable = false)\n",
            " |-- repaglinide_indexed: double (nullable = false)\n",
            " |-- nateglinide_indexed: double (nullable = false)\n",
            " |-- chlorpropamide_indexed: double (nullable = false)\n",
            " |-- glipizide_indexed: double (nullable = false)\n",
            " |-- glyburide_indexed: double (nullable = false)\n",
            " |-- tolazamide_indexed: double (nullable = false)\n",
            " |-- insulin_indexed: double (nullable = false)\n",
            " |-- change_indexed: double (nullable = false)\n",
            " |-- diabetesMed_indexed: double (nullable = false)\n",
            " |-- readmitted_indexed: double (nullable = false)\n",
            "\n",
            "Features:  32\n",
            "time: 27.6 ms (started: 2023-10-16 11:18:25 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# New schema of numeric features\n",
        "df.printSchema()\n",
        "print('Features: ', len(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwvzJ-dAh68Z"
      },
      "source": [
        "Visualize the correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsFa41x6ip1A",
        "outputId": "45d04d75-3eae-4f05-a890-0590b5fb7ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-df85628b49cb>:8: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
            "  corr_matrix_df .style.background_gradient(cmap='coolwarm').set_precision(2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x796264cea410>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_f19a0_row0_col0, #T_f19a0_row1_col1, #T_f19a0_row2_col2, #T_f19a0_row3_col3, #T_f19a0_row4_col4, #T_f19a0_row5_col5, #T_f19a0_row6_col6, #T_f19a0_row7_col7, #T_f19a0_row8_col8, #T_f19a0_row9_col9, #T_f19a0_row10_col10, #T_f19a0_row11_col11, #T_f19a0_row12_col12, #T_f19a0_row13_col13, #T_f19a0_row14_col14, #T_f19a0_row15_col15, #T_f19a0_row16_col16, #T_f19a0_row17_col17, #T_f19a0_row18_col18, #T_f19a0_row19_col19, #T_f19a0_row20_col20, #T_f19a0_row21_col21, #T_f19a0_row22_col22, #T_f19a0_row23_col23, #T_f19a0_row24_col24, #T_f19a0_row25_col25, #T_f19a0_row26_col26, #T_f19a0_row27_col27, #T_f19a0_row28_col28, #T_f19a0_row29_col29, #T_f19a0_row30_col30, #T_f19a0_row31_col31 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col1, #T_f19a0_row6_col26, #T_f19a0_row8_col19, #T_f19a0_row9_col25, #T_f19a0_row12_col1, #T_f19a0_row13_col0, #T_f19a0_row15_col3, #T_f19a0_row17_col6, #T_f19a0_row18_col25, #T_f19a0_row19_col7, #T_f19a0_row20_col6, #T_f19a0_row23_col3, #T_f19a0_row24_col7, #T_f19a0_row25_col0, #T_f19a0_row27_col7, #T_f19a0_row27_col25, #T_f19a0_row31_col13 {\n",
              "  background-color: #6b8df0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col2, #T_f19a0_row6_col14, #T_f19a0_row10_col14, #T_f19a0_row13_col14, #T_f19a0_row13_col22, #T_f19a0_row15_col14, #T_f19a0_row19_col14, #T_f19a0_row21_col13 {\n",
              "  background-color: #5572df;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col3, #T_f19a0_row0_col7, #T_f19a0_row2_col31, #T_f19a0_row8_col1, #T_f19a0_row8_col7, #T_f19a0_row8_col21, #T_f19a0_row9_col11, #T_f19a0_row9_col21, #T_f19a0_row16_col18, #T_f19a0_row17_col18, #T_f19a0_row23_col31, #T_f19a0_row24_col21, #T_f19a0_row26_col7, #T_f19a0_row28_col3, #T_f19a0_row29_col5 {\n",
              "  background-color: #799cf8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col4, #T_f19a0_row2_col7, #T_f19a0_row5_col26, #T_f19a0_row11_col25, #T_f19a0_row14_col25, #T_f19a0_row23_col11, #T_f19a0_row24_col3, #T_f19a0_row25_col5, #T_f19a0_row28_col1, #T_f19a0_row29_col4 {\n",
              "  background-color: #6c8ff1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col5, #T_f19a0_row1_col2, #T_f19a0_row10_col13, #T_f19a0_row11_col21, #T_f19a0_row17_col25, #T_f19a0_row19_col26, #T_f19a0_row20_col26, #T_f19a0_row22_col0, #T_f19a0_row22_col5, #T_f19a0_row23_col1, #T_f19a0_row24_col25, #T_f19a0_row28_col16, #T_f19a0_row30_col31 {\n",
              "  background-color: #6a8bef;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col6, #T_f19a0_row3_col0, #T_f19a0_row4_col1, #T_f19a0_row4_col2, #T_f19a0_row8_col12, #T_f19a0_row10_col19, #T_f19a0_row12_col16, #T_f19a0_row14_col16, #T_f19a0_row17_col5, #T_f19a0_row24_col26, #T_f19a0_row26_col2, #T_f19a0_row27_col26, #T_f19a0_row28_col19, #T_f19a0_row31_col26 {\n",
              "  background-color: #6687ed;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col8, #T_f19a0_row1_col28, #T_f19a0_row9_col30, #T_f19a0_row10_col30, #T_f19a0_row23_col28, #T_f19a0_row31_col9 {\n",
              "  background-color: #a5c3fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row0_col9, #T_f19a0_row2_col6, #T_f19a0_row8_col3, #T_f19a0_row10_col5, #T_f19a0_row12_col26, #T_f19a0_row13_col26, #T_f19a0_row15_col1, #T_f19a0_row15_col26, #T_f19a0_row18_col1, #T_f19a0_row21_col30, #T_f19a0_row24_col6, #T_f19a0_row25_col3, #T_f19a0_row25_col6, #T_f19a0_row26_col6, #T_f19a0_row29_col3 {\n",
              "  background-color: #7093f3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col10, #T_f19a0_row1_col10, #T_f19a0_row11_col29, #T_f19a0_row23_col29 {\n",
              "  background-color: #b7cff9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row0_col11, #T_f19a0_row0_col30, #T_f19a0_row31_col8 {\n",
              "  background-color: #afcafc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row0_col12, #T_f19a0_row5_col12, #T_f19a0_row10_col31, #T_f19a0_row14_col10, #T_f19a0_row15_col10, #T_f19a0_row22_col12, #T_f19a0_row22_col29 {\n",
              "  background-color: #bcd2f7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row0_col13, #T_f19a0_row2_col25, #T_f19a0_row7_col0, #T_f19a0_row7_col16, #T_f19a0_row8_col6, #T_f19a0_row8_col16, #T_f19a0_row8_col26, #T_f19a0_row9_col1, #T_f19a0_row9_col19, #T_f19a0_row10_col25, #T_f19a0_row12_col14, #T_f19a0_row15_col11, #T_f19a0_row16_col6, #T_f19a0_row31_col0 {\n",
              "  background-color: #6788ee;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col14, #T_f19a0_row0_col17, #T_f19a0_row0_col18, #T_f19a0_row1_col5, #T_f19a0_row1_col20, #T_f19a0_row3_col1, #T_f19a0_row3_col6, #T_f19a0_row3_col16, #T_f19a0_row5_col19, #T_f19a0_row6_col3, #T_f19a0_row10_col12, #T_f19a0_row11_col24, #T_f19a0_row11_col27, #T_f19a0_row12_col8, #T_f19a0_row12_col9, #T_f19a0_row12_col10, #T_f19a0_row12_col11, #T_f19a0_row12_col31, #T_f19a0_row14_col0, #T_f19a0_row16_col15, #T_f19a0_row19_col13, #T_f19a0_row28_col2, #T_f19a0_row28_col24, #T_f19a0_row28_col27, #T_f19a0_row29_col30, #T_f19a0_row30_col4, #T_f19a0_row30_col7, #T_f19a0_row30_col21, #T_f19a0_row30_col22, #T_f19a0_row30_col23, #T_f19a0_row30_col24, #T_f19a0_row30_col25, #T_f19a0_row30_col26, #T_f19a0_row30_col27, #T_f19a0_row30_col28, #T_f19a0_row30_col29 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col15, #T_f19a0_row1_col3, #T_f19a0_row8_col27, #T_f19a0_row10_col20, #T_f19a0_row10_col27, #T_f19a0_row14_col27, #T_f19a0_row16_col0, #T_f19a0_row16_col24, #T_f19a0_row18_col27, #T_f19a0_row21_col24, #T_f19a0_row25_col24, #T_f19a0_row25_col27, #T_f19a0_row26_col27, #T_f19a0_row31_col27 {\n",
              "  background-color: #3c4ec2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col16, #T_f19a0_row1_col4, #T_f19a0_row1_col23, #T_f19a0_row2_col27, #T_f19a0_row3_col23, #T_f19a0_row7_col15, #T_f19a0_row9_col15, #T_f19a0_row10_col23, #T_f19a0_row11_col2, #T_f19a0_row14_col15, #T_f19a0_row17_col23, #T_f19a0_row18_col23 {\n",
              "  background-color: #445acc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col19, #T_f19a0_row8_col0, #T_f19a0_row10_col1, #T_f19a0_row10_col4, #T_f19a0_row18_col13, #T_f19a0_row20_col14, #T_f19a0_row22_col26, #T_f19a0_row23_col16, #T_f19a0_row26_col11, #T_f19a0_row30_col11 {\n",
              "  background-color: #6282ea;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col20, #T_f19a0_row1_col13, #T_f19a0_row3_col17, #T_f19a0_row3_col24, #T_f19a0_row4_col27, #T_f19a0_row7_col27, #T_f19a0_row8_col24, #T_f19a0_row9_col24, #T_f19a0_row9_col27, #T_f19a0_row10_col24, #T_f19a0_row12_col4, #T_f19a0_row13_col27, #T_f19a0_row14_col24, #T_f19a0_row16_col27, #T_f19a0_row17_col24, #T_f19a0_row17_col27, #T_f19a0_row18_col24, #T_f19a0_row19_col20, #T_f19a0_row19_col27, #T_f19a0_row22_col27, #T_f19a0_row23_col27, #T_f19a0_row24_col27, #T_f19a0_row26_col24, #T_f19a0_row30_col13 {\n",
              "  background-color: #3d50c3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col21, #T_f19a0_row2_col3, #T_f19a0_row12_col25, #T_f19a0_row14_col31, #T_f19a0_row16_col31, #T_f19a0_row18_col5, #T_f19a0_row20_col11, #T_f19a0_row23_col6, #T_f19a0_row26_col1, #T_f19a0_row26_col3, #T_f19a0_row30_col1, #T_f19a0_row30_col3 {\n",
              "  background-color: #6e90f2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col22, #T_f19a0_row2_col14, #T_f19a0_row4_col17, #T_f19a0_row4_col18, #T_f19a0_row6_col16, #T_f19a0_row7_col19, #T_f19a0_row10_col6, #T_f19a0_row10_col16, #T_f19a0_row14_col7, #T_f19a0_row15_col19, #T_f19a0_row17_col4, #T_f19a0_row19_col11, #T_f19a0_row21_col5, #T_f19a0_row29_col20, #T_f19a0_row30_col5 {\n",
              "  background-color: #5b7ae5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col23, #T_f19a0_row2_col20, #T_f19a0_row8_col18, #T_f19a0_row8_col22, #T_f19a0_row10_col17, #T_f19a0_row10_col18, #T_f19a0_row15_col0, #T_f19a0_row16_col4, #T_f19a0_row19_col17, #T_f19a0_row20_col19, #T_f19a0_row21_col0, #T_f19a0_row21_col22, #T_f19a0_row23_col2, #T_f19a0_row23_col20, #T_f19a0_row24_col4, #T_f19a0_row24_col20, #T_f19a0_row25_col2, #T_f19a0_row27_col15 {\n",
              "  background-color: #4c66d6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col24, #T_f19a0_row15_col4, #T_f19a0_row19_col5, #T_f19a0_row25_col23 {\n",
              "  background-color: #4358cb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col25, #T_f19a0_row5_col6, #T_f19a0_row6_col11, #T_f19a0_row15_col21, #T_f19a0_row22_col31, #T_f19a0_row25_col31, #T_f19a0_row27_col21, #T_f19a0_row31_col7 {\n",
              "  background-color: #7da0f9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col26, #T_f19a0_row2_col9, #T_f19a0_row7_col25, #T_f19a0_row7_col30, #T_f19a0_row15_col6, #T_f19a0_row19_col31, #T_f19a0_row23_col21 {\n",
              "  background-color: #80a3fa;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col27, #T_f19a0_row1_col27, #T_f19a0_row4_col24, #T_f19a0_row7_col24, #T_f19a0_row12_col27, #T_f19a0_row15_col17, #T_f19a0_row15_col27, #T_f19a0_row19_col24, #T_f19a0_row21_col27, #T_f19a0_row28_col0 {\n",
              "  background-color: #3f53c6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row0_col28, #T_f19a0_row31_col12 {\n",
              "  background-color: #8fb1fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row0_col29, #T_f19a0_row5_col30, #T_f19a0_row16_col8, #T_f19a0_row17_col8, #T_f19a0_row17_col16 {\n",
              "  background-color: #a3c2fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row0_col31, #T_f19a0_row20_col9, #T_f19a0_row20_col21, #T_f19a0_row21_col9, #T_f19a0_row28_col11 {\n",
              "  background-color: #85a8fc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col0, #T_f19a0_row2_col11, #T_f19a0_row3_col20, #T_f19a0_row22_col14, #T_f19a0_row22_col19, #T_f19a0_row24_col14, #T_f19a0_row27_col14 {\n",
              "  background-color: #5977e3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col6, #T_f19a0_row2_col28, #T_f19a0_row11_col4, #T_f19a0_row11_col5, #T_f19a0_row19_col9, #T_f19a0_row26_col28 {\n",
              "  background-color: #92b4fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col7, #T_f19a0_row7_col31, #T_f19a0_row12_col21, #T_f19a0_row13_col3, #T_f19a0_row13_col9, #T_f19a0_row13_col20, #T_f19a0_row23_col9 {\n",
              "  background-color: #89acfd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col8, #T_f19a0_row6_col28, #T_f19a0_row14_col30, #T_f19a0_row17_col28, #T_f19a0_row18_col28, #T_f19a0_row27_col30 {\n",
              "  background-color: #a9c6fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col9, #T_f19a0_row11_col6, #T_f19a0_row15_col9, #T_f19a0_row16_col21, #T_f19a0_row21_col7, #T_f19a0_row21_col25 {\n",
              "  background-color: #82a6fb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col11, #T_f19a0_row3_col4, #T_f19a0_row5_col17, #T_f19a0_row11_col16, #T_f19a0_row11_col23, #T_f19a0_row15_col22, #T_f19a0_row18_col0, #T_f19a0_row19_col18, #T_f19a0_row20_col0, #T_f19a0_row21_col15, #T_f19a0_row21_col23, #T_f19a0_row23_col22, #T_f19a0_row24_col15, #T_f19a0_row24_col22, #T_f19a0_row27_col22, #T_f19a0_row28_col15, #T_f19a0_row29_col17, #T_f19a0_row31_col18 {\n",
              "  background-color: #4b64d5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col12, #T_f19a0_row2_col10, #T_f19a0_row5_col28, #T_f19a0_row23_col12, #T_f19a0_row27_col10 {\n",
              "  background-color: #bfd3f6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col14, #T_f19a0_row7_col18, #T_f19a0_row8_col17, #T_f19a0_row11_col1, #T_f19a0_row11_col19, #T_f19a0_row18_col2, #T_f19a0_row28_col17, #T_f19a0_row31_col14 {\n",
              "  background-color: #506bda;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col15, #T_f19a0_row6_col22, #T_f19a0_row7_col23, #T_f19a0_row8_col14, #T_f19a0_row9_col17, #T_f19a0_row9_col18, #T_f19a0_row10_col0, #T_f19a0_row14_col11, #T_f19a0_row14_col18, #T_f19a0_row16_col2, #T_f19a0_row17_col2, #T_f19a0_row21_col4, #T_f19a0_row22_col2, #T_f19a0_row23_col4, #T_f19a0_row27_col20, #T_f19a0_row30_col17, #T_f19a0_row30_col18 {\n",
              "  background-color: #4e68d8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col16, #T_f19a0_row4_col21, #T_f19a0_row6_col9, #T_f19a0_row9_col12, #T_f19a0_row10_col7, #T_f19a0_row17_col21, #T_f19a0_row25_col7, #T_f19a0_row25_col30, #T_f19a0_row31_col3 {\n",
              "  background-color: #7ea1fa;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col17, #T_f19a0_row5_col2, #T_f19a0_row5_col18, #T_f19a0_row6_col0, #T_f19a0_row7_col2, #T_f19a0_row10_col2, #T_f19a0_row11_col17, #T_f19a0_row11_col20, #T_f19a0_row13_col1, #T_f19a0_row13_col16, #T_f19a0_row14_col2, #T_f19a0_row15_col16, #T_f19a0_row20_col22, #T_f19a0_row22_col20, #T_f19a0_row26_col15, #T_f19a0_row28_col22 {\n",
              "  background-color: #536edd;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col18, #T_f19a0_row3_col22, #T_f19a0_row5_col16, #T_f19a0_row6_col18, #T_f19a0_row7_col17, #T_f19a0_row9_col22, #T_f19a0_row10_col22, #T_f19a0_row13_col17, #T_f19a0_row14_col17, #T_f19a0_row20_col15, #T_f19a0_row21_col17, #T_f19a0_row25_col20, #T_f19a0_row25_col26, #T_f19a0_row26_col20, #T_f19a0_row28_col18, #T_f19a0_row29_col15 {\n",
              "  background-color: #4f69d9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col19, #T_f19a0_row4_col10, #T_f19a0_row10_col9, #T_f19a0_row20_col12 {\n",
              "  background-color: #cdd9ec;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col21, #T_f19a0_row10_col3, #T_f19a0_row26_col9, #T_f19a0_row30_col9 {\n",
              "  background-color: #81a4fb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col22, #T_f19a0_row2_col18, #T_f19a0_row2_col22, #T_f19a0_row2_col24, #T_f19a0_row3_col15, #T_f19a0_row6_col17, #T_f19a0_row9_col23, #T_f19a0_row13_col15, #T_f19a0_row13_col23, #T_f19a0_row16_col13, #T_f19a0_row16_col22, #T_f19a0_row17_col20, #T_f19a0_row19_col22, #T_f19a0_row20_col18, #T_f19a0_row21_col18, #T_f19a0_row22_col18, #T_f19a0_row23_col18, #T_f19a0_row24_col18, #T_f19a0_row25_col17, #T_f19a0_row25_col18, #T_f19a0_row25_col22, #T_f19a0_row31_col23 {\n",
              "  background-color: #485fd1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col24, #T_f19a0_row3_col18, #T_f19a0_row6_col24, #T_f19a0_row11_col14, #T_f19a0_row13_col19, #T_f19a0_row15_col24, #T_f19a0_row16_col20, #T_f19a0_row28_col30, #T_f19a0_row30_col20 {\n",
              "  background-color: #4055c8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col25, #T_f19a0_row3_col25, #T_f19a0_row4_col3, #T_f19a0_row6_col25, #T_f19a0_row6_col31, #T_f19a0_row8_col25, #T_f19a0_row9_col7, #T_f19a0_row17_col7, #T_f19a0_row17_col11, #T_f19a0_row19_col25, #T_f19a0_row20_col25, #T_f19a0_row21_col31, #T_f19a0_row22_col6, #T_f19a0_row24_col1, #T_f19a0_row25_col1, #T_f19a0_row27_col1, #T_f19a0_row27_col3, #T_f19a0_row27_col6, #T_f19a0_row29_col1, #T_f19a0_row29_col6 {\n",
              "  background-color: #6f92f3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col26, #T_f19a0_row3_col26, #T_f19a0_row10_col21, #T_f19a0_row14_col5, #T_f19a0_row14_col6, #T_f19a0_row21_col16, #T_f19a0_row22_col1, #T_f19a0_row22_col25, #T_f19a0_row23_col25, #T_f19a0_row25_col11, #T_f19a0_row26_col5, #T_f19a0_row31_col1 {\n",
              "  background-color: #688aef;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row1_col29, #T_f19a0_row3_col29, #T_f19a0_row6_col30, #T_f19a0_row8_col28, #T_f19a0_row14_col29, #T_f19a0_row16_col29, #T_f19a0_row16_col30, #T_f19a0_row17_col30, #T_f19a0_row19_col28 {\n",
              "  background-color: #adc9fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col30, #T_f19a0_row6_col29, #T_f19a0_row16_col28, #T_f19a0_row27_col29, #T_f19a0_row28_col12 {\n",
              "  background-color: #abc8fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row1_col31, #T_f19a0_row4_col26, #T_f19a0_row5_col25, #T_f19a0_row6_col5, #T_f19a0_row7_col26, #T_f19a0_row15_col31, #T_f19a0_row17_col1, #T_f19a0_row17_col31, #T_f19a0_row18_col11, #T_f19a0_row28_col4 {\n",
              "  background-color: #7597f6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col0, #T_f19a0_row2_col16, #T_f19a0_row3_col14, #T_f19a0_row5_col14, #T_f19a0_row10_col26, #T_f19a0_row16_col14, #T_f19a0_row17_col19, #T_f19a0_row18_col4, #T_f19a0_row18_col14, #T_f19a0_row22_col16, #T_f19a0_row24_col19, #T_f19a0_row26_col19, #T_f19a0_row28_col20, #T_f19a0_row29_col14 {\n",
              "  background-color: #5e7de7;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col1, #T_f19a0_row8_col11, #T_f19a0_row9_col3, #T_f19a0_row26_col30, #T_f19a0_row29_col13, #T_f19a0_row29_col31 {\n",
              "  background-color: #84a7fc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col4, #T_f19a0_row5_col0, #T_f19a0_row16_col26, #T_f19a0_row17_col14, #T_f19a0_row19_col16, #T_f19a0_row20_col4, #T_f19a0_row22_col13, #T_f19a0_row23_col0, #T_f19a0_row24_col0, #T_f19a0_row24_col16, #T_f19a0_row25_col19, #T_f19a0_row26_col13, #T_f19a0_row31_col4 {\n",
              "  background-color: #5f7fe8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col5, #T_f19a0_row2_col19, #T_f19a0_row4_col19, #T_f19a0_row9_col5, #T_f19a0_row9_col16, #T_f19a0_row15_col5, #T_f19a0_row15_col7, #T_f19a0_row16_col25, #T_f19a0_row18_col3, #T_f19a0_row18_col26, #T_f19a0_row21_col3, #T_f19a0_row21_col6, #T_f19a0_row24_col5, #T_f19a0_row24_col11, #T_f19a0_row25_col13, #T_f19a0_row27_col5, #T_f19a0_row27_col11, #T_f19a0_row28_col14, #T_f19a0_row30_col2, #T_f19a0_row30_col16, #T_f19a0_row31_col6 {\n",
              "  background-color: #6485ec;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col8, #T_f19a0_row3_col5, #T_f19a0_row5_col20, #T_f19a0_row9_col31, #T_f19a0_row13_col30 {\n",
              "  background-color: #96b7ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row2_col12 {\n",
              "  background-color: #c6d6f1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row2_col13, #T_f19a0_row4_col14, #T_f19a0_row4_col22, #T_f19a0_row9_col13, #T_f19a0_row11_col22, #T_f19a0_row23_col13, #T_f19a0_row23_col19, #T_f19a0_row26_col4, #T_f19a0_row27_col2, #T_f19a0_row29_col23, #T_f19a0_row30_col14 {\n",
              "  background-color: #5875e1;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col15, #T_f19a0_row7_col14, #T_f19a0_row14_col22, #T_f19a0_row17_col0, #T_f19a0_row17_col22, #T_f19a0_row18_col20, #T_f19a0_row18_col22, #T_f19a0_row19_col15, #T_f19a0_row22_col17, #T_f19a0_row24_col17, #T_f19a0_row27_col4, #T_f19a0_row27_col17 {\n",
              "  background-color: #4a63d3;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col17, #T_f19a0_row8_col2, #T_f19a0_row8_col15, #T_f19a0_row8_col20, #T_f19a0_row8_col23, #T_f19a0_row12_col18, #T_f19a0_row12_col22, #T_f19a0_row12_col23, #T_f19a0_row16_col3, #T_f19a0_row16_col23, #T_f19a0_row20_col17, #T_f19a0_row20_col23, #T_f19a0_row22_col23, #T_f19a0_row24_col23, #T_f19a0_row26_col17, #T_f19a0_row26_col22, #T_f19a0_row27_col23, #T_f19a0_row28_col23, #T_f19a0_row31_col15, #T_f19a0_row31_col17 {\n",
              "  background-color: #465ecf;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col21, #T_f19a0_row2_col26, #T_f19a0_row4_col0, #T_f19a0_row14_col21, #T_f19a0_row22_col21 {\n",
              "  background-color: #7b9ff9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col23, #T_f19a0_row4_col15, #T_f19a0_row5_col1, #T_f19a0_row9_col0, #T_f19a0_row12_col24, #T_f19a0_row15_col18, #T_f19a0_row18_col15, #T_f19a0_row19_col23, #T_f19a0_row26_col23, #T_f19a0_row29_col2 {\n",
              "  background-color: #4257c9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row2_col29, #T_f19a0_row5_col3, #T_f19a0_row5_col8, #T_f19a0_row11_col12, #T_f19a0_row21_col28, #T_f19a0_row24_col8, #T_f19a0_row26_col8, #T_f19a0_row27_col8, #T_f19a0_row31_col30 {\n",
              "  background-color: #9ebeff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row2_col30, #T_f19a0_row10_col8, #T_f19a0_row11_col7, #T_f19a0_row13_col6, #T_f19a0_row26_col10 {\n",
              "  background-color: #b9d0f9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col2, #T_f19a0_row3_col7, #T_f19a0_row5_col22, #T_f19a0_row12_col15, #T_f19a0_row14_col13, #T_f19a0_row15_col2, #T_f19a0_row15_col20, #T_f19a0_row16_col5, #T_f19a0_row16_col11, #T_f19a0_row20_col2, #T_f19a0_row21_col2, #T_f19a0_row25_col15, #T_f19a0_row28_col26, #T_f19a0_row29_col0, #T_f19a0_row31_col2, #T_f19a0_row31_col22 {\n",
              "  background-color: #516ddb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row3_col8, #T_f19a0_row3_col19, #T_f19a0_row8_col9, #T_f19a0_row18_col8, #T_f19a0_row23_col30, #T_f19a0_row25_col8, #T_f19a0_row26_col21, #T_f19a0_row29_col26 {\n",
              "  background-color: #a1c0ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col9, #T_f19a0_row25_col28, #T_f19a0_row28_col9, #T_f19a0_row30_col8 {\n",
              "  background-color: #9bbcff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col10, #T_f19a0_row13_col10 {\n",
              "  background-color: #cbd8ee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col11, #T_f19a0_row4_col31, #T_f19a0_row7_col1, #T_f19a0_row14_col9, #T_f19a0_row16_col9, #T_f19a0_row17_col9, #T_f19a0_row22_col9, #T_f19a0_row31_col11 {\n",
              "  background-color: #8badfd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col12, #T_f19a0_row7_col12, #T_f19a0_row8_col29, #T_f19a0_row10_col29 {\n",
              "  background-color: #b1cbfc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col13, #T_f19a0_row3_col21, #T_f19a0_row6_col21, #T_f19a0_row14_col3, #T_f19a0_row16_col7, #T_f19a0_row18_col7, #T_f19a0_row20_col31, #T_f19a0_row21_col1, #T_f19a0_row22_col3, #T_f19a0_row23_col7, #T_f19a0_row28_col6, #T_f19a0_row28_col21, #T_f19a0_row30_col6, #T_f19a0_row31_col21, #T_f19a0_row31_col25 {\n",
              "  background-color: #7295f4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row3_col27, #T_f19a0_row5_col24, #T_f19a0_row5_col27, #T_f19a0_row6_col27, #T_f19a0_row13_col24, #T_f19a0_row17_col15, #T_f19a0_row20_col24, #T_f19a0_row20_col27, #T_f19a0_row22_col24, #T_f19a0_row23_col24, #T_f19a0_row27_col24, #T_f19a0_row29_col24, #T_f19a0_row29_col27, #T_f19a0_row31_col24 {\n",
              "  background-color: #3e51c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row3_col28, #T_f19a0_row14_col28, #T_f19a0_row15_col29, #T_f19a0_row18_col30, #T_f19a0_row19_col3, #T_f19a0_row19_col29 {\n",
              "  background-color: #aec9fc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col30, #T_f19a0_row4_col11, #T_f19a0_row7_col8, #T_f19a0_row17_col29, #T_f19a0_row18_col29, #T_f19a0_row19_col8, #T_f19a0_row19_col30, #T_f19a0_row20_col5, #T_f19a0_row22_col28, #T_f19a0_row24_col29, #T_f19a0_row29_col25 {\n",
              "  background-color: #aac7fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row3_col31, #T_f19a0_row5_col9, #T_f19a0_row6_col4, #T_f19a0_row12_col6, #T_f19a0_row16_col1, #T_f19a0_row27_col9 {\n",
              "  background-color: #88abfd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col5, #T_f19a0_row15_col12, #T_f19a0_row29_col10 {\n",
              "  background-color: #c4d5f3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col6, #T_f19a0_row8_col30, #T_f19a0_row11_col0, #T_f19a0_row11_col30, #T_f19a0_row15_col28, #T_f19a0_row29_col8 {\n",
              "  background-color: #a6c4fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col7, #T_f19a0_row21_col29 {\n",
              "  background-color: #e9d5cb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col8, #T_f19a0_row4_col30, #T_f19a0_row15_col8, #T_f19a0_row21_col8, #T_f19a0_row22_col30 {\n",
              "  background-color: #9dbdff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col9, #T_f19a0_row5_col31, #T_f19a0_row10_col11, #T_f19a0_row24_col9, #T_f19a0_row25_col9, #T_f19a0_row28_col5 {\n",
              "  background-color: #86a9fc;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row4_col12, #T_f19a0_row7_col11, #T_f19a0_row9_col28, #T_f19a0_row11_col8, #T_f19a0_row11_col13, #T_f19a0_row12_col30, #T_f19a0_row13_col12, #T_f19a0_row20_col29, #T_f19a0_row29_col12 {\n",
              "  background-color: #b6cefa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col13 {\n",
              "  background-color: #efcebd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row4_col16, #T_f19a0_row8_col5, #T_f19a0_row9_col6, #T_f19a0_row11_col26, #T_f19a0_row12_col20, #T_f19a0_row14_col1, #T_f19a0_row14_col26, #T_f19a0_row17_col26, #T_f19a0_row23_col5, #T_f19a0_row23_col26, #T_f19a0_row29_col16, #T_f19a0_row29_col22, #T_f19a0_row31_col19 {\n",
              "  background-color: #6384eb;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row4_col20, #T_f19a0_row9_col26, #T_f19a0_row12_col5, #T_f19a0_row17_col3, #T_f19a0_row19_col0, #T_f19a0_row27_col16, #T_f19a0_row28_col25, #T_f19a0_row29_col19, #T_f19a0_row30_col0 {\n",
              "  background-color: #6180e9;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row4_col23, #T_f19a0_row5_col15, #T_f19a0_row6_col19, #T_f19a0_row6_col20, #T_f19a0_row8_col4, #T_f19a0_row9_col2, #T_f19a0_row9_col4, #T_f19a0_row9_col20, #T_f19a0_row11_col15, #T_f19a0_row12_col13, #T_f19a0_row12_col17, #T_f19a0_row12_col19, #T_f19a0_row14_col4, #T_f19a0_row14_col23, #T_f19a0_row22_col15, #T_f19a0_row23_col15, #T_f19a0_row23_col17, #T_f19a0_row27_col18, #T_f19a0_row29_col18 {\n",
              "  background-color: #4961d2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row4_col25, #T_f19a0_row24_col31, #T_f19a0_row27_col31, #T_f19a0_row29_col11 {\n",
              "  background-color: #779af7;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row4_col28, #T_f19a0_row4_col29, #T_f19a0_row16_col12 {\n",
              "  background-color: #c3d5f4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row5_col4, #T_f19a0_row6_col10, #T_f19a0_row19_col12, #T_f19a0_row21_col10 {\n",
              "  background-color: #b2ccfb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row5_col7, #T_f19a0_row5_col29, #T_f19a0_row10_col28, #T_f19a0_row30_col10 {\n",
              "  background-color: #bad0f8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row5_col10, #T_f19a0_row14_col12 {\n",
              "  background-color: #c7d7f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row5_col11, #T_f19a0_row14_col8 {\n",
              "  background-color: #94b6ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row5_col13 {\n",
              "  background-color: #d1493f;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row5_col21, #T_f19a0_row15_col25, #T_f19a0_row18_col6, #T_f19a0_row20_col7, #T_f19a0_row22_col7, #T_f19a0_row22_col11, #T_f19a0_row26_col0, #T_f19a0_row31_col5 {\n",
              "  background-color: #7396f5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row5_col23, #T_f19a0_row6_col23, #T_f19a0_row10_col15, #T_f19a0_row15_col23, #T_f19a0_row26_col18, #T_f19a0_row30_col15, #T_f19a0_row31_col20 {\n",
              "  background-color: #455cce;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row6_col1, #T_f19a0_row7_col21, #T_f19a0_row11_col3, #T_f19a0_row16_col17, #T_f19a0_row18_col16, #T_f19a0_row21_col26, #T_f19a0_row25_col21, #T_f19a0_row28_col13 {\n",
              "  background-color: #90b2fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row6_col2, #T_f19a0_row7_col3, #T_f19a0_row7_col20, #T_f19a0_row7_col22, #T_f19a0_row13_col2, #T_f19a0_row14_col20, #T_f19a0_row15_col13, #T_f19a0_row19_col4, #T_f19a0_row26_col25 {\n",
              "  background-color: #5470de;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row6_col7 {\n",
              "  background-color: #d7dce3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row6_col8 {\n",
              "  background-color: #98b9ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row6_col12, #T_f19a0_row28_col10 {\n",
              "  background-color: #cfdaea;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row6_col13, #T_f19a0_row15_col30, #T_f19a0_row24_col30, #T_f19a0_row28_col8 {\n",
              "  background-color: #a7c5fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row6_col15, #T_f19a0_row9_col14, #T_f19a0_row12_col2, #T_f19a0_row18_col19, #T_f19a0_row23_col14, #T_f19a0_row27_col0, #T_f19a0_row27_col19, #T_f19a0_row30_col19 {\n",
              "  background-color: #5d7ce6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row7_col4 {\n",
              "  background-color: #dbdcde;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col5, #T_f19a0_row9_col8, #T_f19a0_row31_col28 {\n",
              "  background-color: #b5cdfa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col6 {\n",
              "  background-color: #d8dce2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col9, #T_f19a0_row8_col31, #T_f19a0_row13_col31, #T_f19a0_row18_col9, #T_f19a0_row28_col31 {\n",
              "  background-color: #8caffe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col10 {\n",
              "  background-color: #ccd9ed;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col13 {\n",
              "  background-color: #f7ba9f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col28 {\n",
              "  background-color: #d9dce1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row7_col29 {\n",
              "  background-color: #dcdddd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row8_col10, #T_f19a0_row11_col10, #T_f19a0_row26_col29 {\n",
              "  background-color: #d3dbe7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row8_col13, #T_f19a0_row12_col3, #T_f19a0_row16_col19, #T_f19a0_row17_col13, #T_f19a0_row19_col2, #T_f19a0_row19_col6, #T_f19a0_row20_col1, #T_f19a0_row21_col14, #T_f19a0_row24_col2, #T_f19a0_row25_col14, #T_f19a0_row25_col16, #T_f19a0_row26_col16 {\n",
              "  background-color: #5a78e4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row9_col10 {\n",
              "  background-color: #ebd3c6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row9_col29, #T_f19a0_row20_col10, #T_f19a0_row20_col28, #T_f19a0_row28_col7, #T_f19a0_row29_col7, #T_f19a0_row31_col29 {\n",
              "  background-color: #b3cdfb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row11_col9 {\n",
              "  background-color: #97b8ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row11_col18, #T_f19a0_row12_col0, #T_f19a0_row12_col7, #T_f19a0_row13_col18, #T_f19a0_row14_col19, #T_f19a0_row20_col16, #T_f19a0_row21_col11, #T_f19a0_row21_col19, #T_f19a0_row21_col20, #T_f19a0_row22_col4, #T_f19a0_row24_col13, #T_f19a0_row25_col4, #T_f19a0_row26_col14, #T_f19a0_row27_col13, #T_f19a0_row31_col16 {\n",
              "  background-color: #5673e0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row11_col28, #T_f19a0_row16_col10, #T_f19a0_row25_col10 {\n",
              "  background-color: #bbd1f8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row11_col31, #T_f19a0_row20_col8 {\n",
              "  background-color: #9abbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row12_col28 {\n",
              "  background-color: #8db0fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row12_col29, #T_f19a0_row22_col8, #T_f19a0_row23_col8 {\n",
              "  background-color: #9fbfff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row13_col4 {\n",
              "  background-color: #edd2c3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row13_col5 {\n",
              "  background-color: #d0473d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row13_col7 {\n",
              "  background-color: #f7b396;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row13_col8, #T_f19a0_row20_col30, #T_f19a0_row24_col28, #T_f19a0_row27_col28 {\n",
              "  background-color: #a2c1ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row13_col11, #T_f19a0_row18_col10, #T_f19a0_row22_col10, #T_f19a0_row24_col12, #T_f19a0_row27_col12 {\n",
              "  background-color: #c1d4f4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row13_col21, #T_f19a0_row13_col25, #T_f19a0_row18_col17, #T_f19a0_row18_col21, #T_f19a0_row18_col31, #T_f19a0_row20_col3 {\n",
              "  background-color: #7a9df8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row13_col28 {\n",
              "  background-color: #cedaeb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row13_col29 {\n",
              "  background-color: #cad8ef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row17_col10, #T_f19a0_row25_col12 {\n",
              "  background-color: #c0d4f5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row17_col12, #T_f19a0_row18_col12, #T_f19a0_row23_col10, #T_f19a0_row24_col10 {\n",
              "  background-color: #bed2f6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row19_col1 {\n",
              "  background-color: #d5dbe5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row19_col10, #T_f19a0_row26_col12 {\n",
              "  background-color: #c5d6f2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row19_col21, #T_f19a0_row26_col31 {\n",
              "  background-color: #7699f6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_f19a0_row20_col13, #T_f19a0_row29_col9 {\n",
              "  background-color: #93b5fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row21_col12, #T_f19a0_row30_col12 {\n",
              "  background-color: #c9d7f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row25_col29 {\n",
              "  background-color: #d6dce4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row28_col29 {\n",
              "  background-color: #f49a7b;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row29_col21 {\n",
              "  background-color: #d2dbe8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row29_col28 {\n",
              "  background-color: #f59d7e;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_f19a0_row31_col10 {\n",
              "  background-color: #e8d6cc;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_f19a0\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_f19a0_level0_col0\" class=\"col_heading level0 col0\" >age</th>\n",
              "      <th id=\"T_f19a0_level0_col1\" class=\"col_heading level0 col1\" >admission_type_id</th>\n",
              "      <th id=\"T_f19a0_level0_col2\" class=\"col_heading level0 col2\" >discharge_disposition_id</th>\n",
              "      <th id=\"T_f19a0_level0_col3\" class=\"col_heading level0 col3\" >admission_source_id</th>\n",
              "      <th id=\"T_f19a0_level0_col4\" class=\"col_heading level0 col4\" >time_in_hospital</th>\n",
              "      <th id=\"T_f19a0_level0_col5\" class=\"col_heading level0 col5\" >num_lab_procedures</th>\n",
              "      <th id=\"T_f19a0_level0_col6\" class=\"col_heading level0 col6\" >num_procedures</th>\n",
              "      <th id=\"T_f19a0_level0_col7\" class=\"col_heading level0 col7\" >num_medications</th>\n",
              "      <th id=\"T_f19a0_level0_col8\" class=\"col_heading level0 col8\" >number_outpatient</th>\n",
              "      <th id=\"T_f19a0_level0_col9\" class=\"col_heading level0 col9\" >number_emergency</th>\n",
              "      <th id=\"T_f19a0_level0_col10\" class=\"col_heading level0 col10\" >number_inpatient</th>\n",
              "      <th id=\"T_f19a0_level0_col11\" class=\"col_heading level0 col11\" >number_diagnoses</th>\n",
              "      <th id=\"T_f19a0_level0_col12\" class=\"col_heading level0 col12\" >health_index</th>\n",
              "      <th id=\"T_f19a0_level0_col13\" class=\"col_heading level0 col13\" >severity_of_disease</th>\n",
              "      <th id=\"T_f19a0_level0_col14\" class=\"col_heading level0 col14\" >race_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col15\" class=\"col_heading level0 col15\" >gender_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col16\" class=\"col_heading level0 col16\" >diag_1_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col17\" class=\"col_heading level0 col17\" >diag_2_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col18\" class=\"col_heading level0 col18\" >diag_3_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col19\" class=\"col_heading level0 col19\" >max_glu_serum_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col20\" class=\"col_heading level0 col20\" >A1Cresult_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col21\" class=\"col_heading level0 col21\" >metformin_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col22\" class=\"col_heading level0 col22\" >repaglinide_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col23\" class=\"col_heading level0 col23\" >nateglinide_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col24\" class=\"col_heading level0 col24\" >chlorpropamide_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col25\" class=\"col_heading level0 col25\" >glipizide_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col26\" class=\"col_heading level0 col26\" >glyburide_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col27\" class=\"col_heading level0 col27\" >tolazamide_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col28\" class=\"col_heading level0 col28\" >insulin_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col29\" class=\"col_heading level0 col29\" >change_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col30\" class=\"col_heading level0 col30\" >diabetesMed_indexed</th>\n",
              "      <th id=\"T_f19a0_level0_col31\" class=\"col_heading level0 col31\" >readmitted_indexed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row0\" class=\"row_heading level0 row0\" >age</th>\n",
              "      <td id=\"T_f19a0_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row0_col1\" class=\"data row0 col1\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row0_col2\" class=\"data row0 col2\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row0_col3\" class=\"data row0 col3\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row0_col4\" class=\"data row0 col4\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row0_col5\" class=\"data row0 col5\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row0_col6\" class=\"data row0 col6\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row0_col7\" class=\"data row0 col7\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row0_col8\" class=\"data row0 col8\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row0_col9\" class=\"data row0 col9\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row0_col10\" class=\"data row0 col10\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row0_col11\" class=\"data row0 col11\" >0.24</td>\n",
              "      <td id=\"T_f19a0_row0_col12\" class=\"data row0 col12\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row0_col13\" class=\"data row0 col13\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row0_col14\" class=\"data row0 col14\" >-0.12</td>\n",
              "      <td id=\"T_f19a0_row0_col15\" class=\"data row0 col15\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row0_col16\" class=\"data row0 col16\" >-0.11</td>\n",
              "      <td id=\"T_f19a0_row0_col17\" class=\"data row0 col17\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row0_col18\" class=\"data row0 col18\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row0_col19\" class=\"data row0 col19\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row0_col20\" class=\"data row0 col20\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row0_col21\" class=\"data row0 col21\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row0_col22\" class=\"data row0 col22\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row0_col23\" class=\"data row0 col23\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row0_col24\" class=\"data row0 col24\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row0_col25\" class=\"data row0 col25\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row0_col26\" class=\"data row0 col26\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row0_col27\" class=\"data row0 col27\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row0_col28\" class=\"data row0 col28\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row0_col29\" class=\"data row0 col29\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row0_col30\" class=\"data row0 col30\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row0_col31\" class=\"data row0 col31\" >0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row1\" class=\"row_heading level0 row1\" >admission_type_id</th>\n",
              "      <td id=\"T_f19a0_row1_col0\" class=\"data row1 col0\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row1_col2\" class=\"data row1 col2\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row1_col3\" class=\"data row1 col3\" >-0.19</td>\n",
              "      <td id=\"T_f19a0_row1_col4\" class=\"data row1 col4\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row1_col5\" class=\"data row1 col5\" >-0.16</td>\n",
              "      <td id=\"T_f19a0_row1_col6\" class=\"data row1 col6\" >0.12</td>\n",
              "      <td id=\"T_f19a0_row1_col7\" class=\"data row1 col7\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row1_col8\" class=\"data row1 col8\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row1_col9\" class=\"data row1 col9\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row1_col10\" class=\"data row1 col10\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row1_col11\" class=\"data row1 col11\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row1_col12\" class=\"data row1 col12\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col13\" class=\"data row1 col13\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row1_col14\" class=\"data row1 col14\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row1_col15\" class=\"data row1 col15\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col16\" class=\"data row1 col16\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row1_col17\" class=\"data row1 col17\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row1_col18\" class=\"data row1 col18\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row1_col19\" class=\"data row1 col19\" >0.37</td>\n",
              "      <td id=\"T_f19a0_row1_col20\" class=\"data row1 col20\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row1_col21\" class=\"data row1 col21\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row1_col22\" class=\"data row1 col22\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row1_col23\" class=\"data row1 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col24\" class=\"data row1 col24\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col25\" class=\"data row1 col25\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col26\" class=\"data row1 col26\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row1_col27\" class=\"data row1 col27\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col28\" class=\"data row1 col28\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row1_col29\" class=\"data row1 col29\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row1_col30\" class=\"data row1 col30\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row1_col31\" class=\"data row1 col31\" >-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row2\" class=\"row_heading level0 row2\" >discharge_disposition_id</th>\n",
              "      <td id=\"T_f19a0_row2_col0\" class=\"data row2 col0\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row2_col1\" class=\"data row2 col1\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row2_col3\" class=\"data row2 col3\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col4\" class=\"data row2 col4\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row2_col5\" class=\"data row2 col5\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col6\" class=\"data row2 col6\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row2_col7\" class=\"data row2 col7\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col8\" class=\"data row2 col8\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row2_col9\" class=\"data row2 col9\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row2_col10\" class=\"data row2 col10\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col11\" class=\"data row2 col11\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row2_col12\" class=\"data row2 col12\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row2_col13\" class=\"data row2 col13\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row2_col14\" class=\"data row2 col14\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col15\" class=\"data row2 col15\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col16\" class=\"data row2 col16\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row2_col17\" class=\"data row2 col17\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row2_col18\" class=\"data row2 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row2_col19\" class=\"data row2 col19\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row2_col20\" class=\"data row2 col20\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col21\" class=\"data row2 col21\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row2_col22\" class=\"data row2 col22\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row2_col23\" class=\"data row2 col23\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row2_col24\" class=\"data row2 col24\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row2_col25\" class=\"data row2 col25\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row2_col26\" class=\"data row2 col26\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row2_col27\" class=\"data row2 col27\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row2_col28\" class=\"data row2 col28\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row2_col29\" class=\"data row2 col29\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row2_col30\" class=\"data row2 col30\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row2_col31\" class=\"data row2 col31\" >-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row3\" class=\"row_heading level0 row3\" >admission_source_id</th>\n",
              "      <td id=\"T_f19a0_row3_col0\" class=\"data row3 col0\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row3_col1\" class=\"data row3 col1\" >-0.19</td>\n",
              "      <td id=\"T_f19a0_row3_col2\" class=\"data row3 col2\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row3_col4\" class=\"data row3 col4\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row3_col5\" class=\"data row3 col5\" >0.16</td>\n",
              "      <td id=\"T_f19a0_row3_col6\" class=\"data row3 col6\" >-0.20</td>\n",
              "      <td id=\"T_f19a0_row3_col7\" class=\"data row3 col7\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row3_col8\" class=\"data row3 col8\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col9\" class=\"data row3 col9\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row3_col10\" class=\"data row3 col10\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row3_col11\" class=\"data row3 col11\" >0.12</td>\n",
              "      <td id=\"T_f19a0_row3_col12\" class=\"data row3 col12\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row3_col13\" class=\"data row3 col13\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row3_col14\" class=\"data row3 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col15\" class=\"data row3 col15\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col16\" class=\"data row3 col16\" >-0.15</td>\n",
              "      <td id=\"T_f19a0_row3_col17\" class=\"data row3 col17\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row3_col18\" class=\"data row3 col18\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row3_col19\" class=\"data row3 col19\" >0.22</td>\n",
              "      <td id=\"T_f19a0_row3_col20\" class=\"data row3 col20\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row3_col21\" class=\"data row3 col21\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row3_col22\" class=\"data row3 col22\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col23\" class=\"data row3 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col24\" class=\"data row3 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col25\" class=\"data row3 col25\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col26\" class=\"data row3 col26\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row3_col27\" class=\"data row3 col27\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row3_col28\" class=\"data row3 col28\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row3_col29\" class=\"data row3 col29\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row3_col30\" class=\"data row3 col30\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row3_col31\" class=\"data row3 col31\" >0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row4\" class=\"row_heading level0 row4\" >time_in_hospital</th>\n",
              "      <td id=\"T_f19a0_row4_col0\" class=\"data row4 col0\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row4_col1\" class=\"data row4 col1\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row4_col2\" class=\"data row4 col2\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row4_col3\" class=\"data row4 col3\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row4_col5\" class=\"data row4 col5\" >0.32</td>\n",
              "      <td id=\"T_f19a0_row4_col6\" class=\"data row4 col6\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row4_col7\" class=\"data row4 col7\" >0.46</td>\n",
              "      <td id=\"T_f19a0_row4_col8\" class=\"data row4 col8\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row4_col9\" class=\"data row4 col9\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row4_col10\" class=\"data row4 col10\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row4_col11\" class=\"data row4 col11\" >0.22</td>\n",
              "      <td id=\"T_f19a0_row4_col12\" class=\"data row4 col12\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row4_col13\" class=\"data row4 col13\" >0.54</td>\n",
              "      <td id=\"T_f19a0_row4_col14\" class=\"data row4 col14\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row4_col15\" class=\"data row4 col15\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row4_col16\" class=\"data row4 col16\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row4_col17\" class=\"data row4 col17\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row4_col18\" class=\"data row4 col18\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row4_col19\" class=\"data row4 col19\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row4_col20\" class=\"data row4 col20\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row4_col21\" class=\"data row4 col21\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row4_col22\" class=\"data row4 col22\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row4_col23\" class=\"data row4 col23\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row4_col24\" class=\"data row4 col24\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row4_col25\" class=\"data row4 col25\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row4_col26\" class=\"data row4 col26\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row4_col27\" class=\"data row4 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row4_col28\" class=\"data row4 col28\" >0.13</td>\n",
              "      <td id=\"T_f19a0_row4_col29\" class=\"data row4 col29\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row4_col30\" class=\"data row4 col30\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row4_col31\" class=\"data row4 col31\" >0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row5\" class=\"row_heading level0 row5\" >num_lab_procedures</th>\n",
              "      <td id=\"T_f19a0_row5_col0\" class=\"data row5 col0\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row5_col1\" class=\"data row5 col1\" >-0.16</td>\n",
              "      <td id=\"T_f19a0_row5_col2\" class=\"data row5 col2\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row5_col3\" class=\"data row5 col3\" >0.16</td>\n",
              "      <td id=\"T_f19a0_row5_col4\" class=\"data row5 col4\" >0.32</td>\n",
              "      <td id=\"T_f19a0_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row5_col6\" class=\"data row5 col6\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row5_col7\" class=\"data row5 col7\" >0.27</td>\n",
              "      <td id=\"T_f19a0_row5_col8\" class=\"data row5 col8\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row5_col9\" class=\"data row5 col9\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row5_col10\" class=\"data row5 col10\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row5_col11\" class=\"data row5 col11\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row5_col12\" class=\"data row5 col12\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row5_col13\" class=\"data row5 col13\" >0.91</td>\n",
              "      <td id=\"T_f19a0_row5_col14\" class=\"data row5 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row5_col15\" class=\"data row5 col15\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row5_col16\" class=\"data row5 col16\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row5_col17\" class=\"data row5 col17\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row5_col18\" class=\"data row5 col18\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row5_col19\" class=\"data row5 col19\" >-0.12</td>\n",
              "      <td id=\"T_f19a0_row5_col20\" class=\"data row5 col20\" >0.23</td>\n",
              "      <td id=\"T_f19a0_row5_col21\" class=\"data row5 col21\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row5_col22\" class=\"data row5 col22\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row5_col23\" class=\"data row5 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row5_col24\" class=\"data row5 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row5_col25\" class=\"data row5 col25\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row5_col26\" class=\"data row5 col26\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row5_col27\" class=\"data row5 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row5_col28\" class=\"data row5 col28\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row5_col29\" class=\"data row5 col29\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row5_col30\" class=\"data row5 col30\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row5_col31\" class=\"data row5 col31\" >0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row6\" class=\"row_heading level0 row6\" >num_procedures</th>\n",
              "      <td id=\"T_f19a0_row6_col0\" class=\"data row6 col0\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row6_col1\" class=\"data row6 col1\" >0.12</td>\n",
              "      <td id=\"T_f19a0_row6_col2\" class=\"data row6 col2\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col3\" class=\"data row6 col3\" >-0.20</td>\n",
              "      <td id=\"T_f19a0_row6_col4\" class=\"data row6 col4\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row6_col5\" class=\"data row6 col5\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row6_col7\" class=\"data row6 col7\" >0.38</td>\n",
              "      <td id=\"T_f19a0_row6_col8\" class=\"data row6 col8\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row6_col9\" class=\"data row6 col9\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row6_col10\" class=\"data row6 col10\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row6_col11\" class=\"data row6 col11\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row6_col12\" class=\"data row6 col12\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row6_col13\" class=\"data row6 col13\" >0.26</td>\n",
              "      <td id=\"T_f19a0_row6_col14\" class=\"data row6 col14\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row6_col15\" class=\"data row6 col15\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row6_col16\" class=\"data row6 col16\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row6_col17\" class=\"data row6 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col18\" class=\"data row6 col18\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row6_col19\" class=\"data row6 col19\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row6_col20\" class=\"data row6 col20\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col21\" class=\"data row6 col21\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row6_col22\" class=\"data row6 col22\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row6_col23\" class=\"data row6 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row6_col24\" class=\"data row6 col24\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col25\" class=\"data row6 col25\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col26\" class=\"data row6 col26\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col27\" class=\"data row6 col27\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row6_col28\" class=\"data row6 col28\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col29\" class=\"data row6 col29\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row6_col30\" class=\"data row6 col30\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row6_col31\" class=\"data row6 col31\" >-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row7\" class=\"row_heading level0 row7\" >num_medications</th>\n",
              "      <td id=\"T_f19a0_row7_col0\" class=\"data row7 col0\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row7_col1\" class=\"data row7 col1\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row7_col2\" class=\"data row7 col2\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row7_col3\" class=\"data row7 col3\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row7_col4\" class=\"data row7 col4\" >0.46</td>\n",
              "      <td id=\"T_f19a0_row7_col5\" class=\"data row7 col5\" >0.27</td>\n",
              "      <td id=\"T_f19a0_row7_col6\" class=\"data row7 col6\" >0.38</td>\n",
              "      <td id=\"T_f19a0_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row7_col8\" class=\"data row7 col8\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row7_col9\" class=\"data row7 col9\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row7_col10\" class=\"data row7 col10\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row7_col11\" class=\"data row7 col11\" >0.26</td>\n",
              "      <td id=\"T_f19a0_row7_col12\" class=\"data row7 col12\" >-0.08</td>\n",
              "      <td id=\"T_f19a0_row7_col13\" class=\"data row7 col13\" >0.62</td>\n",
              "      <td id=\"T_f19a0_row7_col14\" class=\"data row7 col14\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row7_col15\" class=\"data row7 col15\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row7_col16\" class=\"data row7 col16\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row7_col17\" class=\"data row7 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row7_col18\" class=\"data row7 col18\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row7_col19\" class=\"data row7 col19\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row7_col20\" class=\"data row7 col20\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row7_col21\" class=\"data row7 col21\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row7_col22\" class=\"data row7 col22\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row7_col23\" class=\"data row7 col23\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row7_col24\" class=\"data row7 col24\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row7_col25\" class=\"data row7 col25\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row7_col26\" class=\"data row7 col26\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row7_col27\" class=\"data row7 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row7_col28\" class=\"data row7 col28\" >0.24</td>\n",
              "      <td id=\"T_f19a0_row7_col29\" class=\"data row7 col29\" >0.25</td>\n",
              "      <td id=\"T_f19a0_row7_col30\" class=\"data row7 col30\" >-0.18</td>\n",
              "      <td id=\"T_f19a0_row7_col31\" class=\"data row7 col31\" >0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row8\" class=\"row_heading level0 row8\" >number_outpatient</th>\n",
              "      <td id=\"T_f19a0_row8_col0\" class=\"data row8 col0\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row8_col1\" class=\"data row8 col1\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row8_col2\" class=\"data row8 col2\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row8_col3\" class=\"data row8 col3\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col4\" class=\"data row8 col4\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col5\" class=\"data row8 col5\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col6\" class=\"data row8 col6\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row8_col7\" class=\"data row8 col7\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row8_col9\" class=\"data row8 col9\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row8_col10\" class=\"data row8 col10\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row8_col11\" class=\"data row8 col11\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row8_col12\" class=\"data row8 col12\" >-0.43</td>\n",
              "      <td id=\"T_f19a0_row8_col13\" class=\"data row8 col13\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col14\" class=\"data row8 col14\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row8_col15\" class=\"data row8 col15\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col16\" class=\"data row8 col16\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row8_col17\" class=\"data row8 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col18\" class=\"data row8 col18\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col19\" class=\"data row8 col19\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row8_col20\" class=\"data row8 col20\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row8_col21\" class=\"data row8 col21\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col22\" class=\"data row8 col22\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row8_col23\" class=\"data row8 col23\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row8_col24\" class=\"data row8 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col25\" class=\"data row8 col25\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col26\" class=\"data row8 col26\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row8_col27\" class=\"data row8 col27\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row8_col28\" class=\"data row8 col28\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row8_col29\" class=\"data row8 col29\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row8_col30\" class=\"data row8 col30\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row8_col31\" class=\"data row8 col31\" >0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row9\" class=\"row_heading level0 row9\" >number_emergency</th>\n",
              "      <td id=\"T_f19a0_row9_col0\" class=\"data row9 col0\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row9_col1\" class=\"data row9 col1\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row9_col2\" class=\"data row9 col2\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row9_col3\" class=\"data row9 col3\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row9_col4\" class=\"data row9 col4\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col5\" class=\"data row9 col5\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row9_col6\" class=\"data row9 col6\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row9_col7\" class=\"data row9 col7\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col8\" class=\"data row9 col8\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row9_col10\" class=\"data row9 col10\" >0.27</td>\n",
              "      <td id=\"T_f19a0_row9_col11\" class=\"data row9 col11\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row9_col12\" class=\"data row9 col12\" >-0.31</td>\n",
              "      <td id=\"T_f19a0_row9_col13\" class=\"data row9 col13\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row9_col14\" class=\"data row9 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col15\" class=\"data row9 col15\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row9_col16\" class=\"data row9 col16\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col17\" class=\"data row9 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col18\" class=\"data row9 col18\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col19\" class=\"data row9 col19\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row9_col20\" class=\"data row9 col20\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col21\" class=\"data row9 col21\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col22\" class=\"data row9 col22\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col23\" class=\"data row9 col23\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row9_col24\" class=\"data row9 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row9_col25\" class=\"data row9 col25\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row9_col26\" class=\"data row9 col26\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row9_col27\" class=\"data row9 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row9_col28\" class=\"data row9 col28\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row9_col29\" class=\"data row9 col29\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row9_col30\" class=\"data row9 col30\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row9_col31\" class=\"data row9 col31\" >0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row10\" class=\"row_heading level0 row10\" >number_inpatient</th>\n",
              "      <td id=\"T_f19a0_row10_col0\" class=\"data row10 col0\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row10_col1\" class=\"data row10 col1\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row10_col2\" class=\"data row10 col2\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row10_col3\" class=\"data row10 col3\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row10_col4\" class=\"data row10 col4\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row10_col5\" class=\"data row10 col5\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row10_col6\" class=\"data row10 col6\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row10_col7\" class=\"data row10 col7\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row10_col8\" class=\"data row10 col8\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row10_col9\" class=\"data row10 col9\" >0.27</td>\n",
              "      <td id=\"T_f19a0_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row10_col11\" class=\"data row10 col11\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row10_col12\" class=\"data row10 col12\" >-0.66</td>\n",
              "      <td id=\"T_f19a0_row10_col13\" class=\"data row10 col13\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row10_col14\" class=\"data row10 col14\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row10_col15\" class=\"data row10 col15\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row10_col16\" class=\"data row10 col16\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row10_col17\" class=\"data row10 col17\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row10_col18\" class=\"data row10 col18\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row10_col19\" class=\"data row10 col19\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row10_col20\" class=\"data row10 col20\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row10_col21\" class=\"data row10 col21\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row10_col22\" class=\"data row10 col22\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row10_col23\" class=\"data row10 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row10_col24\" class=\"data row10 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row10_col25\" class=\"data row10 col25\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row10_col26\" class=\"data row10 col26\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row10_col27\" class=\"data row10 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row10_col28\" class=\"data row10 col28\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row10_col29\" class=\"data row10 col29\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row10_col30\" class=\"data row10 col30\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row10_col31\" class=\"data row10 col31\" >0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row11\" class=\"row_heading level0 row11\" >number_diagnoses</th>\n",
              "      <td id=\"T_f19a0_row11_col0\" class=\"data row11 col0\" >0.24</td>\n",
              "      <td id=\"T_f19a0_row11_col1\" class=\"data row11 col1\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row11_col2\" class=\"data row11 col2\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row11_col3\" class=\"data row11 col3\" >0.12</td>\n",
              "      <td id=\"T_f19a0_row11_col4\" class=\"data row11 col4\" >0.22</td>\n",
              "      <td id=\"T_f19a0_row11_col5\" class=\"data row11 col5\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row11_col6\" class=\"data row11 col6\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row11_col7\" class=\"data row11 col7\" >0.26</td>\n",
              "      <td id=\"T_f19a0_row11_col8\" class=\"data row11 col8\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row11_col9\" class=\"data row11 col9\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row11_col10\" class=\"data row11 col10\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row11_col12\" class=\"data row11 col12\" >-0.17</td>\n",
              "      <td id=\"T_f19a0_row11_col13\" class=\"data row11 col13\" >0.31</td>\n",
              "      <td id=\"T_f19a0_row11_col14\" class=\"data row11 col14\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row11_col15\" class=\"data row11 col15\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row11_col16\" class=\"data row11 col16\" >-0.08</td>\n",
              "      <td id=\"T_f19a0_row11_col17\" class=\"data row11 col17\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row11_col18\" class=\"data row11 col18\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row11_col19\" class=\"data row11 col19\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row11_col20\" class=\"data row11 col20\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row11_col21\" class=\"data row11 col21\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row11_col22\" class=\"data row11 col22\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row11_col23\" class=\"data row11 col23\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row11_col24\" class=\"data row11 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row11_col25\" class=\"data row11 col25\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row11_col26\" class=\"data row11 col26\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row11_col27\" class=\"data row11 col27\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row11_col28\" class=\"data row11 col28\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row11_col29\" class=\"data row11 col29\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row11_col30\" class=\"data row11 col30\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row11_col31\" class=\"data row11 col31\" >0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row12\" class=\"row_heading level0 row12\" >health_index</th>\n",
              "      <td id=\"T_f19a0_row12_col0\" class=\"data row12 col0\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col1\" class=\"data row12 col1\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col2\" class=\"data row12 col2\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row12_col3\" class=\"data row12 col3\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row12_col4\" class=\"data row12 col4\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row12_col5\" class=\"data row12 col5\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col6\" class=\"data row12 col6\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row12_col7\" class=\"data row12 col7\" >-0.08</td>\n",
              "      <td id=\"T_f19a0_row12_col8\" class=\"data row12 col8\" >-0.43</td>\n",
              "      <td id=\"T_f19a0_row12_col9\" class=\"data row12 col9\" >-0.31</td>\n",
              "      <td id=\"T_f19a0_row12_col10\" class=\"data row12 col10\" >-0.66</td>\n",
              "      <td id=\"T_f19a0_row12_col11\" class=\"data row12 col11\" >-0.17</td>\n",
              "      <td id=\"T_f19a0_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row12_col13\" class=\"data row12 col13\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row12_col14\" class=\"data row12 col14\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row12_col15\" class=\"data row12 col15\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row12_col16\" class=\"data row12 col16\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col17\" class=\"data row12 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col18\" class=\"data row12 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col19\" class=\"data row12 col19\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row12_col20\" class=\"data row12 col20\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row12_col21\" class=\"data row12 col21\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row12_col22\" class=\"data row12 col22\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row12_col23\" class=\"data row12 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row12_col24\" class=\"data row12 col24\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col25\" class=\"data row12 col25\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row12_col26\" class=\"data row12 col26\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row12_col27\" class=\"data row12 col27\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row12_col28\" class=\"data row12 col28\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row12_col29\" class=\"data row12 col29\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row12_col30\" class=\"data row12 col30\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row12_col31\" class=\"data row12 col31\" >-0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row13\" class=\"row_heading level0 row13\" >severity_of_disease</th>\n",
              "      <td id=\"T_f19a0_row13_col0\" class=\"data row13 col0\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row13_col1\" class=\"data row13 col1\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row13_col2\" class=\"data row13 col2\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row13_col3\" class=\"data row13 col3\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row13_col4\" class=\"data row13 col4\" >0.54</td>\n",
              "      <td id=\"T_f19a0_row13_col5\" class=\"data row13 col5\" >0.91</td>\n",
              "      <td id=\"T_f19a0_row13_col6\" class=\"data row13 col6\" >0.26</td>\n",
              "      <td id=\"T_f19a0_row13_col7\" class=\"data row13 col7\" >0.62</td>\n",
              "      <td id=\"T_f19a0_row13_col8\" class=\"data row13 col8\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row13_col9\" class=\"data row13 col9\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row13_col10\" class=\"data row13 col10\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row13_col11\" class=\"data row13 col11\" >0.31</td>\n",
              "      <td id=\"T_f19a0_row13_col12\" class=\"data row13 col12\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row13_col14\" class=\"data row13 col14\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row13_col15\" class=\"data row13 col15\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row13_col16\" class=\"data row13 col16\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row13_col17\" class=\"data row13 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row13_col18\" class=\"data row13 col18\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row13_col19\" class=\"data row13 col19\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row13_col20\" class=\"data row13 col20\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row13_col21\" class=\"data row13 col21\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row13_col22\" class=\"data row13 col22\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row13_col23\" class=\"data row13 col23\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row13_col24\" class=\"data row13 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row13_col25\" class=\"data row13 col25\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row13_col26\" class=\"data row13 col26\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row13_col27\" class=\"data row13 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row13_col28\" class=\"data row13 col28\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row13_col29\" class=\"data row13 col29\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row13_col30\" class=\"data row13 col30\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row13_col31\" class=\"data row13 col31\" >0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row14\" class=\"row_heading level0 row14\" >race_indexed</th>\n",
              "      <td id=\"T_f19a0_row14_col0\" class=\"data row14 col0\" >-0.12</td>\n",
              "      <td id=\"T_f19a0_row14_col1\" class=\"data row14 col1\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row14_col2\" class=\"data row14 col2\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row14_col3\" class=\"data row14 col3\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col4\" class=\"data row14 col4\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col5\" class=\"data row14 col5\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col6\" class=\"data row14 col6\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col7\" class=\"data row14 col7\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row14_col8\" class=\"data row14 col8\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row14_col9\" class=\"data row14 col9\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col10\" class=\"data row14 col10\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col11\" class=\"data row14 col11\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row14_col12\" class=\"data row14 col12\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row14_col13\" class=\"data row14 col13\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row14_col15\" class=\"data row14 col15\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col16\" class=\"data row14 col16\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col17\" class=\"data row14 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col18\" class=\"data row14 col18\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col19\" class=\"data row14 col19\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col20\" class=\"data row14 col20\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col21\" class=\"data row14 col21\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row14_col22\" class=\"data row14 col22\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col23\" class=\"data row14 col23\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col24\" class=\"data row14 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row14_col25\" class=\"data row14 col25\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row14_col26\" class=\"data row14 col26\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row14_col27\" class=\"data row14 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row14_col28\" class=\"data row14 col28\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row14_col29\" class=\"data row14 col29\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col30\" class=\"data row14 col30\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row14_col31\" class=\"data row14 col31\" >-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row15\" class=\"row_heading level0 row15\" >gender_indexed</th>\n",
              "      <td id=\"T_f19a0_row15_col0\" class=\"data row15 col0\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row15_col1\" class=\"data row15 col1\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row15_col2\" class=\"data row15 col2\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col3\" class=\"data row15 col3\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row15_col4\" class=\"data row15 col4\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row15_col5\" class=\"data row15 col5\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col6\" class=\"data row15 col6\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row15_col7\" class=\"data row15 col7\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col8\" class=\"data row15 col8\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row15_col9\" class=\"data row15 col9\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col10\" class=\"data row15 col10\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col11\" class=\"data row15 col11\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col12\" class=\"data row15 col12\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row15_col13\" class=\"data row15 col13\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row15_col14\" class=\"data row15 col14\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row15_col16\" class=\"data row15 col16\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row15_col17\" class=\"data row15 col17\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row15_col18\" class=\"data row15 col18\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row15_col19\" class=\"data row15 col19\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col20\" class=\"data row15 col20\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row15_col21\" class=\"data row15 col21\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col22\" class=\"data row15 col22\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col23\" class=\"data row15 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col24\" class=\"data row15 col24\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col25\" class=\"data row15 col25\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col26\" class=\"data row15 col26\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row15_col27\" class=\"data row15 col27\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row15_col28\" class=\"data row15 col28\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row15_col29\" class=\"data row15 col29\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col30\" class=\"data row15 col30\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row15_col31\" class=\"data row15 col31\" >-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row16\" class=\"row_heading level0 row16\" >diag_1_indexed</th>\n",
              "      <td id=\"T_f19a0_row16_col0\" class=\"data row16 col0\" >-0.11</td>\n",
              "      <td id=\"T_f19a0_row16_col1\" class=\"data row16 col1\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row16_col2\" class=\"data row16 col2\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col3\" class=\"data row16 col3\" >-0.15</td>\n",
              "      <td id=\"T_f19a0_row16_col4\" class=\"data row16 col4\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row16_col5\" class=\"data row16 col5\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row16_col6\" class=\"data row16 col6\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col7\" class=\"data row16 col7\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col8\" class=\"data row16 col8\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col9\" class=\"data row16 col9\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col10\" class=\"data row16 col10\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col11\" class=\"data row16 col11\" >-0.08</td>\n",
              "      <td id=\"T_f19a0_row16_col12\" class=\"data row16 col12\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col13\" class=\"data row16 col13\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row16_col14\" class=\"data row16 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col15\" class=\"data row16 col15\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row16_col17\" class=\"data row16 col17\" >0.22</td>\n",
              "      <td id=\"T_f19a0_row16_col18\" class=\"data row16 col18\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row16_col19\" class=\"data row16 col19\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col20\" class=\"data row16 col20\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row16_col21\" class=\"data row16 col21\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col22\" class=\"data row16 col22\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col23\" class=\"data row16 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row16_col24\" class=\"data row16 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col25\" class=\"data row16 col25\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row16_col26\" class=\"data row16 col26\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row16_col27\" class=\"data row16 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row16_col28\" class=\"data row16 col28\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row16_col29\" class=\"data row16 col29\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col30\" class=\"data row16 col30\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row16_col31\" class=\"data row16 col31\" >-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row17\" class=\"row_heading level0 row17\" >diag_2_indexed</th>\n",
              "      <td id=\"T_f19a0_row17_col0\" class=\"data row17 col0\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row17_col1\" class=\"data row17 col1\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row17_col2\" class=\"data row17 col2\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row17_col3\" class=\"data row17 col3\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row17_col4\" class=\"data row17 col4\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row17_col5\" class=\"data row17 col5\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row17_col6\" class=\"data row17 col6\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col7\" class=\"data row17 col7\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col8\" class=\"data row17 col8\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col9\" class=\"data row17 col9\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col10\" class=\"data row17 col10\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row17_col11\" class=\"data row17 col11\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row17_col12\" class=\"data row17 col12\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col13\" class=\"data row17 col13\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col14\" class=\"data row17 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col15\" class=\"data row17 col15\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row17_col16\" class=\"data row17 col16\" >0.22</td>\n",
              "      <td id=\"T_f19a0_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row17_col18\" class=\"data row17 col18\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row17_col19\" class=\"data row17 col19\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row17_col20\" class=\"data row17 col20\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row17_col21\" class=\"data row17 col21\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col22\" class=\"data row17 col22\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col23\" class=\"data row17 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col24\" class=\"data row17 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col25\" class=\"data row17 col25\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col26\" class=\"data row17 col26\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row17_col27\" class=\"data row17 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row17_col28\" class=\"data row17 col28\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row17_col29\" class=\"data row17 col29\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row17_col30\" class=\"data row17 col30\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row17_col31\" class=\"data row17 col31\" >-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row18\" class=\"row_heading level0 row18\" >diag_3_indexed</th>\n",
              "      <td id=\"T_f19a0_row18_col0\" class=\"data row18 col0\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row18_col1\" class=\"data row18 col1\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row18_col2\" class=\"data row18 col2\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col3\" class=\"data row18 col3\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row18_col4\" class=\"data row18 col4\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row18_col5\" class=\"data row18 col5\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row18_col6\" class=\"data row18 col6\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row18_col7\" class=\"data row18 col7\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row18_col8\" class=\"data row18 col8\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col9\" class=\"data row18 col9\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col10\" class=\"data row18 col10\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col11\" class=\"data row18 col11\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row18_col12\" class=\"data row18 col12\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col13\" class=\"data row18 col13\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row18_col14\" class=\"data row18 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col15\" class=\"data row18 col15\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row18_col16\" class=\"data row18 col16\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row18_col17\" class=\"data row18 col17\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row18_col19\" class=\"data row18 col19\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row18_col20\" class=\"data row18 col20\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col21\" class=\"data row18 col21\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col22\" class=\"data row18 col22\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col23\" class=\"data row18 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col24\" class=\"data row18 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col25\" class=\"data row18 col25\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col26\" class=\"data row18 col26\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col27\" class=\"data row18 col27\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col28\" class=\"data row18 col28\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row18_col29\" class=\"data row18 col29\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row18_col30\" class=\"data row18 col30\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row18_col31\" class=\"data row18 col31\" >0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row19\" class=\"row_heading level0 row19\" >max_glu_serum_indexed</th>\n",
              "      <td id=\"T_f19a0_row19_col0\" class=\"data row19 col0\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row19_col1\" class=\"data row19 col1\" >0.37</td>\n",
              "      <td id=\"T_f19a0_row19_col2\" class=\"data row19 col2\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row19_col3\" class=\"data row19 col3\" >0.22</td>\n",
              "      <td id=\"T_f19a0_row19_col4\" class=\"data row19 col4\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row19_col5\" class=\"data row19 col5\" >-0.12</td>\n",
              "      <td id=\"T_f19a0_row19_col6\" class=\"data row19 col6\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row19_col7\" class=\"data row19 col7\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col8\" class=\"data row19 col8\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row19_col9\" class=\"data row19 col9\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row19_col10\" class=\"data row19 col10\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row19_col11\" class=\"data row19 col11\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row19_col12\" class=\"data row19 col12\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row19_col13\" class=\"data row19 col13\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row19_col14\" class=\"data row19 col14\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row19_col15\" class=\"data row19 col15\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col16\" class=\"data row19 col16\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row19_col17\" class=\"data row19 col17\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col18\" class=\"data row19 col18\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row19_col20\" class=\"data row19 col20\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row19_col21\" class=\"data row19 col21\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row19_col22\" class=\"data row19 col22\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row19_col23\" class=\"data row19 col23\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row19_col24\" class=\"data row19 col24\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col25\" class=\"data row19 col25\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row19_col26\" class=\"data row19 col26\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col27\" class=\"data row19 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col28\" class=\"data row19 col28\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row19_col29\" class=\"data row19 col29\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row19_col30\" class=\"data row19 col30\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row19_col31\" class=\"data row19 col31\" >0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row20\" class=\"row_heading level0 row20\" >A1Cresult_indexed</th>\n",
              "      <td id=\"T_f19a0_row20_col0\" class=\"data row20 col0\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row20_col1\" class=\"data row20 col1\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row20_col2\" class=\"data row20 col2\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row20_col3\" class=\"data row20 col3\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row20_col4\" class=\"data row20 col4\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row20_col5\" class=\"data row20 col5\" >0.23</td>\n",
              "      <td id=\"T_f19a0_row20_col6\" class=\"data row20 col6\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row20_col7\" class=\"data row20 col7\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row20_col8\" class=\"data row20 col8\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row20_col9\" class=\"data row20 col9\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row20_col10\" class=\"data row20 col10\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row20_col11\" class=\"data row20 col11\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row20_col12\" class=\"data row20 col12\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row20_col13\" class=\"data row20 col13\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row20_col14\" class=\"data row20 col14\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row20_col15\" class=\"data row20 col15\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row20_col16\" class=\"data row20 col16\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row20_col17\" class=\"data row20 col17\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row20_col18\" class=\"data row20 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row20_col19\" class=\"data row20 col19\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row20_col21\" class=\"data row20 col21\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row20_col22\" class=\"data row20 col22\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row20_col23\" class=\"data row20 col23\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row20_col24\" class=\"data row20 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row20_col25\" class=\"data row20 col25\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row20_col26\" class=\"data row20 col26\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row20_col27\" class=\"data row20 col27\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row20_col28\" class=\"data row20 col28\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row20_col29\" class=\"data row20 col29\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row20_col30\" class=\"data row20 col30\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row20_col31\" class=\"data row20 col31\" >-0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row21\" class=\"row_heading level0 row21\" >metformin_indexed</th>\n",
              "      <td id=\"T_f19a0_row21_col0\" class=\"data row21 col0\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row21_col1\" class=\"data row21 col1\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row21_col2\" class=\"data row21 col2\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row21_col3\" class=\"data row21 col3\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row21_col4\" class=\"data row21 col4\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col5\" class=\"data row21 col5\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row21_col6\" class=\"data row21 col6\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row21_col7\" class=\"data row21 col7\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row21_col8\" class=\"data row21 col8\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col9\" class=\"data row21 col9\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col10\" class=\"data row21 col10\" >-0.07</td>\n",
              "      <td id=\"T_f19a0_row21_col11\" class=\"data row21 col11\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row21_col12\" class=\"data row21 col12\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row21_col13\" class=\"data row21 col13\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col14\" class=\"data row21 col14\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row21_col15\" class=\"data row21 col15\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row21_col16\" class=\"data row21 col16\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row21_col17\" class=\"data row21 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col18\" class=\"data row21 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col19\" class=\"data row21 col19\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row21_col20\" class=\"data row21 col20\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row21_col22\" class=\"data row21 col22\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row21_col23\" class=\"data row21 col23\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col24\" class=\"data row21 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col25\" class=\"data row21 col25\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row21_col26\" class=\"data row21 col26\" >0.13</td>\n",
              "      <td id=\"T_f19a0_row21_col27\" class=\"data row21 col27\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row21_col28\" class=\"data row21 col28\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row21_col29\" class=\"data row21 col29\" >0.32</td>\n",
              "      <td id=\"T_f19a0_row21_col30\" class=\"data row21 col30\" >-0.25</td>\n",
              "      <td id=\"T_f19a0_row21_col31\" class=\"data row21 col31\" >-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row22\" class=\"row_heading level0 row22\" >repaglinide_indexed</th>\n",
              "      <td id=\"T_f19a0_row22_col0\" class=\"data row22 col0\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row22_col1\" class=\"data row22 col1\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col2\" class=\"data row22 col2\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col3\" class=\"data row22 col3\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col4\" class=\"data row22 col4\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row22_col5\" class=\"data row22 col5\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col6\" class=\"data row22 col6\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col7\" class=\"data row22 col7\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col8\" class=\"data row22 col8\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col9\" class=\"data row22 col9\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col10\" class=\"data row22 col10\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col11\" class=\"data row22 col11\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row22_col12\" class=\"data row22 col12\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col13\" class=\"data row22 col13\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row22_col14\" class=\"data row22 col14\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col15\" class=\"data row22 col15\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col16\" class=\"data row22 col16\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col17\" class=\"data row22 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col18\" class=\"data row22 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col19\" class=\"data row22 col19\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row22_col20\" class=\"data row22 col20\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col21\" class=\"data row22 col21\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row22_col23\" class=\"data row22 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col24\" class=\"data row22 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col25\" class=\"data row22 col25\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col26\" class=\"data row22 col26\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col27\" class=\"data row22 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row22_col28\" class=\"data row22 col28\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row22_col29\" class=\"data row22 col29\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row22_col30\" class=\"data row22 col30\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row22_col31\" class=\"data row22 col31\" >0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row23\" class=\"row_heading level0 row23\" >nateglinide_indexed</th>\n",
              "      <td id=\"T_f19a0_row23_col0\" class=\"data row23 col0\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row23_col1\" class=\"data row23 col1\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col2\" class=\"data row23 col2\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row23_col3\" class=\"data row23 col3\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col4\" class=\"data row23 col4\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col5\" class=\"data row23 col5\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col6\" class=\"data row23 col6\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col7\" class=\"data row23 col7\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row23_col8\" class=\"data row23 col8\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col9\" class=\"data row23 col9\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col10\" class=\"data row23 col10\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col11\" class=\"data row23 col11\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row23_col12\" class=\"data row23 col12\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col13\" class=\"data row23 col13\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col14\" class=\"data row23 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col15\" class=\"data row23 col15\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col16\" class=\"data row23 col16\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col17\" class=\"data row23 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col18\" class=\"data row23 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col19\" class=\"data row23 col19\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row23_col20\" class=\"data row23 col20\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col21\" class=\"data row23 col21\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col22\" class=\"data row23 col22\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col23\" class=\"data row23 col23\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row23_col24\" class=\"data row23 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col25\" class=\"data row23 col25\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row23_col26\" class=\"data row23 col26\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row23_col27\" class=\"data row23 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col28\" class=\"data row23 col28\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row23_col29\" class=\"data row23 col29\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row23_col30\" class=\"data row23 col30\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row23_col31\" class=\"data row23 col31\" >0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row24\" class=\"row_heading level0 row24\" >chlorpropamide_indexed</th>\n",
              "      <td id=\"T_f19a0_row24_col0\" class=\"data row24 col0\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col1\" class=\"data row24 col1\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col2\" class=\"data row24 col2\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row24_col3\" class=\"data row24 col3\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col4\" class=\"data row24 col4\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col5\" class=\"data row24 col5\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col6\" class=\"data row24 col6\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col7\" class=\"data row24 col7\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col8\" class=\"data row24 col8\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col9\" class=\"data row24 col9\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col10\" class=\"data row24 col10\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col11\" class=\"data row24 col11\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col12\" class=\"data row24 col12\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col13\" class=\"data row24 col13\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col14\" class=\"data row24 col14\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col15\" class=\"data row24 col15\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col16\" class=\"data row24 col16\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col17\" class=\"data row24 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col18\" class=\"data row24 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col19\" class=\"data row24 col19\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col20\" class=\"data row24 col20\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col21\" class=\"data row24 col21\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col22\" class=\"data row24 col22\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col23\" class=\"data row24 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col24\" class=\"data row24 col24\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row24_col25\" class=\"data row24 col25\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col26\" class=\"data row24 col26\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row24_col27\" class=\"data row24 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col28\" class=\"data row24 col28\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row24_col29\" class=\"data row24 col29\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row24_col30\" class=\"data row24 col30\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row24_col31\" class=\"data row24 col31\" >-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row25\" class=\"row_heading level0 row25\" >glipizide_indexed</th>\n",
              "      <td id=\"T_f19a0_row25_col0\" class=\"data row25 col0\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row25_col1\" class=\"data row25 col1\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col2\" class=\"data row25 col2\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row25_col3\" class=\"data row25 col3\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col4\" class=\"data row25 col4\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row25_col5\" class=\"data row25 col5\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row25_col6\" class=\"data row25 col6\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col7\" class=\"data row25 col7\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row25_col8\" class=\"data row25 col8\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col9\" class=\"data row25 col9\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col10\" class=\"data row25 col10\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row25_col11\" class=\"data row25 col11\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row25_col12\" class=\"data row25 col12\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row25_col13\" class=\"data row25 col13\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row25_col14\" class=\"data row25 col14\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row25_col15\" class=\"data row25 col15\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row25_col16\" class=\"data row25 col16\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row25_col17\" class=\"data row25 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col18\" class=\"data row25 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col19\" class=\"data row25 col19\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col20\" class=\"data row25 col20\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col21\" class=\"data row25 col21\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row25_col22\" class=\"data row25 col22\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row25_col23\" class=\"data row25 col23\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col24\" class=\"data row25 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row25_col25\" class=\"data row25 col25\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row25_col26\" class=\"data row25 col26\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row25_col27\" class=\"data row25 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row25_col28\" class=\"data row25 col28\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row25_col29\" class=\"data row25 col29\" >0.21</td>\n",
              "      <td id=\"T_f19a0_row25_col30\" class=\"data row25 col30\" >-0.19</td>\n",
              "      <td id=\"T_f19a0_row25_col31\" class=\"data row25 col31\" >0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row26\" class=\"row_heading level0 row26\" >glyburide_indexed</th>\n",
              "      <td id=\"T_f19a0_row26_col0\" class=\"data row26 col0\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row26_col1\" class=\"data row26 col1\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row26_col2\" class=\"data row26 col2\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row26_col3\" class=\"data row26 col3\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row26_col4\" class=\"data row26 col4\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row26_col5\" class=\"data row26 col5\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row26_col6\" class=\"data row26 col6\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row26_col7\" class=\"data row26 col7\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row26_col8\" class=\"data row26 col8\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row26_col9\" class=\"data row26 col9\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row26_col10\" class=\"data row26 col10\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row26_col11\" class=\"data row26 col11\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row26_col12\" class=\"data row26 col12\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row26_col13\" class=\"data row26 col13\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row26_col14\" class=\"data row26 col14\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row26_col15\" class=\"data row26 col15\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row26_col16\" class=\"data row26 col16\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row26_col17\" class=\"data row26 col17\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row26_col18\" class=\"data row26 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row26_col19\" class=\"data row26 col19\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row26_col20\" class=\"data row26 col20\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row26_col21\" class=\"data row26 col21\" >0.13</td>\n",
              "      <td id=\"T_f19a0_row26_col22\" class=\"data row26 col22\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row26_col23\" class=\"data row26 col23\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row26_col24\" class=\"data row26 col24\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row26_col25\" class=\"data row26 col25\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row26_col26\" class=\"data row26 col26\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row26_col27\" class=\"data row26 col27\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row26_col28\" class=\"data row26 col28\" >-0.08</td>\n",
              "      <td id=\"T_f19a0_row26_col29\" class=\"data row26 col29\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row26_col30\" class=\"data row26 col30\" >-0.17</td>\n",
              "      <td id=\"T_f19a0_row26_col31\" class=\"data row26 col31\" >-0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row27\" class=\"row_heading level0 row27\" >tolazamide_indexed</th>\n",
              "      <td id=\"T_f19a0_row27_col0\" class=\"data row27 col0\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col1\" class=\"data row27 col1\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col2\" class=\"data row27 col2\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row27_col3\" class=\"data row27 col3\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col4\" class=\"data row27 col4\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col5\" class=\"data row27 col5\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col6\" class=\"data row27 col6\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col7\" class=\"data row27 col7\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col8\" class=\"data row27 col8\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col9\" class=\"data row27 col9\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col10\" class=\"data row27 col10\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col11\" class=\"data row27 col11\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col12\" class=\"data row27 col12\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col13\" class=\"data row27 col13\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col14\" class=\"data row27 col14\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col15\" class=\"data row27 col15\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col16\" class=\"data row27 col16\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col17\" class=\"data row27 col17\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col18\" class=\"data row27 col18\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col19\" class=\"data row27 col19\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col20\" class=\"data row27 col20\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col21\" class=\"data row27 col21\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col22\" class=\"data row27 col22\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col23\" class=\"data row27 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col24\" class=\"data row27 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col25\" class=\"data row27 col25\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col26\" class=\"data row27 col26\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col27\" class=\"data row27 col27\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row27_col28\" class=\"data row27 col28\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col29\" class=\"data row27 col29\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row27_col30\" class=\"data row27 col30\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row27_col31\" class=\"data row27 col31\" >-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row28\" class=\"row_heading level0 row28\" >insulin_indexed</th>\n",
              "      <td id=\"T_f19a0_row28_col0\" class=\"data row28 col0\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row28_col1\" class=\"data row28 col1\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row28_col2\" class=\"data row28 col2\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row28_col3\" class=\"data row28 col3\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row28_col4\" class=\"data row28 col4\" >0.13</td>\n",
              "      <td id=\"T_f19a0_row28_col5\" class=\"data row28 col5\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row28_col6\" class=\"data row28 col6\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row28_col7\" class=\"data row28 col7\" >0.24</td>\n",
              "      <td id=\"T_f19a0_row28_col8\" class=\"data row28 col8\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row28_col9\" class=\"data row28 col9\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row28_col10\" class=\"data row28 col10\" >0.09</td>\n",
              "      <td id=\"T_f19a0_row28_col11\" class=\"data row28 col11\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row28_col12\" class=\"data row28 col12\" >-0.10</td>\n",
              "      <td id=\"T_f19a0_row28_col13\" class=\"data row28 col13\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row28_col14\" class=\"data row28 col14\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row28_col15\" class=\"data row28 col15\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row28_col16\" class=\"data row28 col16\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row28_col17\" class=\"data row28 col17\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row28_col18\" class=\"data row28 col18\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row28_col19\" class=\"data row28 col19\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row28_col20\" class=\"data row28 col20\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row28_col21\" class=\"data row28 col21\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row28_col22\" class=\"data row28 col22\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row28_col23\" class=\"data row28 col23\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row28_col24\" class=\"data row28 col24\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row28_col25\" class=\"data row28 col25\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row28_col26\" class=\"data row28 col26\" >-0.08</td>\n",
              "      <td id=\"T_f19a0_row28_col27\" class=\"data row28 col27\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row28_col28\" class=\"data row28 col28\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row28_col29\" class=\"data row28 col29\" >0.62</td>\n",
              "      <td id=\"T_f19a0_row28_col30\" class=\"data row28 col30\" >-0.47</td>\n",
              "      <td id=\"T_f19a0_row28_col31\" class=\"data row28 col31\" >0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row29\" class=\"row_heading level0 row29\" >change_indexed</th>\n",
              "      <td id=\"T_f19a0_row29_col0\" class=\"data row29 col0\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row29_col1\" class=\"data row29 col1\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row29_col2\" class=\"data row29 col2\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row29_col3\" class=\"data row29 col3\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row29_col4\" class=\"data row29 col4\" >0.11</td>\n",
              "      <td id=\"T_f19a0_row29_col5\" class=\"data row29 col5\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row29_col6\" class=\"data row29 col6\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row29_col7\" class=\"data row29 col7\" >0.25</td>\n",
              "      <td id=\"T_f19a0_row29_col8\" class=\"data row29 col8\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row29_col9\" class=\"data row29 col9\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row29_col10\" class=\"data row29 col10\" >0.03</td>\n",
              "      <td id=\"T_f19a0_row29_col11\" class=\"data row29 col11\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row29_col12\" class=\"data row29 col12\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row29_col13\" class=\"data row29 col13\" >0.15</td>\n",
              "      <td id=\"T_f19a0_row29_col14\" class=\"data row29 col14\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row29_col15\" class=\"data row29 col15\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row29_col16\" class=\"data row29 col16\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row29_col17\" class=\"data row29 col17\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row29_col18\" class=\"data row29 col18\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row29_col19\" class=\"data row29 col19\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row29_col20\" class=\"data row29 col20\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row29_col21\" class=\"data row29 col21\" >0.32</td>\n",
              "      <td id=\"T_f19a0_row29_col22\" class=\"data row29 col22\" >0.08</td>\n",
              "      <td id=\"T_f19a0_row29_col23\" class=\"data row29 col23\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row29_col24\" class=\"data row29 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row29_col25\" class=\"data row29 col25\" >0.21</td>\n",
              "      <td id=\"T_f19a0_row29_col26\" class=\"data row29 col26\" >0.19</td>\n",
              "      <td id=\"T_f19a0_row29_col27\" class=\"data row29 col27\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row29_col28\" class=\"data row29 col28\" >0.62</td>\n",
              "      <td id=\"T_f19a0_row29_col29\" class=\"data row29 col29\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row29_col30\" class=\"data row29 col30\" >-0.51</td>\n",
              "      <td id=\"T_f19a0_row29_col31\" class=\"data row29 col31\" >0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row30\" class=\"row_heading level0 row30\" >diabetesMed_indexed</th>\n",
              "      <td id=\"T_f19a0_row30_col0\" class=\"data row30 col0\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row30_col1\" class=\"data row30 col1\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row30_col2\" class=\"data row30 col2\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row30_col3\" class=\"data row30 col3\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row30_col4\" class=\"data row30 col4\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row30_col5\" class=\"data row30 col5\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row30_col6\" class=\"data row30 col6\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row30_col7\" class=\"data row30 col7\" >-0.18</td>\n",
              "      <td id=\"T_f19a0_row30_col8\" class=\"data row30 col8\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row30_col9\" class=\"data row30 col9\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row30_col10\" class=\"data row30 col10\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row30_col11\" class=\"data row30 col11\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row30_col12\" class=\"data row30 col12\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row30_col13\" class=\"data row30 col13\" >-0.09</td>\n",
              "      <td id=\"T_f19a0_row30_col14\" class=\"data row30 col14\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row30_col15\" class=\"data row30 col15\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row30_col16\" class=\"data row30 col16\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row30_col17\" class=\"data row30 col17\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row30_col18\" class=\"data row30 col18\" >0.01</td>\n",
              "      <td id=\"T_f19a0_row30_col19\" class=\"data row30 col19\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row30_col20\" class=\"data row30 col20\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row30_col21\" class=\"data row30 col21\" >-0.25</td>\n",
              "      <td id=\"T_f19a0_row30_col22\" class=\"data row30 col22\" >-0.06</td>\n",
              "      <td id=\"T_f19a0_row30_col23\" class=\"data row30 col23\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row30_col24\" class=\"data row30 col24\" >-0.02</td>\n",
              "      <td id=\"T_f19a0_row30_col25\" class=\"data row30 col25\" >-0.19</td>\n",
              "      <td id=\"T_f19a0_row30_col26\" class=\"data row30 col26\" >-0.17</td>\n",
              "      <td id=\"T_f19a0_row30_col27\" class=\"data row30 col27\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row30_col28\" class=\"data row30 col28\" >-0.47</td>\n",
              "      <td id=\"T_f19a0_row30_col29\" class=\"data row30 col29\" >-0.51</td>\n",
              "      <td id=\"T_f19a0_row30_col30\" class=\"data row30 col30\" >1.00</td>\n",
              "      <td id=\"T_f19a0_row30_col31\" class=\"data row30 col31\" >-0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_f19a0_level0_row31\" class=\"row_heading level0 row31\" >readmitted_indexed</th>\n",
              "      <td id=\"T_f19a0_row31_col0\" class=\"data row31 col0\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row31_col1\" class=\"data row31 col1\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row31_col2\" class=\"data row31 col2\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row31_col3\" class=\"data row31 col3\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row31_col4\" class=\"data row31 col4\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row31_col5\" class=\"data row31 col5\" >0.05</td>\n",
              "      <td id=\"T_f19a0_row31_col6\" class=\"data row31 col6\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row31_col7\" class=\"data row31 col7\" >0.06</td>\n",
              "      <td id=\"T_f19a0_row31_col8\" class=\"data row31 col8\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row31_col9\" class=\"data row31 col9\" >0.10</td>\n",
              "      <td id=\"T_f19a0_row31_col10\" class=\"data row31 col10\" >0.24</td>\n",
              "      <td id=\"T_f19a0_row31_col11\" class=\"data row31 col11\" >0.12</td>\n",
              "      <td id=\"T_f19a0_row31_col12\" class=\"data row31 col12\" >-0.24</td>\n",
              "      <td id=\"T_f19a0_row31_col13\" class=\"data row31 col13\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row31_col14\" class=\"data row31 col14\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row31_col15\" class=\"data row31 col15\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row31_col16\" class=\"data row31 col16\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row31_col17\" class=\"data row31 col17\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row31_col18\" class=\"data row31 col18\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row31_col19\" class=\"data row31 col19\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row31_col20\" class=\"data row31 col20\" >-0.03</td>\n",
              "      <td id=\"T_f19a0_row31_col21\" class=\"data row31 col21\" >-0.04</td>\n",
              "      <td id=\"T_f19a0_row31_col22\" class=\"data row31 col22\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row31_col23\" class=\"data row31 col23\" >0.00</td>\n",
              "      <td id=\"T_f19a0_row31_col24\" class=\"data row31 col24\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row31_col25\" class=\"data row31 col25\" >0.02</td>\n",
              "      <td id=\"T_f19a0_row31_col26\" class=\"data row31 col26\" >-0.01</td>\n",
              "      <td id=\"T_f19a0_row31_col27\" class=\"data row31 col27\" >-0.00</td>\n",
              "      <td id=\"T_f19a0_row31_col28\" class=\"data row31 col28\" >0.07</td>\n",
              "      <td id=\"T_f19a0_row31_col29\" class=\"data row31 col29\" >0.04</td>\n",
              "      <td id=\"T_f19a0_row31_col30\" class=\"data row31 col30\" >-0.05</td>\n",
              "      <td id=\"T_f19a0_row31_col31\" class=\"data row31 col31\" >1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 51.3 s (started: 2023-10-16 11:18:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "assembler = VectorAssembler(inputCols=df.columns, outputCol='corr_features')\n",
        "df_vector = assembler.transform(df).select('corr_features')\n",
        "\n",
        "matrix = Correlation.corr(df_vector, 'corr_features').collect()[0][0]\n",
        "\n",
        "corr_matrix = matrix.toArray().tolist()\n",
        "corr_matrix_df = pd.DataFrame(data=corr_matrix, columns=df.columns, index=df.columns)\n",
        "corr_matrix_df .style.background_gradient(cmap='coolwarm').set_precision(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing how numeric columns are made"
      ],
      "metadata": {
        "id": "GOK7oxJ78fHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8IJyy3Mr3D2",
        "outputId": "1da0d3dc-1a30-4169-fc27-0aded9da7144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------+------------------------+-------------------+----------------+------------------+--------------+---------------+-----------------+----------------+----------------+----------------+------------------+--------------------+------------+--------------+--------------+--------------+--------------+---------------------+-----------------+-----------------+-------------------+-------------------+----------------------+-----------------+-----------------+------------------+---------------+--------------+-------------------+------------------+\n",
            "|age|admission_type_id|discharge_disposition_id|admission_source_id|time_in_hospital|num_lab_procedures|num_procedures|num_medications|number_outpatient|number_emergency|number_inpatient|number_diagnoses|      health_index| severity_of_disease|race_indexed|gender_indexed|diag_1_indexed|diag_2_indexed|diag_3_indexed|max_glu_serum_indexed|A1Cresult_indexed|metformin_indexed|repaglinide_indexed|nateglinide_indexed|chlorpropamide_indexed|glipizide_indexed|glyburide_indexed|tolazamide_indexed|insulin_indexed|change_indexed|diabetesMed_indexed|readmitted_indexed|\n",
            "+---+-----------------+------------------------+-------------------+----------------+------------------+--------------+---------------+-----------------+----------------+----------------+----------------+------------------+--------------------+------------+--------------+--------------+--------------+--------------+---------------------+-----------------+-----------------+-------------------+-------------------+----------------------+-----------------+-----------------+------------------+---------------+--------------+-------------------+------------------+\n",
            "|  5|                5|                      18|                  1|               1|                41|             0|              1|                0|               0|               0|               1|               2.0|6.151418279386793E-6|         0.0|           0.0|           4.0|           2.0|           2.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              0.0|              0.0|               0.0|            0.0|           0.0|                1.0|               0.0|\n",
            "| 15|                1|                       1|                  7|               3|                59|             0|             18|                0|               0|               0|               9|               2.0|1.244264151966874E-5|         0.0|           0.0|           1.0|           2.0|           1.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              0.0|              0.0|               0.0|            3.0|           1.0|                0.0|               1.0|\n",
            "| 25|                1|                       1|                  7|               2|                11|             5|             13|                2|               0|               1|               6|0.3333333333333333|5.172783553120712E-6|         1.0|           0.0|           9.0|           2.0|           1.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              1.0|              0.0|               0.0|            0.0|           0.0|                0.0|               0.0|\n",
            "| 35|                1|                       1|                  7|               2|                44|             1|             16|                0|               0|               0|               7|               2.0|9.786347262660807E-6|         0.0|           1.0|           1.0|           2.0|           0.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              0.0|              0.0|               0.0|            3.0|           1.0|                0.0|               0.0|\n",
            "| 45|                1|                       1|                  7|               1|                51|             0|              8|                0|               0|               0|               5|               2.0|9.087322458185035E-6|         0.0|           1.0|           8.0|           7.0|           2.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              1.0|              0.0|               0.0|            1.0|           1.0|                0.0|               0.0|\n",
            "| 55|                1|                       1|                  1|               3|                31|             6|             16|                0|               0|               0|               9|               2.0|9.087322458185035E-6|         0.0|           1.0|           0.0|           0.0|           2.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              0.0|              0.0|               0.0|            1.0|           0.0|                0.0|               1.0|\n",
            "| 65|                3|                       1|                  1|               4|                70|             1|             21|                0|               0|               0|               7|               2.0|1.439991097220090...|         0.0|           1.0|           0.0|           0.0|           1.0|                  0.0|              0.0|              1.0|                0.0|                0.0|                   0.0|              0.0|              0.0|               0.0|            1.0|           1.0|                0.0|               0.0|\n",
            "| 75|                1|                       1|                  7|               5|                73|             0|             12|                0|               0|               0|               8|               2.0|1.370088616772513E-5|         0.0|           1.0|           0.0|           3.0|           2.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              0.0|              1.0|               0.0|            0.0|           0.0|                0.0|               1.0|\n",
            "| 85|                1|                       1|                  4|              13|                68|             2|             28|                0|               0|               0|               8|               2.0|1.663679034652337...|         0.0|           0.0|           0.0|           0.0|           1.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              1.0|              0.0|               0.0|            1.0|           1.0|                0.0|               0.0|\n",
            "| 95|                3|                       2|                  4|              12|                33|             3|             18|                0|               0|               0|               8|               2.0|1.034556710624142...|         0.0|           0.0|           0.0|           7.0|           3.0|                  0.0|              0.0|              0.0|                0.0|                0.0|                   0.0|              0.0|              0.0|               0.0|            1.0|           1.0|                0.0|               0.0|\n",
            "+---+-----------------+------------------------+-------------------+----------------+------------------+--------------+---------------+-----------------+----------------+----------------+----------------+------------------+--------------------+------------+--------------+--------------+--------------+--------------+---------------------+-----------------+-----------------+-------------------+-------------------+----------------------+-----------------+-----------------+------------------+---------------+--------------+-------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "32\n",
            "time: 6.87 s (started: 2023-10-16 11:19:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df.show(10)\n",
        "print(len(df.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4xiagENr3D2"
      },
      "source": [
        "Normalising and aggregating inputs to reach better performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOYF4aaXr3D2"
      },
      "source": [
        "Scaling to a range or z-score are good when I know upper and lower bouds with few outliers and data are uniformly distribuited; selecting this kind of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zezmd8Zbr3D2",
        "outputId": "2dd86771-a01e-486a-e75d-8654f50d5b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 969 µs (started: 2023-10-16 11:19:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def normalisation_step(df, input_cols, column_name):\n",
        "  vec_assembler = VectorAssembler(inputCols=input_cols, outputCol='vect_features_' + column_name)\n",
        "  df = vec_assembler.transform(df)\n",
        "\n",
        "  scaler = StandardScaler(inputCol='vect_features_' + column_name, outputCol='norm_features_' + column_name, withStd=True, withMean=True)\n",
        "  scalerModel = scaler.fit(df)\n",
        "\n",
        "  df_new = scalerModel.transform(df)\n",
        "  df_new = df_new.drop('vect_features_' + column_name)\n",
        "\n",
        "  return df_new"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data after normalisation"
      ],
      "metadata": {
        "id": "GIM0Z5jQ8Ril"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTUyIxXbr3D2",
        "outputId": "e251bc19-85a4-43d6-dcfd-67341fad1a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 52.9 s (started: 2023-10-16 11:19:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pred_readmission = normalisation_step(df, df.drop('readmitted_indexed').columns, 'toPredReadmission')\n",
        "df_pred_A1Cresult = normalisation_step(df, df.drop('A1Cresult_indexed').columns, 'toPredA1Cresult')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GdO-V_ieyps",
        "outputId": "e38fa254-00d4-4e2e-dd44-696bab858051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+------------------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|\n",
            "+-------------------------------+------------------+\n",
            "|           [1.20761980818831...|               0.0|\n",
            "|           [0.58047087041334...|               1.0|\n",
            "|           [-0.6738270051366...|               0.0|\n",
            "|           [-0.0466780673616...|               0.0|\n",
            "|           [1.20761980818831...|               1.0|\n",
            "+-------------------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "time: 7.37 s (started: 2023-10-16 11:20:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Building the dataset with only rows with A1Cresult's test done (need it for the project work in the last section)\n",
        "df_pred_readmission_withA1Cresults = df_pred_readmission.filter(df_pred_readmission.A1Cresult_indexed != 0.0)\n",
        "df_pred_readmission_withA1Cresults = df_pred_readmission_withA1Cresults.select([\"norm_features_toPredReadmission\", \"readmitted_indexed\"])\n",
        "df_pred_readmission_withA1Cresults.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkKcZCiqLnVm",
        "outputId": "11adae10-37ef-4a9d-a4a8-5906d036a488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(norm_features_toPredReadmission=DenseVector([-3.8096, 2.4163, 4.2535, -1.4272, -1.1384, -0.0972, -0.7836, -1.8504, -0.2919, -0.2116, -0.5006, -3.2981, 0.8562, -1.1002, -0.4584, -0.9265, 0.6675, 0.0715, 0.1422, -0.211, -0.4033, -0.4641, -0.117, -0.0803, -0.028, -0.3489, -0.3136, -0.0196, -0.8684, -0.9309, 1.8415]))\n",
            "33\n",
            "\n",
            "\n",
            "Row(norm_features_toPredA1Cresult=DenseVector([-3.8096, 2.4163, 4.2535, -1.4272, -1.1384, -0.0972, -0.7836, -1.8504, -0.2919, -0.2116, -0.5006, -3.2981, 0.8562, -1.1002, -0.4584, -0.9265, 0.6675, 0.0715, 0.1422, -0.211, -0.4641, -0.117, -0.0803, -0.028, -0.3489, -0.3136, -0.0196, -0.8684, -0.9309, 1.8415, -0.853]))\n",
            "33\n",
            "time: 43.7 s (started: 2023-10-16 11:20:24 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Printing first row of norm_features_toPredReadmission which will be used as indipendent variable in the prediction models\n",
        "print(df_pred_readmission.select('norm_features_toPredReadmission').collect()[0])\n",
        "print(len(df_pred_readmission.columns))\n",
        "print('\\n')\n",
        "print(df_pred_A1Cresult.select('norm_features_toPredA1Cresult').collect()[0])\n",
        "print(len(df_pred_A1Cresult.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwheTKBNMLMV",
        "outputId": "14d69038-ab4d-4b40-963b-7bcf4cbe15ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 73.3 ms (started: 2023-10-16 11:21:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pred_readmission = df_pred_readmission.select([\"norm_features_toPredReadmission\", \"readmitted_indexed\"])\n",
        "df_pred_A1Cresult = df_pred_A1Cresult.select([\"norm_features_toPredA1Cresult\", \"A1Cresult_indexed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize final df, ready to use in training models"
      ],
      "metadata": {
        "id": "w2add5Ud8Gx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCFauceyPayn",
        "outputId": "ea06944a-6d33-4e99-e73b-11d4f37fbdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+------------------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|\n",
            "+-------------------------------+------------------+\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.1824227562364...|               1.0|\n",
            "|           [-2.5552738184615...|               0.0|\n",
            "|           [-1.9281248806865...|               0.0|\n",
            "|           [-1.3009759429115...|               0.0|\n",
            "+-------------------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------------------------+-----------------+\n",
            "|norm_features_toPredA1Cresult|A1Cresult_indexed|\n",
            "+-----------------------------+-----------------+\n",
            "|         [-3.8095716940114...|              0.0|\n",
            "|         [-3.1824227562364...|              0.0|\n",
            "|         [-2.5552738184615...|              0.0|\n",
            "|         [-1.9281248806865...|              0.0|\n",
            "|         [-1.3009759429115...|              0.0|\n",
            "+-----------------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "time: 8.77 s (started: 2023-10-16 11:21:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pred_readmission.show(5)\n",
        "df_pred_A1Cresult.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQE5POAA7WRU"
      },
      "source": [
        "## Splitting Dataset in Taining and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTFZOWsq7V3M",
        "outputId": "72536d94-e6ba-4695-91d6-c254b2ff45d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances in the training set: 79553\n",
            "Number of instances in the test set: 19790\n",
            "time: 25.5 s (started: 2023-10-16 11:21:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "(df_train_readmission, df_test_readmission) = df_pred_readmission.randomSplit([0.8, 0.2], seed=seed)\n",
        "print('Number of instances in the training set:', df_train_readmission.count())\n",
        "print('Number of instances in the test set:', df_test_readmission.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tiba5A7votR8",
        "outputId": "4967a2a1-2f8d-41b4-eb79-6513a939576c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances in the training set: 79553\n",
            "Number of instances in the test set: 19790\n",
            "time: 23.5 s (started: 2023-10-16 11:21:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "(df_train_A1C, df_test_A1C) = df_pred_A1Cresult.randomSplit([0.8, 0.2], seed=seed)\n",
        "print('Number of instances in the training set:', df_train_A1C.count())\n",
        "print('Number of instances in the test set:', df_test_A1C.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osJ-hknb6Zq-"
      },
      "source": [
        "## Predicting Readmission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzl2KJ3cTTxg",
        "outputId": "7bce5173-666d-49ac-9d6d-e0fb65674ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+------------------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|\n",
            "+-------------------------------+------------------+\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "+-------------------------------+------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "time: 6.73 s (started: 2023-10-16 11:22:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_train_readmission.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZzpbNeKVKsI"
      },
      "source": [
        "### Starting predicting all 3 classes separated: 'NO', '>30', '<30'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx2XFc0tmbvL"
      },
      "source": [
        "#### Decision Tree classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uidi05NLRreD"
      },
      "source": [
        "Train decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suIdQH-36fp3",
        "outputId": "600612b2-2d79-47ff-c584-55dd7bc7218b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 38.1 s (started: 2023-10-16 11:22:12 +00:00)\n"
          ]
        }
      ],
      "source": [
        "dt_classifier = DecisionTreeClassifier(labelCol=\"readmitted_indexed\", featuresCol=\"norm_features_toPredReadmission\")\n",
        "model1 = dt_classifier.fit(df_train_readmission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DswryMGWRuS2"
      },
      "source": [
        "Test decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PzaimsGRqo3",
        "outputId": "faf31190-6444-4343-99b9-1b64db6a218c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.52\n",
            "time: 11.8 s (started: 2023-10-16 11:22:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predictions = model1.transform(df_test_readmission)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"readmitted_indexed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrj1YZi15clq",
        "outputId": "055944b8-8ced-4b45-fdbe-531f7b75d3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31,[2,10,11,12,13,18,28],[0.01706837432802734,0.20156281980986182,0.028560655020832236,0.7302035498788839,0.014661014578903866,0.003529090487912242,0.0044144958955785706])\n",
            "time: 60.7 ms (started: 2023-10-16 11:23:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "print(model1.featureImportances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQwjlPz3mWt3"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29T_6C4ZmjXv",
        "outputId": "ca2299fb-1ca1-4cf8-c76e-bbeb1fe9610f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 40.5 s (started: 2023-10-16 11:23:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(labelCol=\"readmitted_indexed\", featuresCol=\"norm_features_toPredReadmission\")\n",
        "model2 = rf.fit(df_train_readmission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce6OKi1jWv2S",
        "outputId": "27aee373-8033-4c87-cad5-c8ca3d2c113f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.52\n",
            "time: 11 s (started: 2023-10-16 11:23:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predictions = model2.transform(df_test_readmission)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"readmitted_indexed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Mg-jP1QLGd"
      },
      "source": [
        "### Predicting general readmission, before or after 30 days ---> 2 classes: 'NO' and 'general_readmission'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpeAXYUgQUID"
      },
      "source": [
        "Unification of <30 and >30."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDKjK4_wQRME",
        "outputId": "0683277f-c579-4f13-84c3-f43a54af973e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+------------------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|\n",
            "+-------------------------------+------------------+\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "|           [-3.8095716940114...|               0.0|\n",
            "+-------------------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+------------------+\n",
            "|readmitted_indexed|\n",
            "+------------------+\n",
            "|               0.0|\n",
            "|               1.0|\n",
            "|               2.0|\n",
            "+------------------+\n",
            "\n",
            "time: 21.8 s (started: 2023-10-16 11:23:54 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_train_readmission.show(10)\n",
        "print(df_train_readmission.select('readmitted_indexed').distinct())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified dataset"
      ],
      "metadata": {
        "id": "SmvkxWBwG2nc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "9YgjNi0AQkIz",
        "outputId": "5bd6a2c1-d079-4b86-fe1f-25c90e3f7f64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+------------------+\n",
              "|readmitted_indexed|\n",
              "+------------------+\n",
              "|               0.0|\n",
              "|               1.0|\n",
              "+------------------+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>readmitted_indexed</th></tr>\n",
              "<tr><td>0.0</td></tr>\n",
              "<tr><td>1.0</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 25.7 s (started: 2023-10-16 11:24:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_train_readmission_binary = df_train_readmission.withColumn(\"readmitted_indexed\", when(df_train_readmission.readmitted_indexed == 2.0, 1.0) \\\n",
        "      .when(df_train_readmission.readmitted_indexed == 1.0, 1.0) \\\n",
        "      .otherwise(df_train_readmission.readmitted_indexed))\n",
        "df_train_readmission_binary.select(\"readmitted_indexed\").distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "L1jPWhaHfrkC",
        "outputId": "b3322af1-f8cc-4239-e9dc-80364697bfb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+------------------+\n",
              "|readmitted_indexed|\n",
              "+------------------+\n",
              "|               0.0|\n",
              "|               1.0|\n",
              "+------------------+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>readmitted_indexed</th></tr>\n",
              "<tr><td>0.0</td></tr>\n",
              "<tr><td>1.0</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 25.9 s (started: 2023-10-16 11:24:41 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_test_readmission_binary = df_test_readmission.withColumn(\"readmitted_indexed\", when(df_test_readmission.readmitted_indexed == 2.0, 1.0) \\\n",
        "      .when(df_test_readmission.readmitted_indexed == 1.0, 1.0) \\\n",
        "      .otherwise(df_test_readmission.readmitted_indexed))\n",
        "df_test_readmission_binary.select(\"readmitted_indexed\").distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdKPt3ujdeWs",
        "outputId": "5dc5e016-2c7c-49b0-82d5-bfefec5dbd3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+\n",
            "|readmitted_indexed|count|\n",
            "+------------------+-----+\n",
            "|               0.0|42023|\n",
            "|               1.0|37530|\n",
            "+------------------+-----+\n",
            "\n",
            "+------------------+-----+\n",
            "|readmitted_indexed|count|\n",
            "+------------------+-----+\n",
            "|               0.0|10504|\n",
            "|               1.0| 9286|\n",
            "+------------------+-----+\n",
            "\n",
            "time: 39.3 s (started: 2023-10-16 11:25:07 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_train_readmission_binary.groupBy(\"readmitted_indexed\").count().show()\n",
        "df_test_readmission_binary.groupBy(\"readmitted_indexed\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x3PekNhdr8b",
        "outputId": "4e47e951-b02a-4b63-b7d1-c9ebd390986d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.62\n",
            "time: 57.5 s (started: 2023-10-16 11:25:47 +00:00)\n"
          ]
        }
      ],
      "source": [
        "dt_classifier = DecisionTreeClassifier(labelCol=\"readmitted_indexed\", featuresCol=\"norm_features_toPredReadmission\")\n",
        "model3 = dt_classifier.fit(df_train_readmission_binary)\n",
        "\n",
        "predictions = model3.transform(df_test_readmission_binary)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"readmitted_indexed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKMU1Op1Qbxn"
      },
      "source": [
        "###  Predicting early readmission ---> unification for NO and >30."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "7ZHmpyTqQiGJ",
        "outputId": "a2f52c73-96db-40f9-ea3c-d1069ab85335"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+------------------+\n",
              "|readmitted_indexed|\n",
              "+------------------+\n",
              "|               0.0|\n",
              "|               1.0|\n",
              "+------------------+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>readmitted_indexed</th></tr>\n",
              "<tr><td>0.0</td></tr>\n",
              "<tr><td>1.0</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 24.2 s (started: 2023-10-16 11:26:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_train_readmission_binary2 = df_train_readmission.withColumn(\"readmitted_indexed\", when(df_train_readmission.readmitted_indexed == 2.0, 1.0) \\\n",
        "      .when(df_train_readmission.readmitted_indexed == 1.0, 0.0) \\\n",
        "      .otherwise(df_train_readmission.readmitted_indexed))\n",
        "df_train_readmission_binary2.select(\"readmitted_indexed\").distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Kp0maV7NS07-",
        "outputId": "44ca48da-0ee5-4041-ebd6-0553ca09b061"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+------------------+\n",
              "|readmitted_indexed|\n",
              "+------------------+\n",
              "|               0.0|\n",
              "|               1.0|\n",
              "+------------------+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>readmitted_indexed</th></tr>\n",
              "<tr><td>0.0</td></tr>\n",
              "<tr><td>1.0</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 26 s (started: 2023-10-16 11:27:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_test_readmission_binary2 = df_test_readmission.withColumn(\"readmitted_indexed\", when(df_test_readmission.readmitted_indexed == 2.0, 1.0) \\\n",
        "      .when(df_test_readmission.readmitted_indexed == 1.0, 0.0) \\\n",
        "      .otherwise(df_test_readmission.readmitted_indexed))\n",
        "df_test_readmission_binary2.select(\"readmitted_indexed\").distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8ZfaYZRS8JL",
        "outputId": "3a7abab0-5fc3-43d7-83c1-6f88a75f75f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+\n",
            "|readmitted_indexed|count|\n",
            "+------------------+-----+\n",
            "|               0.0|70500|\n",
            "|               1.0| 9053|\n",
            "+------------------+-----+\n",
            "\n",
            "+------------------+-----+\n",
            "|readmitted_indexed|count|\n",
            "+------------------+-----+\n",
            "|               0.0|17529|\n",
            "|               1.0| 2261|\n",
            "+------------------+-----+\n",
            "\n",
            "time: 26.8 s (started: 2023-10-16 11:27:34 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_train_readmission_binary2.groupBy(\"readmitted_indexed\").count().show()\n",
        "df_test_readmission_binary2.groupBy(\"readmitted_indexed\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDpFCkfkS1I8",
        "outputId": "f46db7e2-bf60-4bec-ce7a-12216a3f38b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.83\n",
            "time: 57 s (started: 2023-10-16 11:28:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "dt_classifier2 = DecisionTreeClassifier(labelCol=\"readmitted_indexed\", featuresCol=\"norm_features_toPredReadmission\")\n",
        "model4 = dt_classifier2.fit(df_train_readmission_binary2)\n",
        "\n",
        "predictions = model4.transform(df_test_readmission_binary2)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"readmitted_indexed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOk8OjWwZkBN",
        "outputId": "30b764ea-9131-4fbc-9839-b8bb24bf564f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0|19749|\n",
            "|       1.0|   41|\n",
            "+----------+-----+\n",
            "\n",
            "time: 14.6 s (started: 2023-10-16 11:28:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predictions.groupBy('prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g48CfL46CJNE"
      },
      "source": [
        "Those models are not enough precise, trying deep models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0oMBPspWXyj"
      },
      "source": [
        "#### Deep Learning models: MLPC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnbOW8pbBQ9K"
      },
      "source": [
        "Starting with multilayerPerceptron of MLlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjZYgkhuyp1b",
        "outputId": "739442f0-9c3e-41c7-c610-5aace4a11f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|label|\n",
            "+----------+-----+\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Test set f1 = 0.8320865185630827\n",
            "time: 4min 8s (started: 2023-10-16 11:29:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_mlpc_train = df_train_readmission_binary2.withColumnRenamed(\"norm_features_toPredReadmission\",\"features\").withColumnRenamed(\"readmitted_indexed\", \"label\")\n",
        "df_mlpc_test = df_test_readmission_binary2.withColumnRenamed(\"norm_features_toPredReadmission\",\"features\").withColumnRenamed(\"readmitted_indexed\", \"label\")\n",
        "\n",
        "layers = [31, 60, 30, 15, 8, 2]\n",
        "mlpc = MultilayerPerceptronClassifier(layers = layers, blockSize = 64, seed = seed, solver='gd')\n",
        "\n",
        "nn_model = mlpc.fit(df_mlpc_train)\n",
        "prediction_result = nn_model.transform(df_mlpc_test)\n",
        "predictionAndLabels = prediction_result.select(\"prediction\", \"label\")\n",
        "predictionAndLabels.show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
        "print(\"Test set f1 = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdr1H2t3KIQx",
        "outputId": "c1473da4-b1f5-42af-c448-2b197ce11801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|17529|\n",
            "|  1.0| 2261|\n",
            "+-----+-----+\n",
            "\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0|19790|\n",
            "+----------+-----+\n",
            "\n",
            "time: 26.6 s (started: 2023-10-16 11:33:21 +00:00)\n"
          ]
        }
      ],
      "source": [
        "prediction_result.groupBy('label').count().show()\n",
        "prediction_result.groupBy('prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uglm2tFcKn5n"
      },
      "source": [
        "It's a very limited network just to try the implementation, it is unable to predict early readmission for such a complex task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tznv67d-_7lI"
      },
      "source": [
        "#### Custom network with keras and horovod framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ-d4MiB9sWQ"
      },
      "source": [
        "The horovod.spark package provides a convenient wrapper around Horovod that makes running distributed training jobs in Spark clusters easy.\n",
        "More details can be found here: https://horovod.readthedocs.io/en/stable/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIR-KE2XHbbq"
      },
      "source": [
        "Trying a 1D convolutional NN as suggested in this paper https://link.springer.com/article/10.1007/s00521-021-06431-7:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3wKe4JPAB2X",
        "outputId": "e09a9ea4-4ce3-4dca-c859-4b794f323b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 29, 128)           512       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 27, 64)            24640     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 13, 64)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 11, 32)            6176      \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 9, 16)             1552      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 144)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1450      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34341 (134.14 KB)\n",
            "Trainable params: 34341 (134.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "time: 533 ms (started: 2023-10-16 11:33:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "      Conv1D(128, 3, activation='relu', input_shape=(31,1)),\n",
        "      Conv1D(64, 3, activation='relu'),\n",
        "      MaxPooling1D(pool_size=2, padding=\"valid\"),\n",
        "      Conv1D(32, 3, activation='relu'),\n",
        "      Conv1D(16, 3, activation='relu'),\n",
        "      Flatten(),\n",
        "      Dense(10, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETby6vsVoDgz",
        "outputId": "9c8b2db6-5031-4627-8e89-ae801870ae9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_partitions=20\n",
            "writing dataframes\n",
            "train_data_path=file:///dbfs/horovod_spark_estimator/intermediate_train_data.0\n",
            "val_data_path=file:///dbfs/horovod_spark_estimator/intermediate_val_data.0\n",
            "train_partitions=20\n",
            "train_rows=79553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:495: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
            "  train_data_schema = train_data.schema.to_arrow_schema()\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:405: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "  for piece in dataset.pieces:\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:513: FutureWarning: The 'field_by_name' method is deprecated, use 'field' instead\n",
            "  metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:223: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model_fn(model, f)\n",
            "[1,1]<stderr>:2023-10-16 11:34:20.838690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[1,0]<stderr>:2023-10-16 11:34:20.856355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:Pinning current process to the GPU.\n",
            "[1,0]<stdout>:Shared lib path is pointing to: <CDLL '/usr/local/lib/python3.10/dist-packages/horovod/tensorflow/mpi_lib.cpython-310-x86_64-linux-gnu.so', handle 5b07585d92c0 at 0x7de61552c070>\n",
            "[1,0]<stdout>:Training parameters: Epochs: 30, Scaled lr: 0.019999999552965164, Shuffle: True, random_seed: None\n",
            "[1,0]<stdout>:Train rows: 79553, Train batch size: 128, Train_steps_per_epoch: 311\n",
            "[1,0]<stdout>:Val rows: 0, Val batch size: 128, Val_steps_per_epoch: None\n",
            "[1,0]<stdout>:Checkpoint file: file:///dbfs/horovod_spark_estimator/runs/keras_1697456053, Logs dir: file:///dbfs/horovod_spark_estimator/runs/keras_1697456053/logs\n",
            "[1,0]<stdout>:\n",
            "[1,0]<stdout>:data_module: <class 'horovod.spark.keras.datamodule.PetastormDataModule'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
            "[1,0]<stderr>:  self._filesystem = pyarrow.localfs\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,0]<stderr>:  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  if not dataset.common_metadata:\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,0]<stderr>:  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,0]<stderr>:  meta = parquet_dataset.pieces[0].get_metadata()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  for partition in (parquet_dataset.partitions or []):\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  metadata = dataset.metadata\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  common_metadata = dataset.common_metadata\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,0]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
            "[1,1]<stderr>:  self._filesystem = pyarrow.localfs\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,1]<stderr>:  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  if not dataset.common_metadata:\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,1]<stderr>:  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,1]<stderr>:  meta = parquet_dataset.pieces[0].get_metadata()\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  for partition in (parquet_dataset.partitions or []):\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  metadata = dataset.metadata\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  common_metadata = dataset.common_metadata\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,1]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,1]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,1]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
            "[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:71: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "[1,0]<stderr>:Instructions for updating:\n",
            "[1,0]<stderr>:Use `tf.data.Dataset.unbatch()`.\n",
            "[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:71: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "[1,1]<stderr>:Instructions for updating:\n",
            "[1,1]<stderr>:Use `tf.data.Dataset.unbatch()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0988s vs `on_train_batch_end` time: 0.1050s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,1]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.4488[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 47s 127ms/step - loss: 0.4454\n",
            "[1,0]<stdout>:Epoch 2/30\n",
            "311/311 [==============================] - ETA: 0s - loss: 0.3614[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 27s 88ms/step - loss: 0.3545\n",
            "[1,0]<stdout>:Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3585[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 30s 98ms/step - loss: 0.3514\n",
            "[1,0]<stdout>:Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3577[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 35s 114ms/step - loss: 0.3501\n",
            "[1,0]<stdout>:Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3548[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 33s 105ms/step - loss: 0.3473\n",
            "[1,0]<stdout>:Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3507[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 31s 100ms/step - loss: 0.3438\n",
            "[1,0]<stdout>:Epoch 7/30\n",
            "311/311 [==============================] - ETA: 0s - loss: 0.3497[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 27s 87ms/step - loss: 0.3415\n",
            "[1,0]<stdout>:Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3474[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 97ms/step - loss: 0.3413\n",
            "[1,0]<stdout>:Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3503[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 31s 99ms/step - loss: 0.3421\n",
            "[1,0]<stdout>:Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3471[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 30s 96ms/step - loss: 0.3395\n",
            "[1,0]<stdout>:Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3498[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 29s 93ms/step - loss: 0.3427\n",
            "[1,0]<stdout>:Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3462[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 31s 99ms/step - loss: 0.3395\n",
            "[1,0]<stdout>:Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3470[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 31s 100ms/step - loss: 0.3410\n",
            "[1,0]<stdout>:Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3470[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 29s 92ms/step - loss: 0.3399\n",
            "[1,0]<stdout>:Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3483[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 29s 95ms/step - loss: 0.3417\n",
            "[1,0]<stdout>:Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3477[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 98ms/step - loss: 0.3394\n",
            "[1,0]<stdout>:Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3484[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 98ms/step - loss: 0.3412\n",
            "[1,0]<stdout>:Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3472[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 29s 93ms/step - loss: 0.3404\n",
            "[1,0]<stdout>:Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3471[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 96ms/step - loss: 0.3403\n",
            "[1,0]<stdout>:Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3466[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 31s 99ms/step - loss: 0.3395\n",
            "[1,0]<stdout>:Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3466[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 31s 98ms/step - loss: 0.3403\n",
            "[1,0]<stdout>:Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3464[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 27s 87ms/step - loss: 0.3392\n",
            "[1,0]<stdout>:Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3484[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 96ms/step - loss: 0.3406\n",
            "[1,0]<stdout>:Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3450[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 31s 100ms/step - loss: 0.3379\n",
            "[1,0]<stdout>:Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3477[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 97ms/step - loss: 0.3406\n",
            "[1,0]<stdout>:Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3490[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 27s 87ms/step - loss: 0.3413\n",
            "[1,0]<stdout>:Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3454[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053\n",
            "311/311 [==============================] - 30s 96ms/step - loss: 0.3389\n",
            "[1,0]<stdout>:Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3490[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 30s 96ms/step - loss: 0.3412\n",
            "[1,0]<stdout>:Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3435[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 27s 88ms/step - loss: 0.3397\n",
            "[1,0]<stdout>:Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3475[1,0]<stdout>:Syncing dir /tmp/tmphcg4e1tw to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697456053[1,0]<stdout>:\n",
            "311/311 [==============================] - 31s 98ms/step - loss: 0.3391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:223: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "[1,0]<stderr>:  save_model_fn(model, f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16min 12s (started: 2023-10-16 11:33:48 +00:00)\n"
          ]
        }
      ],
      "source": [
        "work_dir = \"/dbfs/horovod_spark_estimator/\"\n",
        "store = DBFSLocalStore(work_dir)\n",
        "\n",
        "hvd_estimator = hvd.KerasEstimator(\n",
        "    model=model,\n",
        "    store=store,\n",
        "    optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "    loss='binary_crossentropy',\n",
        "    feature_cols=['norm_features_toPredReadmission'],\n",
        "    label_cols=['readmitted_indexed'],\n",
        "    batch_size=128,\n",
        "    epochs=30,\n",
        "    )\n",
        "\n",
        "hvd_model = hvd_estimator.fit(df_train_readmission_binary2) \\\n",
        "    .setOutputCols(['predict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_EmdbHxfQzT",
        "outputId": "c3f293fd-c601-4cb9-aaf2-88feb27f52a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1: 0.8404701327649304\n",
            "time: 2min 25s (started: 2023-10-16 13:11:07 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predict_df = hvd_model.transform(df_test_readmission_binary2)\n",
        "predict_df = predict_df.withColumn(\"predict\", when(predict_df.predict < 0.3, 0.0).otherwise(1.0))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "  predictionCol='predict', labelCol='readmitted_indexed', metricName='f1')\n",
        "print('Test F1:', evaluator.evaluate(predict_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw3hjG8HtXy0",
        "outputId": "f5c945d7-547b-4649-cd7b-54861cfa2bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones predicted:\n",
            "+-------+-----+\n",
            "|predict|count|\n",
            "+-------+-----+\n",
            "|    0.0|19393|\n",
            "|    1.0|  397|\n",
            "+-------+-----+\n",
            "\n",
            "\n",
            "Ones Correct:\n",
            "+---------+-----+\n",
            "|correct 1|count|\n",
            "+---------+-----+\n",
            "|      0.0|19652|\n",
            "|      1.0|  138|\n",
            "+---------+-----+\n",
            "\n",
            "time: 4min 17s (started: 2023-10-16 13:20:30 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# How many ones are correct? Let's compare labels and predictions in a new column\n",
        "print(\"Ones predicted:\")\n",
        "predict_df.groupBy('predict').count().show()\n",
        "\n",
        "print(\"\\nOnes Correct:\")\n",
        "predict_df = predict_df.withColumn('correct 1', when((predict_df.predict == 1.0) & (predict_df.readmitted_indexed == 1.0), 1.0).otherwise(0.0))\n",
        "predict_df.groupBy('correct 1').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAlB-B7ZSUZp"
      },
      "source": [
        "So now I can play with the threshold to find a trade-off between 0-error and 1-error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXsBCoQI_49J"
      },
      "source": [
        "Trying PCA to improve performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "gspOoHVe_6Dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5d248a-3e61-465c-df75-1bb83f4afab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio [0.10222815 0.06890062 0.06649803 0.05277852 0.04723434 0.04124038\n",
            " 0.03967399 0.03780522 0.03510643 0.03443922 0.03424951 0.03284408\n",
            " 0.03237846 0.03209193 0.0311499 ]\n",
            "time: 49.3 s (started: 2023-10-16 13:25:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(\n",
        "    k = 15,\n",
        "    inputCol = 'norm_features_toPredReadmission',\n",
        "    outputCol = 'pcaFeatures'\n",
        ").fit(df_train_readmission_binary2)\n",
        "\n",
        "df_train_pca = pca.transform(df_train_readmission_binary2)\n",
        "df_test_pca = pca.transform(df_test_readmission_binary2)\n",
        "\n",
        "print('Explained Variance Ratio', pca.explainedVariance.toArray()) # from this I have seen how many components to select"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U79atfWyT7Bo"
      },
      "source": [
        "Testing the same model to see if there are improvements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "JNeXCvv4Vl3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c5483e-cc90-4a6e-f307-2a1c9b8f7875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 13, 128)           512       \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 11, 64)            24640     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 5, 64)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 3, 32)             6176      \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 1, 16)             1552      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33061 (129.14 KB)\n",
            "Trainable params: 33061 (129.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "time: 194 ms (started: 2023-10-16 13:25:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "      Conv1D(128, 3, activation='relu', input_shape=(15,1)),\n",
        "      Conv1D(64, 3, activation='relu'),\n",
        "      MaxPooling1D(pool_size=2, padding=\"valid\"),\n",
        "      Conv1D(32, 3, activation='relu'),\n",
        "      Conv1D(16, 3, activation='relu'),\n",
        "      Flatten(),\n",
        "      Dense(10, activation='relu'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "bvn0kNhGTpG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad97dc15-d3d4-47ca-98fa-2ac9744ee2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_partitions=20\n",
            "writing dataframes\n",
            "train_data_path=file:///dbfs/horovod_spark_estimator/intermediate_train_data.0\n",
            "val_data_path=file:///dbfs/horovod_spark_estimator/intermediate_val_data.0\n",
            "train_partitions=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:483: FutureWarning: The 'field_by_name' method is deprecated, use 'field' instead\n",
            "  metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:495: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
            "  train_data_schema = train_data.schema.to_arrow_schema()\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:405: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "  for piece in dataset.pieces:\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:513: FutureWarning: The 'field_by_name' method is deprecated, use 'field' instead\n",
            "  metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:223: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model_fn(model, f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'NoneType' object has no attribute 'type'\n",
            "train_rows=79553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,1]<stderr>:2023-10-16 13:26:20.615882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[1,0]<stderr>:2023-10-16 13:26:20.955640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:Pinning current process to the GPU.\n",
            "[1,0]<stdout>:Shared lib path is pointing to: <CDLL '/usr/local/lib/python3.10/dist-packages/horovod/tensorflow/mpi_lib.cpython-310-x86_64-linux-gnu.so', handle 565ed69f0d30 at 0x7f7272ee4070>[1,0]<stdout>:\n",
            "[1,0]<stdout>:Training parameters: Epochs: 30, Scaled lr: 0.019999999552965164, Shuffle: True, random_seed: None\n",
            "[1,0]<stdout>:Train rows: 79553, Train batch size: 128, Train_steps_per_epoch: 311\n",
            "[1,0]<stdout>:Val rows: 0, Val batch size: 128, Val_steps_per_epoch: None\n",
            "[1,0]<stdout>:Checkpoint file: file:///dbfs/horovod_spark_estimator/runs/keras_1697462771, Logs dir: file:///dbfs/horovod_spark_estimator/runs/keras_1697462771/logs\n",
            "[1,0]<stdout>:\n",
            "[1,0]<stdout>:data_module: <class 'horovod.spark.keras.datamodule.PetastormDataModule'>[1,0]<stdout>:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
            "[1,0]<stderr>:  self._filesystem = pyarrow.localfs\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,0]<stderr>:  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  if not dataset.common_metadata:\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,0]<stderr>:  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,0]<stderr>:  meta = parquet_dataset.pieces[0].get_metadata()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  for partition in (parquet_dataset.partitions or []):\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  metadata = dataset.metadata\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  common_metadata = dataset.common_metadata\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,0]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
            "[1,1]<stderr>:  self._filesystem = pyarrow.localfs\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,1]<stderr>:  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  if not dataset.common_metadata:\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,1]<stderr>:  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,1]<stderr>:  meta = parquet_dataset.pieces[0].get_metadata()\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  for partition in (parquet_dataset.partitions or []):\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  metadata = dataset.metadata\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  common_metadata = dataset.common_metadata\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,1]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,1]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,1]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
            "[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:71: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "[1,0]<stderr>:Instructions for updating:\n",
            "[1,0]<stderr>:Use `tf.data.Dataset.unbatch()`.\n",
            "[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:71: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "[1,1]<stderr>:Instructions for updating:\n",
            "[1,1]<stderr>:Use `tf.data.Dataset.unbatch()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0628s vs `on_train_batch_end` time: 0.1153s). Check your callbacks.\n",
            "[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0431s vs `on_train_batch_end` time: 0.1310s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,1]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3991[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 32s 63ms/step - loss: 0.3948\n",
            "[1,0]<stdout>:Epoch 2/30\n",
            "311/311 [==============================] - ETA: 0s - loss: 0.3595[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 55ms/step - loss: 0.3522\n",
            "[1,0]<stdout>:Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1/311 [..............................] - ETA: 11s - loss: 0.3839[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3562[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 18s 57ms/step - loss: 0.3492\n",
            "[1,0]<stdout>:Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3543[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3472\n",
            "[1,0]<stdout>:Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3515[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 18s 56ms/step - loss: 0.3443\n",
            "[1,0]<stdout>:Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3514[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 56ms/step - loss: 0.3433\n",
            "[1,0]<stdout>:Epoch 7/30\n",
            "311/311 [==============================] - ETA: 0s - loss: 0.3521[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3447\n",
            "[1,0]<stdout>:Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3484[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3421\n",
            "[1,0]<stdout>:Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1/311 [..............................] - ETA: 11s - loss: 0.4101[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3494[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3427\n",
            "[1,0]<stdout>:Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3/311 [..............................] - ETA: 14s - loss: 0.3866[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3508[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 55ms/step - loss: 0.3427\n",
            "[1,0]<stdout>:Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3480[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3420\n",
            "[1,0]<stdout>:Epoch 12/30\n",
            "311/311 [==============================] - ETA: 0s - loss: 0.3487[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 56ms/step - loss: 0.3414\n",
            "[1,0]<stdout>:Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3474[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 53ms/step - loss: 0.3413\n",
            "[1,0]<stdout>:Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1/311 [..............................] - ETA: 12s - loss: 0.3829[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3501[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3414\n",
            "[1,0]<stdout>:Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3474[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3412\n",
            "[1,0]<stdout>:Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3/311 [..............................] - ETA: 11s - loss: 0.3621[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3480[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 55ms/step - loss: 0.3402\n",
            "[1,0]<stdout>:Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5/311 [..............................] - ETA: 10s - loss: 0.3466[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3473[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 55ms/step - loss: 0.3416\n",
            "[1,0]<stdout>:Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  8/311 [..............................] - ETA: 12s - loss: 0.3225[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3477[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 56ms/step - loss: 0.3404\n",
            "[1,0]<stdout>:Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  8/311 [..............................] - ETA: 13s - loss: 0.3442[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3485[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 22s 71ms/step - loss: 0.3400\n",
            "[1,0]<stdout>:Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3468[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 20s 63ms/step - loss: 0.3411\n",
            "[1,0]<stdout>:Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309/311 [============================>.] - ETA: 0s - loss: 0.3459[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3460[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 18s 57ms/step - loss: 0.3397\n",
            "[1,0]<stdout>:Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3477[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3476[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 16s 52ms/step - loss: 0.3408\n",
            "[1,0]<stdout>:Epoch 23/30\n",
            "310/311 [============================>.] - ETA: 0s - loss: 0.3487[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 16s 52ms/step - loss: 0.3403\n",
            "[1,0]<stdout>:Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3463[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3396\n",
            "[1,0]<stdout>:Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1/311 [..............................] - ETA: 12s - loss: 0.3566[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3446[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 18s 58ms/step - loss: 0.3395\n",
            "[1,0]<stdout>:Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3/311 [..............................] - ETA: 10s - loss: 0.3199[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3476[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 53ms/step - loss: 0.3389\n",
            "[1,0]<stdout>:Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5/311 [..............................] - ETA: 9s - loss: 0.3661[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3477[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 53ms/step - loss: 0.3411\n",
            "[1,0]<stdout>:Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3461[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3390\n",
            "[1,0]<stdout>:Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310/311 [============================>.] - ETA: 0s - loss: 0.3463[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771\n",
            "311/311 [==============================] - 17s 53ms/step - loss: 0.3407\n",
            "[1,0]<stdout>:Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "311/311 [==============================] - ETA: 0s - loss: 0.3465[1,0]<stdout>:Syncing dir /tmp/tmpb95r5uo5 to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697462771[1,0]<stdout>:\n",
            "311/311 [==============================] - 17s 54ms/step - loss: 0.3386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:223: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "[1,0]<stderr>:  save_model_fn(model, f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8371452985180287\n",
            "time: 12min 9s (started: 2023-10-16 13:25:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "work_dir = \"/dbfs/horovod_spark_estimator/\"\n",
        "store = DBFSLocalStore(work_dir)\n",
        "\n",
        "hvd_estimator = hvd.KerasEstimator(\n",
        "    model=model,\n",
        "    store=store,\n",
        "    optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "    loss='binary_crossentropy',\n",
        "    feature_cols=['pcaFeatures'],\n",
        "    label_cols=['readmitted_indexed'],\n",
        "    batch_size=128,\n",
        "    epochs=30,\n",
        "    )\n",
        "\n",
        "hvd_model = hvd_estimator.fit(df_train_pca) \\\n",
        "    .setOutputCols(['predict'])\n",
        "\n",
        "predict_df = hvd_model.transform(df_test_pca)\n",
        "predict_df = predict_df.withColumn(\"predict\", when(predict_df.predict < 0.3, 0.0).otherwise(1.0))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "  predictionCol='predict', labelCol='readmitted_indexed', metricName='f1')\n",
        "print('Test accuracy:', evaluator.evaluate(predict_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "1BQdHhuDT5kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f2c9a3-6eb0-416d-bc1b-c9352e2217ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones predicted:\n",
            "+-------+-----+\n",
            "|predict|count|\n",
            "+-------+-----+\n",
            "|    0.0|19575|\n",
            "|    1.0|  215|\n",
            "+-------+-----+\n",
            "\n",
            "\n",
            "Ones Correct:\n",
            "+---------+-----+\n",
            "|correct 1|count|\n",
            "+---------+-----+\n",
            "|      0.0|19715|\n",
            "|      1.0|   75|\n",
            "+---------+-----+\n",
            "\n",
            "time: 3min 26s (started: 2023-10-16 13:38:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# How many ones are correct? Let's compare labels and predictions in a new column\n",
        "print(\"Ones predicted:\")\n",
        "predict_df.groupBy('predict').count().show()\n",
        "\n",
        "print(\"\\nOnes Correct:\")\n",
        "predict_df = predict_df.withColumn('correct 1', when((predict_df.predict == 1.0) & (predict_df.readmitted_indexed == 1.0), 1.0).otherwise(0.0))\n",
        "predict_df.groupBy('correct 1').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5FvyiY5YvBx"
      },
      "source": [
        "I obtained similar results looking at the percentage of ones predicted and ones correctness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNoc6wXw__kT"
      },
      "source": [
        "# Project Work: Predicting early readmission with only features which have A1Cresult test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX76I_CdaUJc"
      },
      "source": [
        "Corrected dataset recovery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r5SteHBbCH_",
        "outputId": "34e8ee45-8522-4997-afce-64d3d37144c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16834"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.58 s (started: 2023-10-16 13:41:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pred_readmission_withA1Cresults.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "senQQQ1Rmg-3"
      },
      "source": [
        "unification of the classes NO and >30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPzYarxHmgZ2",
        "outputId": "8114770b-a411-421d-8afc-3eb6ae78a960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 89.8 ms (started: 2023-10-16 13:41:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "df_pred_readmission_withA1Cresults = df_pred_readmission_withA1Cresults.withColumn(\"readmitted_indexed\", when(df_pred_readmission_withA1Cresults.readmitted_indexed == 2.0, 1.0) \\\n",
        "      .when(df_pred_readmission_withA1Cresults.readmitted_indexed == 1.0, 0.0) \\\n",
        "      .otherwise(df_pred_readmission_withA1Cresults.readmitted_indexed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZl3rxQpjZpG"
      },
      "source": [
        "Splitting in train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdCRwEs0jcMz",
        "outputId": "de4a0a04-bc4c-4fcd-9523-43dd22f3b820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances in the training set: 14369\n",
            "Number of instances in the test set: 2465\n",
            "time: 22.6 s (started: 2023-10-16 13:41:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "(df_train_pjw, df_test_pjw) = df_pred_readmission_withA1Cresults.randomSplit([0.85, 0.15], seed=seed)\n",
        "print('Number of instances in the training set:', df_train_pjw.count())\n",
        "print('Number of instances in the test set:', df_test_pjw.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG0h4JgLkA2F"
      },
      "source": [
        "The dataset is very limited in dimension, but let's try to find some insight about the importance of A1C test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "171wTP5WAILJ"
      },
      "source": [
        "### K-means clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds71FvmJAHLb",
        "outputId": "6ef6b94a-1edc-4eef-94c0-240d89ae4d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+------------------+----------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|prediction|\n",
            "+-------------------------------+------------------+----------+\n",
            "|           [1.20761980818831...|               0.0|         0|\n",
            "|           [0.58047087041334...|               0.0|         0|\n",
            "|           [-0.6738270051366...|               0.0|         1|\n",
            "|           [-0.0466780673616...|               0.0|         1|\n",
            "|           [1.20761980818831...|               0.0|         1|\n",
            "|           [0.58047087041334...|               1.0|         0|\n",
            "|           [-0.0466780673616...|               1.0|         1|\n",
            "|           [0.58047087041334...|               0.0|         0|\n",
            "|           [0.58047087041334...|               0.0|         0|\n",
            "|           [-1.9281248806865...|               0.0|         0|\n",
            "|           [-0.0466780673616...|               0.0|         1|\n",
            "|           [-0.0466780673616...|               0.0|         0|\n",
            "|           [-0.0466780673616...|               1.0|         0|\n",
            "|           [-0.0466780673616...|               0.0|         0|\n",
            "|           [-0.6738270051366...|               0.0|         1|\n",
            "|           [1.20761980818831...|               0.0|         1|\n",
            "|           [1.20761980818831...|               1.0|         1|\n",
            "|           [1.20761980818831...|               0.0|         0|\n",
            "|           [-1.3009759429115...|               0.0|         1|\n",
            "|           [-0.6738270051366...|               0.0|         1|\n",
            "+-------------------------------+------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "time: 1min 3s (started: 2023-10-16 13:41:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "kmeans = KMeans(featuresCol=\"norm_features_toPredReadmission\", k=2, seed=seed)\n",
        "kmeans_model = kmeans.fit(df_pred_readmission_withA1Cresults)\n",
        "predictions = kmeans_model.transform(df_pred_readmission_withA1Cresults)\n",
        "predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWyQCrDtxMLO",
        "outputId": "93bed1b5-ef6d-415e-e93d-42b96ede8920"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4414874658429369"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.9 s (started: 2023-10-16 13:42:55 +00:00)\n"
          ]
        }
      ],
      "source": [
        "accuracy_score(predictions.select('readmitted_indexed').toPandas(), predictions.select('prediction').toPandas())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGXc8g8wy31A"
      },
      "source": [
        "Too poor results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK8t6qVOysVV"
      },
      "source": [
        "Selecting a reduced space and trying clustering again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m_jNDbvyj03",
        "outputId": "16795129-439a-444e-e223-1f6841090e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratio [0.11327934 0.073627   0.05961847 0.05466757 0.04763262 0.04265594\n",
            " 0.04168561 0.04031009 0.03941983 0.03879739]\n",
            "+-------------------------------+------------------+--------------------+----------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|         pcaFeatures|prediction|\n",
            "+-------------------------------+------------------+--------------------+----------+\n",
            "|           [1.20761980818831...|               0.0|[-1.5384292271849...|         0|\n",
            "|           [0.58047087041334...|               0.0|[-0.5540932975882...|         0|\n",
            "|           [-0.6738270051366...|               0.0|[1.57902087066283...|         1|\n",
            "|           [-0.0466780673616...|               0.0|[0.87208833659209...|         1|\n",
            "|           [1.20761980818831...|               0.0|[1.72610631870966...|         1|\n",
            "|           [0.58047087041334...|               1.0|[-3.5403721546557...|         0|\n",
            "|           [-0.0466780673616...|               1.0|[-0.6241098361894...|         1|\n",
            "|           [0.58047087041334...|               0.0|[-2.7220381443305...|         0|\n",
            "|           [0.58047087041334...|               0.0|[-3.2338208003293...|         0|\n",
            "|           [-1.9281248806865...|               0.0|[-1.8513885023338...|         0|\n",
            "|           [-0.0466780673616...|               0.0|[0.08551728797476...|         1|\n",
            "|           [-0.0466780673616...|               0.0|[-2.5828553944939...|         0|\n",
            "|           [-0.0466780673616...|               1.0|[-1.6574552867547...|         0|\n",
            "|           [-0.0466780673616...|               0.0|[-1.6590184077338...|         0|\n",
            "|           [-0.6738270051366...|               0.0|[0.46209323980659...|         1|\n",
            "|           [1.20761980818831...|               0.0|[-0.1924793499461...|         1|\n",
            "|           [1.20761980818831...|               1.0|[1.67812427814730...|         1|\n",
            "|           [1.20761980818831...|               0.0|[-1.6046375297689...|         0|\n",
            "|           [-1.3009759429115...|               0.0|[0.97924145139123...|         1|\n",
            "|           [-0.6738270051366...|               0.0|[1.97676866420793...|         1|\n",
            "+-------------------------------+------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4486752999881193"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 13s (started: 2023-10-16 13:43:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(\n",
        "    k = 10,\n",
        "    inputCol = 'norm_features_toPredReadmission',\n",
        "    outputCol = 'pcaFeatures'\n",
        ").fit(df_pred_readmission_withA1Cresults)\n",
        "\n",
        "df_pca = pca.transform(df_pred_readmission_withA1Cresults)\n",
        "\n",
        "print('Explained Variance Ratio', pca.explainedVariance.toArray())\n",
        "\n",
        "kmeans = KMeans(featuresCol=\"pcaFeatures\", k=2, seed=seed)\n",
        "kmeans_model = kmeans.fit(df_pca)\n",
        "predictions = kmeans_model.transform(df_pca)\n",
        "predictions.show()\n",
        "\n",
        "print(\"Accuracy:\")\n",
        "accuracy_score(predictions.select('readmitted_indexed').toPandas(), predictions.select('prediction').toPandas())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvsEklMv0OJh"
      },
      "source": [
        "It doesn't improve, clustering is a bad idea for this type of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQyjxWmj0JQd"
      },
      "source": [
        "### Decision Tree (to have a comparison with previous results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OuBNBZ30IGI",
        "outputId": "5f340c68-cfb2-4795-ee1d-fdd8654dad63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.86\n",
            "time: 51.1 s (started: 2023-10-16 13:44:22 +00:00)\n"
          ]
        }
      ],
      "source": [
        "dt_classifier = DecisionTreeClassifier(labelCol=\"readmitted_indexed\", featuresCol=\"norm_features_toPredReadmission\")\n",
        "model_DT = dt_classifier.fit(df_train_pjw)\n",
        "\n",
        "predictions = model_DT.transform(df_test_pjw)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"readmitted_indexed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcCUra9D2eTz",
        "outputId": "8aa049c5-a3b2-4c3b-d740-747c5faf20f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----+\n",
            "|readmitted_indexed|count|\n",
            "+------------------+-----+\n",
            "|               0.0| 2224|\n",
            "|               1.0|  241|\n",
            "+------------------+-----+\n",
            "\n",
            "time: 12.3 s (started: 2023-10-16 13:45:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predictions.groupBy('readmitted_indexed').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8acoHL52OHt",
        "outputId": "95628325-102d-4a16-b786-d501673ff5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|       0.0| 2462|\n",
            "|       1.0|    3|\n",
            "+----------+-----+\n",
            "\n",
            "time: 13.1 s (started: 2023-10-16 13:45:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predictions.groupBy('prediction').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV5nPHTr2phR"
      },
      "source": [
        "Hitting few ones, I can't say that the test is as incisive as written in the paper. However, I have to consider that the dataset is very small and not the most correct way to see this correlation. I probably have to predict the whole dataset and see if the correct ones match the test performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgIkELPxaQ4P"
      },
      "source": [
        "### (linear) SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEgp0yCnaTcQ",
        "outputId": "547772fc-a1c0-4864-909e-7ddec8a410e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction f1:  0.8558593609747382\n",
            "+-------------------------------+------------------+--------------------+----------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|       rawPrediction|prediction|\n",
            "+-------------------------------+------------------+--------------------+----------+\n",
            "|           [-3.8095716940114...|               0.0|[1.01508775352097...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00020581430183...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00019776832501...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00020183586567...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00021820781104...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00016098920725...|       0.0|\n",
            "|           [-3.8095716940114...|               1.0|[1.00021512125161...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00021815386350...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00021006641705...|       0.0|\n",
            "|           [-3.8095716940114...|               0.0|[1.00019959114288...|       0.0|\n",
            "+-------------------------------+------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "time: 59.9 s (started: 2023-10-16 13:45:39 +00:00)\n"
          ]
        }
      ],
      "source": [
        "lsvc = LinearSVC(featuresCol=\"norm_features_toPredReadmission\", labelCol=\"readmitted_indexed\", maxIter=50)\n",
        "lsvc = lsvc.fit(df_train_pjw)\n",
        "\n",
        "pred = lsvc.transform(df_test_pjw)\n",
        "\n",
        "evaluator=MulticlassClassificationEvaluator(labelCol=\"readmitted_indexed\", metricName=\"f1\")\n",
        "f1 = evaluator.evaluate(pred)\n",
        "\n",
        "print(\"Prediction f1: \", f1)\n",
        "\n",
        "pred.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "hMnYS-aysBsc",
        "outputId": "8c8b1fa4-68c5-4fea-9113-7f992e8aad64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+----------+-----+\n",
              "|prediction|count|\n",
              "+----------+-----+\n",
              "|       0.0| 2465|\n",
              "+----------+-----+"
            ],
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>prediction</th><th>count</th></tr>\n",
              "<tr><td>0.0</td><td>2465</td></tr>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 27 s (started: 2023-10-16 13:46:39 +00:00)\n"
          ]
        }
      ],
      "source": [
        "pred.groupBy('prediction').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESq9ARGaANnU"
      },
      "source": [
        "### Horovod model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXOc9jE7AQOF",
        "outputId": "646fd010-a1ae-450b-8b64-d9bb8455af9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 31, 62)            124       \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 30, 128)           16000     \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 30, 64)            8256      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 10, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 64)            0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10, 62)            4030      \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 8, 32)             5984      \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 2, 32)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 32)             0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               6500      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                260       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47490 (185.51 KB)\n",
            "Trainable params: 47490 (185.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 317 ms (started: 2023-10-16 13:47:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "      Dense(62, activation='softmax', input_shape=(31,1)),\n",
        "      Conv1D(128, 2, activation='relu'),\n",
        "      Conv1D(64, 1, activation='relu'),\n",
        "      MaxPooling1D(pool_size=3, padding=\"valid\"),\n",
        "      Dropout(0.2),\n",
        "      Dense(62, activation='softmax'),\n",
        "      Conv1D(32, 3, activation='relu'),\n",
        "      MaxPooling1D(pool_size=4),\n",
        "      Dropout(0.2),\n",
        "      Flatten(),\n",
        "      Dense(100, activation='relu'),\n",
        "      Dense(50, activation='softmax'),\n",
        "      Dense(25, activation='softmax'),\n",
        "      Dense(10, activation='sigmoid'),\n",
        "      Dense(1, activation='sigmoid'),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "achRUBrLib26",
        "outputId": "0e39ce69-818b-468c-99e2-c6963bb90226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_partitions=20\n",
            "writing dataframes\n",
            "train_data_path=file:///dbfs/horovod_spark_estimator/intermediate_train_data.0\n",
            "val_data_path=file:///dbfs/horovod_spark_estimator/intermediate_val_data.0\n",
            "train_partitions=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:483: FutureWarning: The 'field_by_name' method is deprecated, use 'field' instead\n",
            "  metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:495: FutureWarning: 'ParquetDataset.schema' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.schema' attribute instead (which will return an Arrow schema instead of a Parquet schema).\n",
            "  train_data_schema = train_data.schema.to_arrow_schema()\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:405: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "  for piece in dataset.pieces:\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/common/util.py:513: FutureWarning: The 'field_by_name' method is deprecated, use 'field' instead\n",
            "  metadata, avg_row_size = make_metadata_dictionary(train_data_schema)\n",
            "/usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:223: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  save_model_fn(model, f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'NoneType' object has no attribute 'type'\n",
            "train_rows=14369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:2023-10-16 13:47:29.516140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[1,1]<stderr>:2023-10-16 13:47:29.567331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:Pinning current process to the GPU.[1,0]<stdout>:\n",
            "[1,0]<stdout>:Shared lib path is pointing to: <CDLL '/usr/local/lib/python3.10/dist-packages/horovod/tensorflow/mpi_lib.cpython-310-x86_64-linux-gnu.so', handle 5a913b761860 at 0x790344368070>\n",
            "[1,0]<stdout>:Training parameters: Epochs: 25, Scaled lr: 0.019999999552965164, Shuffle: True, random_seed: None\n",
            "[1,0]<stdout>:Train rows: 14369, Train batch size: 64, Train_steps_per_epoch: 113\n",
            "[1,0]<stdout>:Val rows: 0, Val batch size: 64, Val_steps_per_epoch: None\n",
            "[1,0]<stdout>:Checkpoint file: file:///dbfs/horovod_spark_estimator/runs/keras_1697464043, Logs dir: file:///dbfs/horovod_spark_estimator/runs/keras_1697464043/logs\n",
            "[1,0]<stdout>:\n",
            "[1,0]<stdout>:data_module: <class 'horovod.spark.keras.datamodule.PetastormDataModule'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
            "[1,0]<stderr>:  self._filesystem = pyarrow.localfs\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,0]<stderr>:  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  if not dataset.common_metadata:\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,0]<stderr>:  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,0]<stderr>:  meta = parquet_dataset.pieces[0].get_metadata()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  for partition in (parquet_dataset.partitions or []):\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  metadata = dataset.metadata\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  common_metadata = dataset.common_metadata\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,0]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,0]<stderr>:  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
            "[1,1]<stderr>:  self._filesystem = pyarrow.localfs\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,1]<stderr>:  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  if not dataset.common_metadata:\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
            "[1,1]<stderr>:  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,1]<stderr>:  meta = parquet_dataset.pieces[0].get_metadata()\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  for partition in (parquet_dataset.partitions or []):\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  metadata = dataset.metadata\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  common_metadata = dataset.common_metadata\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
            "[1,1]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,1]<stderr>:  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
            "[1,1]<stderr>:  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,1]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,1]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
            "[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:71: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "[1,0]<stderr>:Instructions for updating:\n",
            "[1,0]<stderr>:Use `tf.data.Dataset.unbatch()`.\n",
            "[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:71: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "[1,1]<stderr>:Instructions for updating:\n",
            "[1,1]<stderr>:Use `tf.data.Dataset.unbatch()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,0]<stdout>:Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1330s vs `on_train_batch_end` time: 0.4740s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5/113 [>.............................] - ETA: 9s - loss: 1.8423[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0870s vs `on_train_batch_end` time: 0.5129s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.7860[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 22s 98ms/step - loss: 0.7843\n",
            "[1,0]<stdout>:Epoch 2/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,1]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,1]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3568[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.3502\n",
            "[1,0]<stdout>:Epoch 3/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3461[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 12s 109ms/step - loss: 0.3339\n",
            "[1,0]<stdout>:Epoch 4/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3338[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.3288\n",
            "[1,0]<stdout>:Epoch 5/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3418[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.3241\n",
            "[1,0]<stdout>:Epoch 6/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/113 [============================>.] - ETA: 0s - loss: 0.3273[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.3212\n",
            "[1,0]<stdout>:Epoch 7/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3413[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 9s 78ms/step - loss: 0.3273\n",
            "[1,0]<stdout>:Epoch 8/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3329[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 104ms/step - loss: 0.3235\n",
            "[1,0]<stdout>:Epoch 9/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/113 [============================>.] - ETA: 0s - loss: 0.3337[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.3270\n",
            "[1,0]<stdout>:Epoch 10/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6/113 [>.............................] - ETA: 6s - loss: 0.3913[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3411[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 9s 80ms/step - loss: 0.3232\n",
            "[1,0]<stdout>:Epoch 11/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3357[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 106ms/step - loss: 0.3267\n",
            "[1,0]<stdout>:Epoch 12/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3336[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 13s 111ms/step - loss: 0.3226\n",
            "[1,0]<stdout>:Epoch 13/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/113 [============================>.] - ETA: 0s - loss: 0.3508[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 9s 84ms/step - loss: 0.3349\n",
            "[1,0]<stdout>:Epoch 14/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3241[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 104ms/step - loss: 0.3184\n",
            "[1,0]<stdout>:Epoch 15/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3430[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 12s 107ms/step - loss: 0.3273\n",
            "[1,0]<stdout>:Epoch 16/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3326[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 9s 81ms/step - loss: 0.3238\n",
            "[1,0]<stdout>:Epoch 17/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 37/113 [========>.....................] - ETA: 6s - loss: 0.3346[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/113 [============================>.] - ETA: 0s - loss: 0.3445[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 12s 105ms/step - loss: 0.3306\n",
            "[1,0]<stdout>:Epoch 18/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3330[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.3251\n",
            "[1,0]<stdout>:Epoch 19/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3354[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 9s 80ms/step - loss: 0.3228\n",
            "[1,0]<stdout>:Epoch 20/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3336[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 12s 108ms/step - loss: 0.3220\n",
            "[1,0]<stdout>:Epoch 21/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3363[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 108ms/step - loss: 0.3253\n",
            "[1,0]<stdout>:Epoch 22/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3372[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043\n",
            "113/113 [==============================] - 9s 79ms/step - loss: 0.3298\n",
            "[1,0]<stdout>:Epoch 23/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3363[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 110ms/step - loss: 0.3220\n",
            "[1,0]<stdout>:Epoch 24/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 68/113 [=================>............] - ETA: 2s - loss: 0.3376[1,0]<stdout>:\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3372[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 12s 103ms/step - loss: 0.3220\n",
            "[1,0]<stdout>:Epoch 25/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/tf_utils.py:378: UserWarning: Running multiple iterations over make_petastorm_dataset is not recommend for performance issue. Use Reader's num_epochs contructor arguments to set number of iterations,or use tf.data.Dataset's cache() function to cache data of first iteration beforecalling 'repeat' method of Datset class.\n",
            "[1,0]<stderr>:  warnings.warn(_RESET_READER_WARN, category=UserWarning)\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
            "[1,0]<stderr>:  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
            "[1,0]<stderr>:  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - ETA: 0s - loss: 0.3308[1,0]<stdout>:Syncing dir /tmp/tmpkqsazz9n to dir file:///dbfs/horovod_spark_estimator/runs/keras_1697464043[1,0]<stdout>:\n",
            "113/113 [==============================] - 8s 74ms/step - loss: 0.3255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1,0]<stderr>:/usr/local/lib/python3.10/dist-packages/horovod/spark/keras/util.py:223: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "[1,0]<stderr>:  save_model_fn(model, f)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8558593609747382\n",
            "time: 6min 38s (started: 2023-10-16 13:47:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "work_dir = \"/dbfs/horovod_spark_estimator/\"\n",
        "store = DBFSLocalStore(work_dir)\n",
        "\n",
        "hvd_estimator = hvd.KerasEstimator(\n",
        "    model=model,\n",
        "    store=store,\n",
        "    optimizer=keras.optimizers.SGD(lr=0.1),\n",
        "    loss='binary_crossentropy',\n",
        "    feature_cols=['norm_features_toPredReadmission'],\n",
        "    label_cols=['readmitted_indexed'],\n",
        "    batch_size=64,\n",
        "    epochs=25,\n",
        "    )\n",
        "\n",
        "hvd_model = hvd_estimator.fit(df_train_pjw) \\\n",
        "    .setOutputCols(['predict'])\n",
        "\n",
        "predict_df = hvd_model.transform(df_test_pjw)\n",
        "predict_df = predict_df.withColumn(\"predict\", when(predict_df.predict < 0.3, 0.0).otherwise(1.0))\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "  predictionCol='predict', labelCol='readmitted_indexed', metricName='f1')\n",
        "print('Test accuracy:', evaluator.evaluate(predict_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKXbkJgQid2P",
        "outputId": "c65c5815-bf12-4ab2-8ba3-2c87bce229eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones predicted:\n",
            "+-------+-----+\n",
            "|predict|count|\n",
            "+-------+-----+\n",
            "|    0.0| 2465|\n",
            "+-------+-----+\n",
            "\n",
            "\n",
            "Ones Correct:\n",
            "+---------+-----+\n",
            "|correct 1|count|\n",
            "+---------+-----+\n",
            "|      0.0| 2465|\n",
            "+---------+-----+\n",
            "\n",
            "time: 1min (started: 2023-10-16 13:54:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# How many ones are correct? Let's compare labels and predictions in a new column\n",
        "print(\"Ones predicted:\")\n",
        "predict_df.groupBy('predict').count().show()\n",
        "\n",
        "print(\"\\nOnes Correct:\")\n",
        "predict_df = predict_df.withColumn('correct 1', when((predict_df.predict == 1.0) & (predict_df.readmitted_indexed == 1.0), 1.0).otherwise(0.0))\n",
        "predict_df.groupBy('correct 1').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brXpyG3M2VKy",
        "outputId": "d23ecced-fba4-408c-d108-bff5a4c64254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+------------------+-------+---------+\n",
            "|norm_features_toPredReadmission|readmitted_indexed|predict|correct 1|\n",
            "+-------------------------------+------------------+-------+---------+\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               1.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               0.0|    0.0|      0.0|\n",
            "|           [-3.8095716940114...|               1.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               1.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "|           [-3.1824227562364...|               0.0|    0.0|      0.0|\n",
            "+-------------------------------+------------------+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "time: 5.43 s (started: 2023-10-16 13:55:50 +00:00)\n"
          ]
        }
      ],
      "source": [
        "predict_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbNboHSiGZ3c"
      },
      "source": [
        "# FUTURE WORK: make some prediction on A1Cresult ---> done or not?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "57kg2SCcxGPs",
        "btgeV_HKr3Dt",
        "jLwZkUsVr3Dv",
        "bhxIV6Q0r3Dx",
        "usGJlwvMPkCr",
        "0c__Y4hlPYD7",
        "LjXwtfimr3D0",
        "TQE5POAA7WRU",
        "osJ-hknb6Zq-",
        "RZzpbNeKVKsI",
        "kx2XFc0tmbvL",
        "gQwjlPz3mWt3",
        "u7Mg-jP1QLGd",
        "MKMU1Op1Qbxn",
        "m0oMBPspWXyj",
        "Tznv67d-_7lI",
        "TNoc6wXw__kT",
        "171wTP5WAILJ",
        "BQyjxWmj0JQd",
        "kgIkELPxaQ4P",
        "ESq9ARGaANnU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}